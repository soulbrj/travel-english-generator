import os
import shutil
import streamlit as st
import pandas as pd
import numpy as np
from PIL import Image, ImageDraw, ImageFont, ImageOps
import imageio.v2 as imageio
import tempfile
import subprocess
import traceback
import asyncio
import base64
import time

# æ£€æŸ¥ ffmpeg æ˜¯å¦å¯ç”¨
def check_ffmpeg():
    ffmpeg_path = shutil.which('ffmpeg')
    return ffmpeg_path

# å°è¯•å¯¼å…¥å„ç§TTSåº“
EDGE_TTS_AVAILABLE = False
PYTTSX3_AVAILABLE = False
GTTS_AVAILABLE = False

try:
    import edge_tts
    EDGE_TTS_AVAILABLE = True
except Exception:
    EDGE_TTS_AVAILABLE = False

try:
    import pyttsx3
    PYTTSX3_AVAILABLE = True
except Exception:
    PYTTSX3_AVAILABLE = False

try:
    from gtts import gTTS
    GTTS_AVAILABLE = True
except Exception:
    GTTS_AVAILABLE = False

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ—…è¡Œè‹±è¯­è§†é¢‘ç”Ÿæˆå™¨",
    page_icon="ğŸ¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: 700;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 2rem;
    }
    .section-header {
        font-size: 1.5rem;
        font-weight: 600;
        color: #1f2937;
        margin: 1.5rem 0 1rem 0;
        padding-bottom: 0.5rem;
        border-bottom: 2px solid #e5e7eb;
    }
    .info-card {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin: 1rem 0;
    }
    .success-card {
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin: 1rem 0;
    }
    .warning-card {
        background: linear-gradient(135deg, #f6d365 0%, #fda085 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin: 1rem 0;
    }
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    }
    .stButton > button {
        width: 100%;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        padding: 0.75rem 1.5rem;
        border-radius: 8px;
        font-weight: 600;
        transition: all 0.3s ease;
    }
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
    }
    .upload-section {
        border: 2px dashed #667eea;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        background: rgba(102, 126, 234, 0.05);
        margin: 1rem 0;
    }
    .preview-section {
        background: #f8fafc;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
        border-left: 4px solid #667eea;
    }
    .setting-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
        border: 1px solid #e5e7eb;
        margin: 0.5rem 0;
    }
    .voice-preview-btn {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        color: white !important;
        border: none !important;
        border-radius: 6px !important;
        padding: 0.5rem 1rem !important;
        font-size: 0.9rem !important;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 0px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        border-radius: 4px 4px 0px 0px;
        gap: 0px;
        padding-top: 10px;
        padding-bottom: 10px;
    }
</style>
""", unsafe_allow_html=True)

# ä¼šè¯çŠ¶æ€
if 'bg_image' not in st.session_state:
    st.session_state.bg_image = None
if 'tts_method' not in st.session_state:
    st.session_state.tts_method = "edge_tts"

# -----------------------
# å·¥å…·å‡½æ•°
# -----------------------
def wrap_text(text, max_chars):
    if not text or str(text).strip().lower() == 'nan':
        return [""]
    text = str(text).strip()
    if any('\u4e00' <= c <= '\u9fff' for c in text):
        max_chars = min(max_chars, 15)
    words = text.split()
    lines, current = [], []
    for word in words:
        test_line = ' '.join(current + [word])
        if len(test_line) <= max_chars:
            current.append(word)
        else:
            if current:
                lines.append(' '.join(current))
            if len(word) > max_chars:
                for i in range(0, len(word), max_chars):
                    lines.append(word[i:i+max_chars])
                current = []
            else:
                current = [word]
    if current:
        lines.append(' '.join(current))
    return lines

def get_phonetic_font(size, bold=False):
    """ä¸“é—¨ç”¨äºéŸ³æ ‡æ˜¾ç¤ºçš„å­—ä½“åŠ è½½å‡½æ•°"""
    try:
        font_files = [
            "DoulosSIL-R.ttf", "CharisSIL-R.ttf", "NotoSansIPA-Regular.ttf",
            "ArialUni.ttf", "l_10646.ttf", "DejaVuSans.ttf",
        ]
        
        system_font_paths = [
            "/usr/share/fonts/", "C:/Windows/Fonts/", 
            "~/Library/Fonts/", "/Library/Fonts/",
        ]
        
        if bold:
            bold_fonts = [
                "DoulosSIL-B.ttf", "CharisSIL-B.ttf", "NotoSansIPA-Bold.ttf",
                "ArialUniBold.ttf", "DejaVuSans-Bold.ttf",
            ]
            for font in bold_fonts:
                try:
                    return ImageFont.truetype(font, size)
                except:
                    pass
        
        for font in font_files:
            try:
                return ImageFont.truetype(font, size)
            except:
                pass
        
        return ImageFont.load_default()
    except Exception as e:
        return ImageFont.load_default()

def get_font(size, font_type="default", bold=False):
    """è·å–å­—ä½“ï¼Œæ”¯æŒéŸ³æ ‡ç¬¦å·å’Œä¸­æ–‡"""
    if font_type == "phonetic":
        return get_phonetic_font(size, bold)
    
    try:
        chinese_fonts = [
            "simhei.ttf", "msyh.ttc", "simsun.ttc", "STHeiti Light.ttc",
            "PingFang.ttc", "Arial Unicode MS", "SimHei", "Microsoft YaHei",
            "WenQuanYi Micro Hei", "NotoSansCJK-Regular.ttc",
        ]
        
        if bold:
            bold_fonts = [
                "simhei.ttf", "msyhbd.ttc", "STHeiti Medium.ttc",
                "PingFang SC Semibold.ttc", "Arial Unicode MS", "SimHei",
            ]
            for f in bold_fonts:
                try:
                    return ImageFont.truetype(f, size)
                except Exception:
                    continue
        
        for f in chinese_fonts:
            try:
                return ImageFont.truetype(f, size)
            except Exception:
                continue
        
        return ImageFont.load_default()
    except Exception as e:
        return ImageFont.load_default()

def create_frame(english, chinese, phonetic, width=1920, height=1080,
                 bg_color=(0,0,0), bg_image=None,
                 eng_color=(255,255,255), chn_color=(173,216,230), pho_color=(255,255,0),
                 eng_size=80, chn_size=60, pho_size=50,
                 text_bg_enabled=False, text_bg_color=(255,255,255,180), text_bg_padding=20,
                 text_bg_radius=30, text_bg_width=None, text_bg_height=None,
                 bold_text=True, eng_pho_spacing=30, pho_chn_spacing=30, line_spacing=15):
    """åˆ›å»ºä¸€å¸§å›¾ç‰‡"""
    if bg_image:
        try:
            img = ImageOps.fit(bg_image.convert('RGB'), (width, height), Image.Resampling.LANCZOS)
        except Exception:
            img = Image.new('RGB', (width, height), bg_color)
    else:
        img = Image.new('RGB', (width, height), bg_color)

    draw = ImageDraw.Draw(img)
    
    eng_font = get_font(eng_size, "phonetic", bold=bold_text)
    chn_font = get_font(chn_size, "chinese", bold=bold_text)
    pho_font = get_font(pho_size, "phonetic", bold=bold_text)

    eng_lines = wrap_text(english, 40)
    chn_lines = wrap_text(chinese, 20)
    pho_lines = wrap_text(phonetic, 45) if phonetic else []

    total_height = 0

    for line in eng_lines:
        bbox = draw.textbbox((0,0), line, font=eng_font)
        h = bbox[3] - bbox[1]
        total_height += h
    total_height += line_spacing * (len(eng_lines)-1)

    if pho_lines:
        total_height += eng_pho_spacing
        for line in pho_lines:
            bbox = draw.textbbox((0,0), line, font=pho_font)
            h = bbox[3] - bbox[1]
            total_height += h
        total_height += line_spacing * (len(pho_lines)-1)

    if chn_lines:
        total_height += pho_chn_spacing
        for line in chn_lines:
            bbox = draw.textbbox((0,0), line, font=chn_font)
            h = bbox[3] - bbox[1]
            total_height += h
        total_height += line_spacing * (len(chn_lines)-1)

    if text_bg_enabled:
        max_width = 0
        for line in eng_lines:
            bbox = draw.textbbox((0,0), line, font=eng_font)
            w = bbox[2] - bbox[0]
            max_width = max(max_width, w)
        for line in pho_lines:
            bbox = draw.textbbox((0,0), line, font=pho_font)
            w = bbox[2] - bbox[0]
            max_width = max(max_width, w)
        for line in chn_lines:
            bbox = draw.textbbox((0,0), line, font=chn_font)
            w = bbox[2] - bbox[0]
            max_width = max(max_width, w)
        
        if text_bg_width is None:
            bg_width = max_width + text_bg_padding * 2
        else:
            bg_width = text_bg_width
            
        if text_bg_height is None:
            bg_height = total_height + text_bg_padding * 2
        else:
            bg_height = text_bg_height
        
        bg_x = (width - bg_width) // 2
        bg_y = (height - bg_height) // 2
        
        bg_layer = Image.new('RGBA', (bg_width, bg_height), (0,0,0,0))
        bg_draw = ImageDraw.Draw(bg_layer)
        
        if text_bg_radius > 0:
            bg_draw.rounded_rectangle(
                [(0, 0), (bg_width, bg_height)],
                radius=text_bg_radius,
                fill=text_bg_color
            )
        else:
            bg_draw.rectangle(
                [(0, 0), (bg_width, bg_height)],
                fill=text_bg_color
            )
        
        img.paste(bg_layer, (bg_x, bg_y), bg_layer)

    y = (height - total_height)//2

    for line in eng_lines:
        bbox = draw.textbbox((0,0), line, font=eng_font)
        w = bbox[2] - bbox[0]
        h = bbox[3] - bbox[1]
        x = (width - w)//2
        shadow_offset = 3
        draw.text((x+shadow_offset, y+shadow_offset), line, font=eng_font, fill=(0,0,0,128))
        draw.text((x, y), line, font=eng_font, fill=eng_color)
        y += h + line_spacing

    if pho_lines:
        y += eng_pho_spacing
        for line in pho_lines:
            bbox = draw.textbbox((0,0), line, font=pho_font)
            w = bbox[2] - bbox[0]
            h = bbox[3] - bbox[1]
            x = (width - w)//2
            shadow_offset = 3
            draw.text((x+shadow_offset, y+shadow_offset), line, font=pho_font, fill=(0,0,0,128))
            draw.text((x, y), line, font=pho_font, fill=pho_color)
            y += h + line_spacing

    if chn_lines:
        y += pho_chn_spacing
        for line in chn_lines:
            bbox = draw.textbbox((0,0), line, font=chn_font)
            w = bbox[2] - bbox[0]
            h = bbox[3] - bbox[1]
            x = (width - w)//2
            shadow_offset = 3
            draw.text((x+shadow_offset, y+shadow_offset), line, font=chn_font, fill=(0,0,0,128))
            draw.text((x, y), line, font=chn_font, fill=chn_color)
            y += h + line_spacing

    return img

# -----------------------
# TTS æœåŠ¡ - å¤šæ–¹æ¡ˆæ”¯æŒ
# -----------------------
VOICE_OPTIONS = {
    "English - Female (US) - Aria": "en-US-AriaNeural",
    "English - Female (US) - Jenny": "en-US-JennyNeural",
    "English - Male (US) - Guy": "en-US-GuyNeural",
    "English - Male (US) - Davis": "en-US-DavisNeural",
    "Chinese - Female (CN) - Xiaoxiao": "zh-CN-XiaoxiaoNeural",
    "Chinese - Female (CN) - Xiaoyi": "zh-CN-XiaoyiNeural",
    "Chinese - Male (CN) - Yunxi": "zh-CN-YunxiNeural",
}

# Edge TTS
async def _edge_tts_save(text: str, voice_name: str, out_path: str, rate: str = "+0%"):
    try:
        communicate = edge_tts.Communicate(text, voice_name, rate=rate)
        await communicate.save(out_path)
        return True
    except Exception as e:
        st.error(f"Edge TTSç”Ÿæˆå¤±è´¥: {e}")
        return False

def generate_edge_audio(text, voice, speed=1.0, out_path=None):
    if not EDGE_TTS_AVAILABLE:
        return None
    
    pct = int((speed - 1.0) * 100)
    rate_str = f"{pct:+d}%"
    
    if out_path is None:
        fd, out_path = tempfile.mkstemp(suffix='.mp3')
        os.close(fd)
    
    try:
        success = asyncio.run(_edge_tts_save(text, voice, out_path, rate_str))
        if success and os.path.exists(out_path) and os.path.getsize(out_path) > 0:
            return out_path
        else:
            if os.path.exists(out_path):
                os.unlink(out_path)
            return None
    except Exception as e:
        if os.path.exists(out_path):
            os.unlink(out_path)
        return None

# pyttsx3 TTS (ç¦»çº¿)
def generate_pyttsx3_audio(text, out_path=None):
    if not PYTTSX3_AVAILABLE:
        return None
    
    if out_path is None:
        fd, out_path = tempfile.mkstemp(suffix='.mp3')
        os.close(fd)
    
    try:
        engine = pyttsx3.init()
        
        # è®¾ç½®å±æ€§
        engine.setProperty('rate', 150)  # è¯­é€Ÿ
        engine.setProperty('volume', 0.9)  # éŸ³é‡
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        engine.save_to_file(text, out_path)
        engine.runAndWait()
        
        # ç­‰å¾…æ–‡ä»¶ç”Ÿæˆ
        time.sleep(1)
        
        if os.path.exists(out_path) and os.path.getsize(out_path) > 0:
            return out_path
        else:
            if os.path.exists(out_path):
                os.unlink(out_path)
            return None
    except Exception as e:
        st.error(f"pyttsx3 TTSç”Ÿæˆå¤±è´¥: {e}")
        if os.path.exists(out_path):
            os.unlink(out_path)
        return None

# gTTS (Google TTS)
def generate_gtts_audio(text, lang='en', out_path=None):
    if not GTTS_AVAILABLE:
        return None
    
    if out_path is None:
        fd, out_path = tempfile.mkstemp(suffix='.mp3')
        os.close(fd)
    
    try:
        tts = gTTS(text=text, lang=lang, slow=False)
        tts.save(out_path)
        
        if os.path.exists(out_path) and os.path.getsize(out_path) > 0:
            return out_path
        else:
            if os.path.exists(out_path):
                os.unlink(out_path)
            return None
    except Exception as e:
        st.error(f"gTTSç”Ÿæˆå¤±è´¥: {e}")
        if os.path.exists(out_path):
            os.unlink(out_path)
        return None

# ç»Ÿä¸€çš„TTSç”Ÿæˆå‡½æ•°
def generate_audio_with_fallback(text, voice_info, tts_method, speed=1.0):
    """ä½¿ç”¨å¤šç§TTSæ–¹æ³•ç”ŸæˆéŸ³é¢‘ï¼Œæœ‰å¤‡ç”¨æ–¹æ¡ˆ"""
    
    # æ ¹æ®è¯­éŸ³ç±»å‹åˆ¤æ–­è¯­è¨€
    if "Chinese" in voice_info or "zh-" in voice_info:
        lang = 'zh'
    else:
        lang = 'en'
    
    out_path = tempfile.mktemp(suffix='.mp3')
    
    # æ ¹æ®é€‰æ‹©çš„TTSæ–¹æ³•ç”ŸæˆéŸ³é¢‘
    if tts_method == "edge_tts" and EDGE_TTS_AVAILABLE:
        result = generate_edge_audio(text, voice_info, speed, out_path)
        if result:
            return result
    
    if tts_method == "pyttsx3" and PYTTSX3_AVAILABLE:
        result = generate_pyttsx3_audio(text, out_path)
        if result:
            return result
    
    if tts_method == "gtts" and GTTS_AVAILABLE:
        result = generate_gtts_audio(text, lang, out_path)
        if result:
            return result
    
    # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•å…¶ä»–å¯ç”¨æ–¹æ³•
    if EDGE_TTS_AVAILABLE and tts_method != "edge_tts":
        result = generate_edge_audio(text, voice_info, speed, out_path)
        if result:
            return result
    
    if PYTTSX3_AVAILABLE and tts_method != "pyttsx3":
        result = generate_pyttsx3_audio(text, out_path)
        if result:
            return result
    
    if GTTS_AVAILABLE and tts_method != "gtts":
        result = generate_gtts_audio(text, lang, out_path)
        if result:
            return result
    
    # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
    return None

# -----------------------
# éŸ³é¢‘å¤„ç†å‡½æ•°
# -----------------------
def create_silent_audio(duration, output_path):
    """åˆ›å»ºé™éŸ³éŸ³é¢‘æ–‡ä»¶"""
    cmd = [
        "ffmpeg", "-y", "-f", "lavfi", "-i", "anullsrc=r=44100:cl=stereo",
        "-t", str(duration), "-acodec", "libmp3lame", output_path
    ]
    try:
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        return os.path.exists(output_path) and os.path.getsize(output_path) > 0
    except Exception as e:
        return False

def merge_audio_files(audio_paths, per_duration, pause_duration, output_path):
    """åˆå¹¶éŸ³é¢‘æ–‡ä»¶"""
    if not check_ffmpeg():
        return None
    
    with tempfile.TemporaryDirectory() as tmpdir:
        list_file = os.path.join(tmpdir, "audio_list.txt")
        
        valid_files = []
        
        with open(list_file, 'w') as f:
            for i, audio_path in enumerate(audio_paths):
                if audio_path and os.path.exists(audio_path) and os.path.getsize(audio_path) > 0:
                    f.write(f"file '{audio_path}'\n")
                    valid_files.append(audio_path)
                    
                    if i < len(audio_paths) - 1 and pause_duration > 0:
                        pause_audio = os.path.join(tmpdir, f"pause_{i}.mp3")
                        if create_silent_audio(pause_duration, pause_audio):
                            f.write(f"file '{pause_audio}'\n")
                            valid_files.append(pause_audio)
                else:
                    silent_audio = os.path.join(tmpdir, f"silent_{i}.mp3")
                    if create_silent_audio(per_duration, silent_audio):
                        f.write(f"file '{silent_audio}'\n")
                        valid_files.append(silent_audio)
        
        if not valid_files:
            return None
            
        cmd = [
            "ffmpeg", "-y", "-f", "concat", "-safe", "0",
            "-i", list_file, "-c", "copy", output_path
        ]
        
        try:
            result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
            if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                return output_path
            else:
                return None
        except Exception:
            return None

def merge_video_audio(video_path, audio_path, output_path):
    """åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘"""
    if not check_ffmpeg():
        return None
        
    if not os.path.exists(video_path) or not os.path.exists(audio_path):
        return None
        
    cmd = [
        "ffmpeg", "-y",
        "-i", video_path,
        "-i", audio_path,
        "-c:v", "copy",
        "-c:a", "aac",
        "-strict", "experimental",
        "-shortest",
        output_path
    ]
    
    try:
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        if result.returncode == 0 and os.path.exists(output_path) and os.path.getsize(output_path) > 0:
            return output_path
        else:
            return None
    except Exception:
        return None

# -----------------------
# è§†é¢‘ç”Ÿæˆå‡½æ•°
# -----------------------
def generate_video_with_optimization(df, settings, progress_bar, status_placeholder):
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            video_no_audio = os.path.join(tmpdir, "video_no_audio.mp4")
            final_video = os.path.join(tmpdir, "final_video.mp4")
            
            width = settings['width']
            height = settings['height']
            fps = settings['fps']
            per_duration = settings['per_duration']
            pause_duration = settings['pause_duration']
            bg_color = settings['bg_color']
            bg_image = settings['bg_image']
            eng_color = settings['eng_color']
            chn_color = settings['chn_color']
            pho_color = settings['pho_color']
            eng_size = settings['eng_size']
            chn_size = settings['chn_size']
            pho_size = settings['pho_size']
            text_bg_enabled = settings['text_bg_enabled']
            text_bg_color = settings['text_bg_color']
            text_bg_padding = settings['text_bg_padding']
            text_bg_radius = settings['text_bg_radius']
            text_bg_width = settings['text_bg_width']
            text_bg_height = settings['text_bg_height']
            bold_text = settings['bold_text']
            segment_order = settings['segment_order']
            voice_mapping = settings['voice_mapping']
            tts_speed = settings['tts_speed']
            tts_method = settings['tts_method']
            eng_pho_spacing = settings['eng_pho_spacing']
            pho_chn_spacing = settings['pho_chn_spacing']
            line_spacing = settings['line_spacing']
            
            per_duration_frames = int(round(per_duration * fps))
            pause_duration_frames = int(round(pause_duration * fps))
            
            total_segments = len(df) * len(segment_order)
            total_frames = total_segments * per_duration_frames + (total_segments - 1) * pause_duration_frames
            current_frame = 0
            
            writer = None
            audio_paths = []
            
            try:
                # ç”ŸæˆéŸ³é¢‘
                status_placeholder.info("ğŸµ æ­£åœ¨ç”ŸæˆéŸ³é¢‘...")
                audio_count = 0
                total_audio_count = len(df) * len(segment_order)
                
                for i, row in df.iterrows():
                    eng = str(row['è‹±è¯­'])
                    chn = str(row['ä¸­æ–‡'])
                    
                    for j, segment_type in enumerate(segment_order):
                        voice_info, text_type = voice_mapping[segment_type]
                        text_to_speak = eng if text_type == "english" else chn
                        
                        # ä½¿ç”¨ç»Ÿä¸€çš„TTSç”Ÿæˆå‡½æ•°
                        audio_file = generate_audio_with_fallback(text_to_speak, voice_info, tts_method, tts_speed)
                        
                        if audio_file and os.path.exists(audio_file) and os.path.getsize(audio_file) > 0:
                            audio_paths.append(audio_file)
                            st.success(f"âœ… éŸ³é¢‘ {audio_count+1}/{total_audio_count} ç”ŸæˆæˆåŠŸ")
                        else:
                            # ç”Ÿæˆå¤±è´¥æ—¶ä½¿ç”¨é™éŸ³
                            silent_audio = os.path.join(tmpdir, f"silent_{i}_{j}.mp3")
                            if create_silent_audio(per_duration, silent_audio):
                                audio_paths.append(silent_audio)
                                st.warning(f"âš ï¸ éŸ³é¢‘ {audio_count+1}/{total_audio_count} ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é™éŸ³æ›¿ä»£")
                            else:
                                audio_paths.append(None)
                        
                        audio_count += 1
                        audio_progress = audio_count / total_audio_count * 0.4
                        progress_bar.progress(audio_progress)
                
                # ç”Ÿæˆè§†é¢‘å¸§
                status_placeholder.info("ğŸ¬ æ­£åœ¨ç”Ÿæˆè§†é¢‘...")
                writer = imageio.get_writer(video_no_audio, fps=fps, macro_block_size=1, format='FFMPEG', codec='libx264')
                
                for i, row in df.iterrows():
                    eng = str(row['è‹±è¯­'])
                    chn = str(row['ä¸­æ–‡'])
                    pho = str(row['éŸ³æ ‡']) if pd.notna(row['éŸ³æ ‡']) else ""
                    
                    frame_img = create_frame(
                        english=eng, chinese=chn, phonetic=pho,
                        width=width, height=height,
                        bg_color=bg_color, bg_image=bg_image,
                        eng_color=eng_color, chn_color=chn_color, pho_color=pho_color,
                        eng_size=eng_size, chn_size=chn_size, pho_size=pho_size,
                        text_bg_enabled=text_bg_enabled,
                        text_bg_color=text_bg_color,
                        text_bg_padding=text_bg_padding,
                        text_bg_radius=text_bg_radius,
                        text_bg_width=text_bg_width,
                        text_bg_height=text_bg_height,
                        bold_text=bold_text,
                        eng_pho_spacing=eng_pho_spacing,
                        pho_chn_spacing=pho_chn_spacing,
                        line_spacing=line_spacing
                    )
                    
                    frame_array = np.array(frame_img.convert('RGB'))
                    
                    for segment_idx in range(len(segment_order)):
                        for _ in range(per_duration_frames):
                            writer.append_data(frame_array)
                            current_frame += 1
                            if current_frame % 10 == 0:
                                video_progress = 0.4 + 0.4 * (current_frame / total_frames)
                                progress_bar.progress(min(video_progress, 0.8))
                        
                        if not (i == len(df) - 1 and segment_idx == len(segment_order) - 1):
                            for _ in range(pause_duration_frames):
                                writer.append_data(frame_array)
                                current_frame += 1
                                if current_frame % 10 == 0:
                                    video_progress = 0.4 + 0.4 * (current_frame / total_frames)
                                    progress_bar.progress(min(video_progress, 0.8))
            
            except Exception as e:
                st.error(f"ç”Ÿæˆè§†é¢‘è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                return None
            finally:
                if writer is not None:
                    writer.close()
            
            if not os.path.exists(video_no_audio) or os.path.getsize(video_no_audio) == 0:
                st.error("æ— å£°è§†é¢‘ç”Ÿæˆå¤±è´¥")
                return None
            
            # åˆå¹¶éŸ³é¢‘
            status_placeholder.info("ğŸ”Š æ­£åœ¨åˆå¹¶éŸ³é¢‘...")
            progress_bar.progress(0.85)
            
            valid_audio_paths = [p for p in audio_paths if p is not None and os.path.exists(p) and os.path.getsize(p) > 0]
            
            if valid_audio_paths and check_ffmpeg():
                st.info(f"æ‰¾åˆ° {len(valid_audio_paths)}/{len(audio_paths)} ä¸ªæœ‰æ•ˆéŸ³é¢‘æ–‡ä»¶")
                
                combined_audio_path = os.path.join(tmpdir, "combined_audio.mp3")
                merged_audio = merge_audio_files(valid_audio_paths, per_duration, pause_duration, combined_audio_path)
                
                if merged_audio and os.path.exists(merged_audio) and os.path.getsize(merged_audio) > 0:
                    status_placeholder.info("ğŸµ æ­£åœ¨åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘...")
                    progress_bar.progress(0.95)
                    
                    merged_video = merge_video_audio(video_no_audio, merged_audio, final_video)
                    if merged_video:
                        final_video = merged_video
                        progress_bar.progress(1.0)
                        st.success("âœ… è§†é¢‘å’ŒéŸ³é¢‘åˆå¹¶æˆåŠŸï¼")
                    else:
                        st.warning("è§†é¢‘éŸ³é¢‘åˆå¹¶å¤±è´¥ï¼Œå°†ä½¿ç”¨æ— å£°è§†é¢‘")
                        final_video = video_no_audio
                else:
                    st.warning("éŸ³é¢‘åˆå¹¶å¤±è´¥ï¼Œå°†ä½¿ç”¨æ— å£°è§†é¢‘")
                    final_video = video_no_audio
            else:
                st.warning("æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶ï¼Œå°†ä½¿ç”¨æ— å£°è§†é¢‘")
                final_video = video_no_audio
            
            if os.path.exists(final_video) and os.path.getsize(final_video) > 0:
                with open(final_video, "rb") as f:
                    video_bytes = f.read()
                return video_bytes
            else:
                st.error("ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º")
                return None
                
    except Exception as e:
        st.error(f"ç”Ÿæˆå¤±è´¥: {e}")
        return None

# -----------------------
# UI ä¸ä¸»æµç¨‹
# -----------------------
st.markdown('<h1 class="main-header">ğŸ¬ æ—…è¡Œè‹±è¯­è§†é¢‘ç”Ÿæˆå™¨</h1>', unsafe_allow_html=True)
st.markdown("### å¤šéŸ³è‰²å¾ªç¯æ’­æ”¾ â€¢ ä¸“ä¸šçº§è§†é¢‘åˆ¶ä½œ")

# ç³»ç»Ÿæ£€æŸ¥
with st.sidebar:
    st.markdown("## ğŸ”§ ç³»ç»Ÿæ£€æŸ¥")
    ffmpeg_available = check_ffmpeg()
    
    st.markdown("## ğŸµ TTS æœåŠ¡çŠ¶æ€")
    if EDGE_TTS_AVAILABLE:
        st.success("âœ… Edge TTS å¯ç”¨")
    else:
        st.error("âŒ Edge TTS ä¸å¯ç”¨")
    
    if PYTTSX3_AVAILABLE:
        st.success("âœ… pyttsx3 (ç¦»çº¿) å¯ç”¨")
    else:
        st.warning("âš ï¸ pyttsx3 ä¸å¯ç”¨")
    
    if GTTS_AVAILABLE:
        st.success("âœ… gTTS (Google) å¯ç”¨")
    else:
        st.warning("âš ï¸ gTTS ä¸å¯ç”¨")

# ä¸Šä¼  Excel
st.markdown('<div class="section-header">ğŸ“ 1. ä¸Šä¼ æ•°æ®æ–‡ä»¶</div>', unsafe_allow_html=True)

uploaded = st.file_uploader(
    "é€‰æ‹© Excel æ–‡ä»¶",
    type=["xlsx", "xls"],
    help="å¿…é¡»åŒ…å«åˆ—ï¼šè‹±è¯­ã€ä¸­æ–‡ã€éŸ³æ ‡",
    key="excel_uploader"
)

if uploaded:
    try:
        df = pd.read_excel(uploaded)
    except Exception as e:
        st.error(f"è¯»å– Excel å¤±è´¥ï¼š{e}")
        df = None
else:
    df = None

if df is not None:
    required = ['è‹±è¯­','ä¸­æ–‡','éŸ³æ ‡']
    miss = [c for c in required if c not in df.columns]
    if miss:
        st.error(f"Excel ç¼ºå°‘åˆ—ï¼š{', '.join(miss)}")
        st.stop()
    
    # æ•°æ®é¢„è§ˆ
    st.markdown('<div class="preview-section">', unsafe_allow_html=True)
    st.subheader("ğŸ“Š æ•°æ®é¢„è§ˆ")
    st.dataframe(df.head(10), height=220, use_container_width=True)
    st.info(f"ğŸ“ˆ å…± {len(df)} è¡Œæ•°æ®ï¼Œé¢„è®¡ç”Ÿæˆ {len(df) * 4} æ®µéŸ³é¢‘")
    st.markdown('</div>', unsafe_allow_html=True)

    # è®¾ç½®é¢æ¿
    st.markdown('<div class="section-header">ğŸ¨ 2. è‡ªå®šä¹‰è®¾ç½®</div>', unsafe_allow_html=True)
    
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ¨ æ ·å¼è®¾ç½®", "ğŸ”Š éŸ³é¢‘è®¾ç½®", "ğŸ“ æ–‡å­—èƒŒæ™¯", "âš™ï¸ è§†é¢‘å‚æ•°"])
    
    with tab1:
        col_bg, col_txt = st.columns([1, 2])
        
        with col_bg:
            st.subheader("ğŸ¨ èƒŒæ™¯è®¾ç½®")
            bg_type = st.radio("èƒŒæ™¯ç±»å‹", ["çº¯è‰²", "å›¾ç‰‡"], horizontal=True, key="bg_type")
            if bg_type == "çº¯è‰²":
                bg_hex = st.color_picker("èƒŒæ™¯é¢œè‰²", "#000000", key="bg_color_picker")
                bg_color = tuple(int(bg_hex[i:i+2],16) for i in (1,3,5))
                st.session_state.bg_image = None
            else:
                bg_file = st.file_uploader("ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡", type=["jpg","jpeg","png"], key="bg_image_uploader")
                if bg_file:
                    try:
                        st.session_state.bg_image = Image.open(bg_file)
                        st.image(st.session_state.bg_image, caption="èƒŒæ™¯é¢„è§ˆ", use_container_width=True)
                    except Exception as e:
                        st.error(f"æ‰“å¼€èƒŒæ™¯å›¾ç‰‡å¤±è´¥ï¼š{e}")
                        st.session_state.bg_image = None
                bg_color = (0,0,0)

        with col_txt:
            st.subheader("ğŸ“ æ–‡å­—æ ·å¼")
            c1, c2, c3 = st.columns(3)
            with c1:
                st.markdown("**è‹±è¯­è®¾ç½®**")
                eng_color = st.color_picker("é¢œè‰²", "#FFFFFF", key="eng_color")
                eng_color = tuple(int(eng_color[i:i+2],16) for i in (1,3,5))
                eng_size = st.slider("å­—å·", 20, 120, 80, key="eng_size")
            with c2:
                st.markdown("**éŸ³æ ‡è®¾ç½®**")
                pho_color = st.color_picker("é¢œè‰²", "#FFFF00", key="pho_color")
                pho_color = tuple(int(pho_color[i:i+2],16) for i in (1,3,5))
                pho_size = st.slider("å­—å·", 16, 100, 50, key="pho_size")
            with c3:
                st.markdown("**ä¸­æ–‡è®¾ç½®**")
                chn_color = st.color_picker("é¢œè‰²", "#ADD8E6", key="chn_color")
                chn_color = tuple(int(chn_color[i:i+2],16) for i in (1,3,5))
                chn_size = st.slider("å­—å·", 20, 120, 60, key="chn_size")
            
            bold_text = st.checkbox("æ–‡å­—åŠ ç²—", value=True, key="bold_text")
            
            st.markdown("---")
            st.subheader("ğŸ“ æ–‡å­—é—´è·è®¾ç½®")
            col_spacing1, col_spacing2, col_spacing3 = st.columns(3)
            with col_spacing1:
                eng_pho_spacing = st.slider("è‹±è¯­-éŸ³æ ‡é—´è·", 10, 100, 30, key="eng_pho_spacing")
            with col_spacing2:
                pho_chn_spacing = st.slider("éŸ³æ ‡-ä¸­æ–‡é—´è·", 10, 100, 50, key="pho_chn_spacing")
            with col_spacing3:
                line_spacing = st.slider("è¡Œå†…é—´è·", 5, 50, 15, key="line_spacing")

    with tab2:
        st.subheader("ğŸ”Š TTS æœåŠ¡é€‰æ‹©")
        
        # TTSæ–¹æ³•é€‰æ‹©
        tts_options = []
        if EDGE_TTS_AVAILABLE:
            tts_options.append("Edge TTS (æ¨è)")
        if PYTTSX3_AVAILABLE:
            tts_options.append("pyttsx3 (ç¦»çº¿)")
        if GTTS_AVAILABLE:
            tts_options.append("gTTS (Google)")
        
        if not tts_options:
            st.error("âŒ æ²¡æœ‰å¯ç”¨çš„TTSæœåŠ¡ï¼Œè¯·å®‰è£…è‡³å°‘ä¸€ä¸ªTTSåº“")
            st.stop()
        
        tts_method_display = st.selectbox(
            "é€‰æ‹©TTSæœåŠ¡",
            tts_options,
            key="tts_method_display"
        )
        
        # æ˜ å°„æ˜¾ç¤ºåç§°åˆ°å†…éƒ¨åç§°
        tts_method_mapping = {
            "Edge TTS (æ¨è)": "edge_tts",
            "pyttsx3 (ç¦»çº¿)": "pyttsx3", 
            "gTTS (Google)": "gtts"
        }
        tts_method = tts_method_mapping[tts_method_display]
        st.session_state.tts_method = tts_method
        
        st.subheader("ğŸµ æ’­æ”¾é¡ºåºè®¾ç½®")
        
        col_order1, col_order2, col_order3, col_order4 = st.columns(4)
        with col_order1:
            segment1_type = st.selectbox("ç¬¬1æ®µ", ["è‹±æ–‡ç”·å£°", "è‹±æ–‡å¥³å£°", "ä¸­æ–‡éŸ³è‰²"], index=0, key="segment1")
        with col_order2:
            segment2_type = st.selectbox("ç¬¬2æ®µ", ["è‹±æ–‡ç”·å£°", "è‹±æ–‡å¥³å£°", "ä¸­æ–‡éŸ³è‰²"], index=1, key="segment2")
        with col_order3:
            segment3_type = st.selectbox("ç¬¬3æ®µ", ["è‹±æ–‡ç”·å£°", "è‹±æ–‡å¥³å£°", "ä¸­æ–‡éŸ³è‰²"], index=2, key="segment3")
        with col_order4:
            segment4_type = st.selectbox("ç¬¬4æ®µ", ["è‹±æ–‡ç”·å£°", "è‹±æ–‡å¥³å£°", "ä¸­æ–‡éŸ³è‰²"], index=0, key="segment4")
        
        st.markdown(f'<div class="success-card">ğŸµ æ’­æ”¾é¡ºåºï¼š{segment1_type} â†’ {segment2_type} â†’ {segment3_type} â†’ {segment4_type}</div>', unsafe_allow_html=True)

        st.subheader("ğŸ™ï¸ éŸ³è‰²é€‰æ‹©")
        
        col_voice1, col_voice2, col_voice3 = st.columns(3)
        
        with col_voice1:
            st.markdown("**è‹±æ–‡ç”·å£°**")
            male_english_voices = {k:v for k,v in VOICE_OPTIONS.items() if "Male" in k and "English" in k}
            male_english_label = st.selectbox("é€‰æ‹©ç”·å£°éŸ³è‰²", list(male_english_voices.keys()), index=0, key="male_voice")
            male_english_voice = male_english_voices[male_english_label]

        with col_voice2:
            st.markdown("**è‹±æ–‡å¥³å£°**")
            female_english_voices = {k:v for k,v in VOICE_OPTIONS.items() if "Female" in k and "English" in k}
            female_english_label = st.selectbox("é€‰æ‹©å¥³å£°éŸ³è‰²", list(female_english_voices.keys()), index=0, key="female_voice")
            female_english_voice = female_english_voices[female_english_label]

        with col_voice3:
            st.markdown("**ä¸­æ–‡éŸ³è‰²**")
            chinese_voices = {k:v for k,v in VOICE_OPTIONS.items() if "Chinese" in k}
            chinese_label = st.selectbox("é€‰æ‹©ä¸­æ–‡éŸ³è‰²", list(chinese_voices.keys()), index=0, key="chinese_voice")
            chinese_voice = chinese_voices[chinese_label]

        col_speed, col_pause = st.columns(2)
        with col_speed:
            tts_speed = st.slider("è¯­é€Ÿè°ƒèŠ‚", 0.5, 2.0, 1.0, 0.1, key="tts_speed")
            st.info(f"å½“å‰è¯­é€Ÿ: {tts_speed}x")
        with col_pause:
            pause_duration = st.slider("æ¯ç»„åœé¡¿æ—¶é—´ï¼ˆç§’ï¼‰", 0.0, 3.0, 0.5, 0.1, key="pause_duration")

    with tab3:
        st.subheader("ğŸ–¼ï¸ æ–‡å­—èƒŒæ™¯åŒºåŸŸ")
        text_bg_enabled = st.checkbox("å¯ç”¨æ–‡å­—èƒŒæ™¯åŒºåŸŸ", value=True, key="text_bg_enabled")
        if text_bg_enabled:
            col_bg_size1, col_bg_size2 = st.columns(2)
            with col_bg_size1:
                text_bg_width = st.slider("æ–‡å­—èƒŒæ™¯å®½åº¦", 520, 1600, 1000, key="text_bg_width")
            with col_bg_size2:
                text_bg_height = st.slider("æ–‡å­—èƒŒæ™¯é«˜åº¦", 200, 800, 400, key="text_bg_height")
                
            text_bg_hex = st.color_picker("æ–‡å­—èƒŒæ™¯é¢œè‰²", "#FFFFFF", key="text_bg_color")
            text_bg_rgb = tuple(int(text_bg_hex[i:i+2],16) for i in (1,3,5))
            text_bg_alpha = st.slider("æ–‡å­—èƒŒæ™¯é€æ˜åº¦", 0, 255, 180, key="text_bg_alpha")
            text_bg_color = text_bg_rgb + (text_bg_alpha,)
            text_bg_padding = st.slider("æ–‡å­—èƒŒæ™¯å†…è¾¹è·", 10, 50, 20, key="text_bg_padding")
            text_bg_radius = st.slider("æ–‡å­—èƒŒæ™¯åœ†è§’", 0, 50, 30, key="text_bg_radius")
        else:
            text_bg_color = (255,255,255,180)
            text_bg_padding = 20
            text_bg_radius = 30
            text_bg_width = None
            text_bg_height = None

    with tab4:
        st.subheader("âš™ï¸ è§†é¢‘å‚æ•°")
        col_v1, col_v2 = st.columns(2)
        with col_v1:
            per_duration = st.slider("æ¯æ®µéŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰", 2, 8, 4, key="per_duration")
            fps = st.slider("å¸§ç‡", 8, 30, 20, key="fps")
        with col_v2:
            width = st.selectbox("åˆ†è¾¨ç‡å®½åº¦", [640, 960, 1280, 1920], index=3, key="width")
            height = int(width * 9 / 16)
            st.info(f"åˆ†è¾¨ç‡: {width} Ã— {height}")

    # é¢„è§ˆå•è¡Œ
    st.markdown('<div class="section-header">ğŸ‘ï¸ 3. é¢„è§ˆæ•ˆæœ</div>', unsafe_allow_html=True)
    
    if not df.empty:
        st.markdown('<div class="preview-section">', unsafe_allow_html=True)
        col_preview1, col_preview2 = st.columns([1, 2])
        
        with col_preview1:
            idx = st.slider("é€‰æ‹©é¢„è§ˆè¡Œ", 0, min(len(df)-1, 9), 0, key="preview_row")
            row = df.iloc[idx]
            st.write(f"**è‹±è¯­:** {row['è‹±è¯­']}")
            st.write(f"**éŸ³æ ‡:** {row['éŸ³æ ‡'] if pd.notna(row['éŸ³æ ‡']) else 'æ— '}")
            st.write(f"**ä¸­æ–‡:** {row['ä¸­æ–‡']}")
        
        with col_preview2:
            preview_img = create_frame(
                english=str(row['è‹±è¯­']),
                chinese=str(row['ä¸­æ–‡']),
                phonetic=str(row['éŸ³æ ‡']) if pd.notna(row['éŸ³æ ‡']) else "",
                width=width, height=height,
                bg_color=bg_color, bg_image=st.session_state.bg_image,
                eng_color=eng_color, chn_color=chn_color, pho_color=pho_color,
                eng_size=eng_size, chn_size=chn_size, pho_size=pho_size,
                text_bg_enabled=text_bg_enabled,
                text_bg_color=text_bg_color,
                text_bg_padding=text_bg_padding,
                text_bg_radius=text_bg_radius,
                text_bg_width=text_bg_width,
                text_bg_height=text_bg_height,
                bold_text=bold_text,
                eng_pho_spacing=eng_pho_spacing,
                pho_chn_spacing=pho_chn_spacing,
                line_spacing=line_spacing
            )
            st.image(preview_img, caption="å¸§é¢„è§ˆ", use_container_width=True)
        st.markdown('</div>', unsafe_allow_html=True)

    # ç”ŸæˆæŒ‰é’®
    st.markdown('<div class="section-header">ğŸš€ 4. ç”Ÿæˆè§†é¢‘</div>', unsafe_allow_html=True)
    
    if len(df) > 20:
        st.markdown(f'<div class="warning-card">âš ï¸ æ•°æ®é‡è¾ƒå¤§ï¼ˆ{len(df)} è¡Œï¼‰ï¼Œç”Ÿæˆå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ã€‚å»ºè®®åˆ†æ‰¹å¤„ç†æˆ–å‡å°‘æ¯æ®µéŸ³é¢‘æ—¶é•¿ã€‚</div>', unsafe_allow_html=True)
    
    col_gen1, col_gen2, col_gen3 = st.columns([1, 2, 1])
    with col_gen2:
        if st.button("ğŸ¬ å¼€å§‹ç”Ÿæˆè§†é¢‘", use_container_width=True, key="generate_button"):
            status_placeholder = st.empty()
            progress_bar = st.progress(0)
            
            with st.spinner("ğŸ¥ æ­£åœ¨ç”Ÿæˆè§†é¢‘..."):
                voice_mapping = {
                    "è‹±æ–‡ç”·å£°": (male_english_voice, "english"),
                    "è‹±æ–‡å¥³å£°": (female_english_voice, "english"), 
                    "ä¸­æ–‡éŸ³è‰²": (chinese_voice, "chinese")
                }
                
                segment_order = [segment1_type, segment2_type, segment3_type, segment4_type]
                
                settings = {
                    'width': width,
                    'height': height,
                    'fps': fps,
                    'per_duration': per_duration,
                    'pause_duration': pause_duration,
                    'bg_color': bg_color,
                    'bg_image': st.session_state.bg_image,
                    'eng_color': eng_color,
                    'chn_color': chn_color,
                    'pho_color': pho_color,
                    'eng_size': eng_size,
                    'chn_size': chn_size,
                    'pho_size': pho_size,
                    'text_bg_enabled': text_bg_enabled,
                    'text_bg_color': text_bg_color,
                    'text_bg_padding': text_bg_padding,
                    'text_bg_radius': text_bg_radius,
                    'text_bg_width': text_bg_width,
                    'text_bg_height': text_bg_height,
                    'bold_text': bold_text,
                    'segment_order': segment_order,
                    'voice_mapping': voice_mapping,
                    'tts_speed': tts_speed,
                    'tts_method': st.session_state.tts_method,
                    'eng_pho_spacing': eng_pho_spacing,
                    'pho_chn_spacing': pho_chn_spacing,
                    'line_spacing': line_spacing
                }
                
                video_bytes = generate_video_with_optimization(df, settings, progress_bar, status_placeholder)
                
                if video_bytes:
                    status_placeholder.success("âœ… è§†é¢‘ç”Ÿæˆå®Œæˆï¼")
                    
                    col_vid1, col_vid2, col_vid3 = st.columns([1, 2, 1])
                    with col_vid2:
                        st.video(video_bytes)
                        
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½è§†é¢‘",
                            data=video_bytes,
                            file_name="travel_english_video.mp4",
                            mime="video/mp4",
                            use_container_width=True,
                            key="download_button"
                        )
                else:
                    status_placeholder.error("è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®æˆ–é‡è¯•")

# ä¾§è¾¹æ ä¿¡æ¯
with st.sidebar:
    st.markdown("## â„¹ï¸ ä½¿ç”¨æŒ‡å—")
    
    with st.expander("ğŸ“ æ•°æ®æ ¼å¼è¦æ±‚", expanded=True):
        st.markdown("""
        Excel æ–‡ä»¶å¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—ï¼š
        - **è‹±è¯­**: è‹±æ–‡å¥å­
        - **ä¸­æ–‡**: ä¸­æ–‡ç¿»è¯‘  
        - **éŸ³æ ‡**: éŸ³æ ‡æ ‡æ³¨ï¼ˆå¯é€‰ï¼‰
        """)
    
    with st.expander("ğŸµ TTS æœåŠ¡è¯´æ˜"):
        st.markdown("""
        - **Edge TTS**: å¾®è½¯åœ¨çº¿æœåŠ¡ï¼ŒéŸ³è´¨å¥½ä½†éœ€è¦ç½‘ç»œ
        - **pyttsx3**: ç¦»çº¿æœåŠ¡ï¼Œç¨³å®šä½†éŸ³è´¨ä¸€èˆ¬
        - **gTTS**: Googleåœ¨çº¿æœåŠ¡ï¼Œéœ€è¦ç½‘ç»œ
        """)
    
    with st.expander("âš™ï¸ ç³»ç»Ÿè¦æ±‚"):
        st.markdown("""
        - **FFmpeg**: å¿…é¡»å®‰è£…
        - **ç½‘ç»œ**: åœ¨çº¿TTSæœåŠ¡éœ€è¦è”ç½‘
        - **æµè§ˆå™¨**: å»ºè®®ä½¿ç”¨ Chrome/Firefox
        - **æ•°æ®é‡**: å»ºè®®æ¯æ¬¡ä¸è¶…è¿‡50è¡Œ
        """)

# é¡µè„š
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: #666;'>"
    "ğŸ¬ æ—…è¡Œè‹±è¯­è§†é¢‘ç”Ÿæˆå™¨ | å¤šTTSæœåŠ¡æ”¯æŒ"
    "</div>", 
    unsafe_allow_html=True
)

# éšè— Streamlit é»˜è®¤èœå•å’Œé¡µè„š
hide_streamlit_style = """
<style>
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
.stDeployButton {display:none;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)
