import streamlit as st
import pandas as pd
import numpy as np
import os
import tempfile
import subprocess
import shutil
import traceback
import asyncio
import imageio.v2 as imageio
from PIL import Image, ImageDraw, ImageFont, ImageOps
import requests
import time

# -------------------- é¡µé¢è®¾ç½® --------------------
st.set_page_config(page_title="æ—…è¡Œè‹±è¯­è§†é¢‘ç”Ÿæˆå™¨ï¼ˆæ¨¡å¼Bç¦»çº¿ç‰ˆï¼‰", page_icon="ğŸ¬", layout="wide")

st.markdown("""
<style>
    .main-header {
        font-size: 2.3rem;
        font-weight: 700;
        color: #334155;
        text-align: center;
        margin-bottom: 1rem;
    }
    .stProgress > div > div > div > div {
        background-color: #6366F1;
    }
    div[data-testid="stFileUploader"] section {
        background-color: #F8FAFC;
        border-radius: 10px;
        padding: 10px;
    }
</style>
""", unsafe_allow_html=True)

st.markdown("<div class='main-header'>ğŸ¬ æ—…è¡Œè‹±è¯­è§†é¢‘ç”Ÿæˆå™¨ â€” ç¦»çº¿æ¨¡å¼Bï¼ˆæ¯è¡Œç‹¬ç«‹æ‹¼æ¥ï¼‰</div>", unsafe_allow_html=True)
st.info("ğŸ’¡ ä¸Šä¼  Excelï¼ˆåŒ…å«åˆ—ï¼šè‹±è¯­ã€ä¸­æ–‡ã€éŸ³æ ‡ï¼‰ï¼Œå¹¶ä¸Šä¼ ç¦»çº¿éŸ³é¢‘æ–‡ä»¶ï¼Œå¦‚ 1-1.mp3ã€1-2.mp3ã€1-3.mp3ã€1-4.mp3ã€‚")

# -------------------- åŠ è½½ ffmpeg --------------------
def check_ffmpeg():
    return shutil.which("ffmpeg") is not None

# -------------------- åŠ è½½ edge-ttsï¼ˆç”¨äºè¯•å¬ï¼‰ --------------------
try:
    import edge_tts
    EDGE_TTS_AVAILABLE = True
except Exception:
    EDGE_TTS_AVAILABLE = False

# -------------------- å·¥å…·å‡½æ•° --------------------
def wrap_text(text, max_chars):
    if not text or str(text).strip().lower() == 'nan':
        return [""]
    text = str(text).strip()
    if any('\u4e00' <= c <= '\u9fff' for c in text):
        max_chars = min(max_chars, 15)
    words = text.split()
    lines, current = [], []
    for word in words:
        test_line = ' '.join(current + [word])
        if len(test_line) <= max_chars:
            current.append(word)
        else:
            if current:
                lines.append(' '.join(current))
            if len(word) > max_chars:
                for i in range(0, len(word), max_chars):
                    lines.append(word[i:i+max_chars])
                current = []
            else:
                current = [word]
    if current:
        lines.append(' '.join(current))
    return lines


def get_font(size, bold=False):
    choices = [
        "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
        "/usr/share/fonts/truetype/freefont/FreeSans.ttf",
        "arial.ttf"
    ]
    for f in choices:
        try:
            return ImageFont.truetype(f, size)
        except:
            continue
    return ImageFont.load_default()


def create_frame(english, chinese, phonetic, width=1920, height=1080,
                 bg_color=(10,10,10), bg_image=None,
                 eng_color=(255,255,255), chn_color=(180,220,255), pho_color=(255,240,120),
                 eng_size=80, chn_size=60, pho_size=50,
                 text_bg_enabled=True, text_bg_color=(255,255,255,180), text_bg_padding=20,
                 text_bg_radius=30, bold_text=True):

    if bg_image:
        try:
            img = ImageOps.fit(bg_image.convert('RGB'), (width, height), Image.Resampling.LANCZOS)
        except Exception:
            img = Image.new('RGB', (width, height), bg_color)
    else:
        img = Image.new('RGB', (width, height), bg_color)

    draw = ImageDraw.Draw(img)
    eng_font = get_font(eng_size)
    chn_font = get_font(chn_size)
    pho_font = get_font(pho_size)

    lines = wrap_text(english, 40)
    total_height = sum(draw.textbbox((0,0), line, font=eng_font)[3] for line in lines)
    total_height += 150

    y = (height - total_height)//2
    for line in lines:
        w = draw.textlength(line, font=eng_font)
        x = (width - w)//2
        draw.text((x, y), line, font=eng_font, fill=eng_color)
        y += eng_size + 15

    if phonetic:
        w = draw.textlength(phonetic, font=pho_font)
        x = (width - w)//2
        draw.text((x, y), phonetic, font=pho_font, fill=pho_color)
        y += pho_size + 20

    lines = wrap_text(chinese, 20)
    for line in lines:
        w = draw.textlength(line, font=chn_font)
        x = (width - w)//2
        draw.text((x, y), line, font=chn_font, fill=chn_color)
        y += chn_size + 10

    return img


# -------------------- éŸ³é¢‘è¯•å¬ --------------------
def preview_voice(voice_name, text, speed=1.0):
    if not EDGE_TTS_AVAILABLE:
        return None
    import tempfile
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    tmp.close()
    try:
        asyncio.run(edge_tts.Communicate(text, voice_name).save(tmp.name))
        with open(tmp.name, "rb") as f:
            return f.read()
    except Exception:
        return None
    finally:
        os.remove(tmp.name)


# -------------------- Excel ä¸Šä¼  --------------------
uploaded_excel = st.file_uploader("ğŸ“„ ä¸Šä¼  Excel æ–‡ä»¶", type=["xlsx"])
if uploaded_excel:
    try:
        df = pd.read_excel(uploaded_excel)
        if not all(col in df.columns for col in ["è‹±è¯­", "ä¸­æ–‡", "éŸ³æ ‡"]):
            st.error("Excel å¿…é¡»åŒ…å«åˆ—ï¼šè‹±è¯­ã€ä¸­æ–‡ã€éŸ³æ ‡")
            st.stop()
        st.success(f"âœ… æˆåŠŸåŠ è½½ {len(df)} è¡Œå¥å­ã€‚")
        st.dataframe(df.head(10))
    except Exception as e:
        st.error(f"è¯»å– Excel å¤±è´¥: {e}")
        st.stop()
else:
    df = None

# -------------------- èƒŒæ™¯è®¾ç½® --------------------
col1, col2 = st.columns(2)
with col1:
    bg_type = st.radio("èƒŒæ™¯ç±»å‹", ["çº¯è‰²èƒŒæ™¯", "ä¸Šä¼ å›¾ç‰‡"], horizontal=True)
    if bg_type == "çº¯è‰²èƒŒæ™¯":
        bg_hex = st.color_picker("é€‰æ‹©èƒŒæ™¯é¢œè‰²", "#0b1220")
        bg_color = tuple(int(bg_hex[i:i+2], 16) for i in (1,3,5))
        bg_image = None
    else:
        bg_file = st.file_uploader("ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡", type=["jpg","png"])
        if bg_file:
            bg_image = Image.open(bg_file)
            st.image(bg_image, caption="èƒŒæ™¯é¢„è§ˆ", use_column_width=True)
        else:
            bg_image = None
            bg_color = (10,10,10)

with col2:
    eng_color = st.color_picker("è‹±è¯­é¢œè‰²", "#FFFFFF")
    chn_color = st.color_picker("ä¸­æ–‡é¢œè‰²", "#B4E0FF")
    pho_color = st.color_picker("éŸ³æ ‡é¢œè‰²", "#FFF07A")

# -------------------- ä¸Šä¼ ç¦»çº¿éŸ³é¢‘ --------------------
st.markdown("### ğŸµ ä¸Šä¼ ç¦»çº¿éŸ³é¢‘æ–‡ä»¶ï¼ˆæ¨¡å¼Bï¼‰")
st.info("å‘½åè§„åˆ™ï¼š1-1.mp3ã€1-2.mp3ã€1-3.mp3ã€1-4.mp3 ç­‰ï¼›ç¼ºå¤±éƒ¨åˆ†è‡ªåŠ¨ä½¿ç”¨é™éŸ³ã€‚")
uploaded_audios = st.file_uploader("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶", type=["mp3"], accept_multiple_files=True)
uploaded_audio_map = {}
if uploaded_audios:
    for f in uploaded_audios:
        base = os.path.splitext(f.name)[0]
        uploaded_audio_map[base.lower()] = f.read()

# -------------------- è¯•å¬åŠŸèƒ½ --------------------
if EDGE_TTS_AVAILABLE:
    st.markdown("### ğŸ§ è¯•å¬éŸ³è‰²")
    col_a, col_b, col_c = st.columns(3)
    with col_a:
        if st.button("è¯•å¬è‹±æ–‡ç”·å£°"):
            audio = preview_voice("en-US-GuyNeural", "Hello! This is an English male voice.")
            if audio: st.audio(audio, format="audio/mp3")
            else: st.warning("è¯•å¬å¤±è´¥")
    with col_b:
        if st.button("è¯•å¬è‹±æ–‡å¥³å£°"):
            audio = preview_voice("en-US-JennyNeural", "Hello! This is an English female voice.")
            if audio: st.audio(audio, format="audio/mp3")
            else: st.warning("è¯•å¬å¤±è´¥")
    with col_c:
        if st.button("è¯•å¬ä¸­æ–‡å¥³å£°"):
            audio = preview_voice("zh-CN-XiaoxiaoNeural", "ä½ å¥½ï¼è¿™æ˜¯ä¸­æ–‡è¯­éŸ³ã€‚")
            if audio: st.audio(audio, format="audio/mp3")
            else: st.warning("è¯•å¬å¤±è´¥")
else:
    st.warning("âš ï¸ edge-tts ä¸å¯ç”¨ï¼ˆç¦»çº¿ç¯å¢ƒï¼‰ï¼Œè¯•å¬åŠŸèƒ½ç¦ç”¨ã€‚")

# -------------------- å‚æ•° --------------------
st.markdown("### âš™ï¸ å‚æ•°è®¾ç½®")
col3, col4 = st.columns(2)
with col3:
    fps = st.slider("è§†é¢‘å¸§ç‡", 8, 30, 20)
    per_duration = st.slider("æ¯æ®µæ—¶é•¿ï¼ˆç§’ï¼‰", 2, 6, 4)
with col4:
    pause_duration = st.slider("æ®µé—´é™éŸ³ï¼ˆç§’ï¼‰", 0.0, 2.0, 0.5)
def write_concat_list(file_list, out_list_path):
    """
    å°† file_list å†™å…¥ out_list_pathï¼ˆæ¯è¡Œ file 'path'ï¼‰ï¼Œ
    åœ¨å†™å…¥å‰å¯¹å•å¼•å·è¿›è¡Œå®‰å…¨è½¬ä¹‰ï¼Œé¿å… ffmpeg è§£æé—®é¢˜æˆ– Python è¯­æ³•é—®é¢˜ã€‚
    """
    with open(out_list_path, "w", encoding="utf-8") as f:
        for p in file_list:
            safe_path = p.replace("'", "'\\''")
            f.write("file '%s'\n" % safe_path)
    return out_list_path

# åˆ›å»ºé™éŸ³éŸ³é¢‘ï¼ˆmp3ï¼‰
def create_silent_audio(duration, out_path):
    try:
        cmd = [
            "ffmpeg", "-y",
            "-f", "lavfi", "-i", f"anullsrc=r=44100:cl=stereo",
            "-t", str(duration),
            "-q:a", "9", "-acodec", "libmp3lame",
            out_path
        ]
        subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        return os.path.exists(out_path) and os.path.getsize(out_path) > 0
    except Exception as e:
        st.warning(f"åˆ›å»ºé™éŸ³éŸ³é¢‘å¤±è´¥: {e}")
        return False

# è°ƒæ•´éŸ³é¢‘æ—¶é•¿ï¼ˆå­˜åœ¨åˆ™è£åˆ‡/å¡«å……ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»ºé™éŸ³ï¼‰
def adjust_audio_to_duration(in_path, duration, out_path):
    if not in_path or not os.path.exists(in_path):
        return create_silent_audio(duration, out_path)
    try:
        cmd = [
            "ffmpeg", "-y", "-i", in_path,
            "-t", str(duration),
            "-af", "apad",
            "-acodec", "libmp3lame",
            out_path
        ]
        subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        return os.path.exists(out_path) and os.path.getsize(out_path) > 0
    except Exception as e:
        # fallback to silent
        return create_silent_audio(duration, out_path)

# ç”¨ ffmpeg concat åˆå¹¶å¤šä¸ªéŸ³é¢‘ï¼ˆæˆ–è§†é¢‘ï¼‰
def ffmpeg_concat(file_list, out_path, is_video=False):
    with tempfile.NamedTemporaryFile(delete=False, mode="w", suffix=".txt", encoding="utf-8") as f:
        list_path = f.name
        for p in file_list:
            safe_p = p.replace("'", "'\\''")
            f.write("file '%s'\n" % safe_p)
    try:
        if is_video:
            cmd = ["ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", list_path, "-c", "copy", out_path]
        else:
            # å¯¹éŸ³é¢‘ä½¿ç”¨ concat åè®®ï¼ˆè‹¥å¤±è´¥å¯æ”¹ä¸º re-encodeï¼‰
            cmd = ["ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", list_path, "-c", "copy", out_path]
        subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        return os.path.exists(out_path) and os.path.getsize(out_path) > 0
    except subprocess.CalledProcessError as e:
        # å¦‚æœç›´æ¥ concat å¤±è´¥ï¼Œå°è¯•é‡ç¼–ç ç­–ç•¥ï¼ˆå¯¹éŸ³é¢‘ï¼‰
        try:
            if not is_video:
                # é€ä¸ªè½¬ç å† concatï¼ˆæ›´å…¼å®¹ï¼‰
                temp_dir = os.path.dirname(list_path)
                reencoded = []
                for idx, p in enumerate(file_list):
                    tgt = os.path.join(temp_dir, f"reenc_{idx}.mp3")
                    cmd2 = ["ffmpeg", "-y", "-i", p, "-acodec", "libmp3lame", "-ar", "44100", tgt]
                    subprocess.run(cmd2, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
                    if os.path.exists(tgt) and os.path.getsize(tgt) > 0:
                        reencoded.append(tgt)
                if reencoded:
                    # å†™æ–° list
                    with open(list_path, "w", encoding="utf-8") as f2:
                        for p in reencoded:
                            safe_p = p.replace("'", "'\\''")
                            f2.write("file '%s'\n" % safe_p)
                    cmd3 = ["ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", list_path, "-c", "copy", out_path]
                    subprocess.run(cmd3, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
                    return os.path.exists(out_path) and os.path.getsize(out_path) > 0
        except Exception:
            pass
        return False
    finally:
        try:
            os.remove(list_path)
        except:
            pass

# TTS ç”Ÿæˆï¼ˆä»…åœ¨ç¯å¢ƒæ”¯æŒ edge-tts æˆ– HTTP é™çº§æ—¶ä¼šèµ·ä½œç”¨ï¼‰
# ä¸ºç®€æ´æˆ‘ä»¬åœ¨è¿™é‡Œå¦‚æœ EDGE_TTS_AVAILABLE åˆ™å°½é‡ä½¿ç”¨å®ƒï¼ˆä¸ä¼šæŠ¥é”™ï¼‰
def generate_tts_audio(text, voice, out_path, speed=1.0):
    # è‹¥ç¯å¢ƒæ²¡æœ‰ edge-ttsï¼Œåˆ™ç›´æ¥è¿”å› Noneï¼ˆå¤–ç½‘å—é™æ—¶ä¼šè¿™æ ·ï¼‰
    if not EDGE_TTS_AVAILABLE:
        return None
    try:
        # ä½¿ç”¨ edge-tts å¼‚æ­¥æ¥å£ä¿å­˜
        # edge_tts.Communicate(...).save(...) åœ¨ sync ç¯å¢ƒå¯èƒ½éœ€ asyncio.run
        coro = edge_tts.Communicate(text, voice).save(out_path)
        asyncio.run(coro)
        if os.path.exists(out_path) and os.path.getsize(out_path) > 0:
            return out_path
        else:
            try:
                os.remove(out_path)
            except:
                pass
            return None
    except Exception:
        try:
            if os.path.exists(out_path):
                os.remove(out_path)
        except:
            pass
        return None

# ä¸»ç”Ÿæˆï¼šæ¯è¡Œå•ç‹¬ç”Ÿæˆç‰‡æ®µå¹¶æ‹¼æ¥ï¼ˆä¿ç•™åŸæœ‰è¡Œä¸ºï¼‰
def generate_and_concat(df, settings, uploaded_audio_map, status_placeholder, progress_bar):
    """
    é€»è¾‘ï¼š
    - å¯¹äºæ¯ä¸€è¡Œï¼Œç”Ÿæˆä¸€æ®µæ— å£°è§†é¢‘ï¼ˆé‡å¤å¸§è¦†ç›–è¯¥è¡Œæ€»æ—¶é•¿ï¼‰
    - ä¸ºæ¯ä¸€è¡Œæ„å»ºéŸ³é¢‘ç‰‡æ®µåˆ—è¡¨ï¼ˆæŒ‰ segment é¡ºåºï¼‰ï¼Œæ¯æ®µéŸ³é¢‘è°ƒæ•´ä¸º per_durationï¼Œæ®µé—´æ’å…¥ pause é™éŸ³
    - åˆå¹¶è¯¥è¡ŒéŸ³é¢‘ä¸ºä¸€ä¸ªæ–‡ä»¶ï¼Œå†ä¸è¯¥è¡Œæ— å£°è§†é¢‘åˆå¹¶ä¸º line_final
    - æœ€å concat æ‰€æœ‰ line_final -> output_video.mp4
    """
    if not check_ffmpeg():
        st.error("æœªæ£€æµ‹åˆ° ffmpegï¼Œè¯·ç¡®ä¿ ffmpeg å·²å®‰è£…å¹¶å¯ç”¨ã€‚")
        return None

    tmpdir = tempfile.mkdtemp(prefix="tvb_")
    try:
        fps = settings.get("fps", 20)
        per_dur = settings.get("per_duration", 4)
        pause_dur = settings.get("pause_duration", 0.5)
        width = settings.get("width", 1920)
        height = settings.get("height", 1080)
        eng_color = settings.get("eng_color", (255,255,255))
        chn_color = settings.get("chn_color", (180,220,255))
        pho_color = settings.get("pho_color", (255,240,120))
        eng_size = settings.get("eng_size", 80)
        chn_size = settings.get("chn_size", 60)
        pho_size = settings.get("pho_size", 48)
        bg_image_local = settings.get("bg_image", None)
        bg_color_local = settings.get("bg_color", (10,10,10))
        text_bg_enabled = settings.get("text_bg_enabled", True)
        voice_map = settings.get("voice_map", {
            "è‹±æ–‡ç”·å£°": "en-US-GuyNeural",
            "è‹±æ–‡å¥³å£°": "en-US-JennyNeural",
            "ä¸­æ–‡éŸ³è‰²": "zh-CN-XiaoxiaoNeural"
        })
        segment_order = settings.get("segment_order", ["è‹±æ–‡ç”·å£°","è‹±æ–‡å¥³å£°","ä¸­æ–‡éŸ³è‰²","è‹±æ–‡ç”·å£°"])

        total_lines = len(df)
        line_outputs = []
        for idx, row in df.iterrows():
            i = idx + 1
            status_placeholder.info(f"æ­£åœ¨å¤„ç†ç¬¬ {i}/{total_lines} è¡Œï¼šå‡†å¤‡éŸ³é¢‘ä¸å¸§...")
            # 1) å‡†å¤‡éŸ³é¢‘éƒ¨åˆ†
            per_line_audio_items = []
            for seg_idx, seg in enumerate(segment_order, start=1):
                key = f"{i}-{seg_idx}"
                # ä¼˜å…ˆä½¿ç”¨ä¸Šä¼ çš„ç¦»çº¿éŸ³é¢‘ï¼ˆuploaded_audio_map çš„ key å¯èƒ½æ˜¯ '1-1' æˆ– '01-01' ç­‰ï¼Œæˆ‘ä»¬åœ¨ä¸Šä¼ æ—¶å·²ä»¥ base åç§°å­˜å‚¨ï¼‰
                uploaded_key_variants = [key, key.lower(), key.replace('-', '-').lower()]
                audio_src = None
                # ä¸Šä¼  map çš„ key å­˜å‚¨å¯èƒ½æ˜¯åŸå§‹ baseï¼ˆå¦‚ "1-1"ï¼‰æˆ–å°å†™ï¼Œå·²å¤„ç†
                if uploaded_audio_map:
                    # try direct match
                    if key in uploaded_audio_map:
                        val = uploaded_audio_map[key]
                        # val æ˜¯ bytesï¼ˆä¸Šä¼ æ—¶è¯»å–çš„ï¼‰
                        pth = os.path.join(tmpdir, f"uploaded_{key}.mp3")
                        with open(pth, "wb") as _f:
                            _f.write(val)
                        audio_src = pth
                    elif key.lower() in uploaded_audio_map:
                        val = uploaded_audio_map[key.lower()]
                        pth = os.path.join(tmpdir, f"uploaded_{key}.mp3")
                        with open(pth, "wb") as _f:
                            _f.write(val)
                        audio_src = pth
                # å¦‚æœæ²¡æœ‰ä¸Šä¼ éŸ³é¢‘ï¼Œåˆ™å°è¯• TTSï¼ˆå¯èƒ½å› ç½‘ç»œå—é™å¤±è´¥ï¼‰
                if not audio_src:
                    voice = voice_map.get(seg, list(voice_map.values())[0])
                    text_to_speak = str(row.get("è‹±è¯­","")) if "è‹±æ–‡" in seg else str(row.get("ä¸­æ–‡",""))
                    tts_out = os.path.join(tmpdir, f"tts_{i}_{seg_idx}.mp3")
                    tts_res = generate_tts_audio(text_to_speak, voice, tts_out, speed=1.0)
                    if tts_res:
                        audio_src = tts_res
                    else:
                        audio_src = None
                # å°†è¯¥æ®µè°ƒæ•´ä¸º per_dur æ—¶é•¿ï¼ˆæˆ–é™éŸ³ï¼‰
                dst_adjusted = os.path.join(tmpdir, f"line_{i}_seg_{seg_idx}_adj.mp3")
                ok = adjust_audio_to_duration(audio_src, per_dur, dst_adjusted)
                if not ok:
                    # create silent as fallback
                    create_silent_audio(per_dur, dst_adjusted)
                per_line_audio_items.append(dst_adjusted)
                # å¦‚æœä¸æ˜¯æœ€åä¸€æ®µï¼ŒåŠ  pause
                if seg_idx < len(segment_order):
                    pause_file = os.path.join(tmpdir, f"line_{i}_pause_{seg_idx}.mp3")
                    create_silent_audio(pause_dur, pause_file)
                    per_line_audio_items.append(pause_file)

            # åˆå¹¶è¯¥è¡ŒéŸ³é¢‘
            per_line_concat = os.path.join(tmpdir, f"line_{i}_audio.mp3")
            ok_concat = ffmpeg_concat(per_line_audio_items, per_line_concat, is_video=False)
            if not ok_concat:
                # fallback: create single silent of expected duration
                total_segments = len(segment_order)
                total_dur_line = total_segments * per_dur + (total_segments - 1) * pause_dur
                create_silent_audio(total_dur_line, per_line_concat)

            # 2) ç”Ÿæˆè¯¥è¡Œæ— å£°è§†é¢‘ï¼ˆé‡å¤å¸§è¶³å¤Ÿæ—¶é•¿ï¼‰
            total_frames_for_line = len(segment_order) * int(round(per_dur * fps)) + (len(segment_order)-1) * int(round(pause_dur * fps))
            frame_image = create_frame(
                english=str(row.get("è‹±è¯­","")),
                chinese=str(row.get("ä¸­æ–‡","")),
                phonetic=str(row.get("éŸ³æ ‡","")) if pd.notna(row.get("éŸ³æ ‡","")) else "",
                width=width, height=height,
                bg_color=bg_color_local, bg_image=bg_image_local,
                eng_color=eng_color, chn_color=chn_color, pho_color=pho_color,
                eng_size=eng_size, chn_size=chn_size, pho_size=pho_size,
                text_bg_enabled=text_bg_enabled
            )
            frame_arr = np.array(frame_image.convert("RGB"))
            line_video_path = os.path.join(tmpdir, f"line_{i}_video.mp4")
            writer = imageio.get_writer(line_video_path, fps=fps, macro_block_size=1, format="FFMPEG", codec="libx264")
            try:
                for _ in range(total_frames_for_line):
                    writer.append_data(frame_arr)
            except Exception as e:
                st.warning(f"å†™å…¥ç¬¬ {i} è¡Œå¸§æ—¶å‡ºé”™: {e}")
            finally:
                writer.close()

            # 3) åˆå¹¶è§†é¢‘ä¸è¯¥è¡ŒéŸ³é¢‘ -> final line file
            line_final = os.path.join(tmpdir, f"line_{i}_final.mp4")
            try:
                cmd = [
                    "ffmpeg", "-y",
                    "-i", line_video_path,
                    "-i", per_line_concat,
                    "-c:v", "copy", "-c:a", "aac", "-shortest",
                    line_final
                ]
                subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
                if os.path.exists(line_final) and os.path.getsize(line_final) > 0:
                    line_outputs.append(line_final)
                else:
                    # fallback to silent video if merge failed
                    line_outputs.append(line_video_path)
            except Exception:
                # on any error fallback silent video
                line_outputs.append(line_video_path)

            # update progress
            progress_bar.progress(0.3 + 0.6 * ((idx+1)/total_lines))
            status_placeholder.info(f"ç¬¬ {i}/{total_lines} è¡Œå¤„ç†å®Œæˆ")

        # all lines done -> concat all line_outputs
        status_placeholder.info("æ­£åœ¨æ‹¼æ¥æ‰€æœ‰ç‰‡æ®µï¼Œè¯·ç¨å€™...")
        final_out = os.path.join(tmpdir, "output_video.mp4")
        concat_ok = ffmpeg_concat(line_outputs, final_out, is_video=True)
        if not concat_ok:
            # å°è¯•é‡ç¼–ç æ‹¼æ¥ï¼ˆæ›´å…¼å®¹ï¼‰
            list_file = os.path.join(tmpdir, "videos_list.txt")
            write_concat_list(line_outputs, list_file)
            try:
                cmd2 = ["ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", list_file, "-c:v", "libx264", "-c:a", "aac", final_out]
                subprocess.run(cmd2, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
            except Exception as e:
                st.error(f"æœ€ç»ˆæ‹¼æ¥å¤±è´¥: {e}")
                return None

        if os.path.exists(final_out) and os.path.getsize(final_out) > 0:
            # copy final_out to current working dir for persistence
            try:
                shutil.copy(final_out, os.path.join(os.getcwd(), "output_video.mp4"))
            except:
                pass
            with open(final_out, "rb") as f:
                data = f.read()
            status_placeholder.success("è§†é¢‘ç”Ÿæˆå®Œæˆï¼šoutput_video.mp4")
            progress_bar.progress(1.0)
            return data
        else:
            st.error("æœ€ç»ˆè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º")
            return None

    except Exception as e:
        st.error(f"ç”Ÿæˆè¿‡ç¨‹å¼‚å¸¸ï¼š{e}")
        st.text(traceback.format_exc())
        return None
    finally:
        # æ¸…ç†ä¸´æ—¶ç›®å½•ï¼ˆå¦‚éœ€è°ƒè¯•å¯æ³¨é‡Šæ‰ï¼‰
        try:
            shutil.rmtree(tmpdir)
        except:
            pass


# -------------------- ç”ŸæˆæŒ‰é’®ä¸è§¦å‘ --------------------
if df is not None:
    st.markdown("### ğŸš€ å¼€å§‹ç”Ÿæˆ")
    if st.button("ğŸ¬ ç”Ÿæˆè§†é¢‘ï¼ˆä½¿ç”¨ä¸Šä¼ éŸ³é¢‘ä¼˜å…ˆï¼Œç¼ºå¤±åˆ™é™éŸ³æˆ–å°è¯• TTSï¼‰"):
        status_ph = st.empty()
        pbar = st.progress(0.0)
        # æ„é€  settings
        settings = {
            "fps": fps,
            "per_duration": per_duration,
            "pause_duration": pause_duration,
            "width": 1920,
            "height": 1080,
            "eng_color": tuple(int(eng_color[i:i+2],16) for i in (1,3,5)) if isinstance(eng_color,str) else eng_color,
            "chn_color": tuple(int(chn_color[i:i+2],16) for i in (1,3,5)) if isinstance(chn_color,str) else chn_color,
            "pho_color": tuple(int(pho_color[i:i+2],16) for i in (1,3,5)) if isinstance(pho_color,str) else pho_color,
            "eng_size": eng_size,
            "chn_size": chn_size,
            "pho_size": pho_size,
            "bg_image": bg_image,
            "bg_color": bg_color,
            "text_bg_enabled": True,
            "voice_map": {
                "è‹±æ–‡ç”·å£°": "en-US-GuyNeural",
                "è‹±æ–‡å¥³å£°": "en-US-JennyNeural",
                "ä¸­æ–‡éŸ³è‰²": "zh-CN-XiaoxiaoNeural"
            },
            "segment_order": ["è‹±æ–‡ç”·å£°","è‹±æ–‡å¥³å£°","ä¸­æ–‡éŸ³è‰²","è‹±æ–‡ç”·å£°"]
        }
        # è§¦å‘ç”Ÿæˆ
        try:
            video_bytes = generate_and_concat(df, settings, uploaded_audio_map, status_ph, pbar)
            if video_bytes:
                st.video(video_bytes)
                st.download_button("ğŸ“¥ ä¸‹è½½ output_video.mp4", data=video_bytes, file_name="output_video.mp4", mime="video/mp4")
            else:
                st.error("ç”Ÿæˆå¤±è´¥ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹é”™è¯¯ä¿¡æ¯ã€‚")
        except Exception as e:
            st.error(f"æœªæ•è·çš„å¼‚å¸¸ï¼š{e}")
            st.text(traceback.format_exc())
