import streamlit as st
import pandas as pd
import os
import numpy as np
from PIL import Image, ImageDraw
import imageio.v2 as imageio
import tempfile
import base64
import subprocess
import platform

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ—…æ¸¸è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨",
    page_icon="ğŸ¬",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'bg_image' not in st.session_state:
    st.session_state.bg_image = None

def check_system_tts():
    """æ£€æŸ¥ç³»ç»ŸTTSæ”¯æŒ"""
    system = platform.system()
    if system == "Windows":
        return "Windows TTSå¯ç”¨"
    elif system == "Darwin":  # macOS
        return "macOS TTSå¯ç”¨"
    elif system == "Linux":
        # æ£€æŸ¥espeakæ˜¯å¦å®‰è£…
        result = subprocess.run(["which", "espeak"], capture_output=True, text=True)
        if result.returncode == 0:
            return "espeak TTSå¯ç”¨"
    return "æ— æœ¬åœ°TTSæ”¯æŒ"

def generate_audio_system(text, lang='en', output_file=None):
    """ä½¿ç”¨ç³»ç»ŸTTSç”ŸæˆéŸ³é¢‘"""
    system = platform.system()
    
    try:
        if system == "Windows":
            # ä½¿ç”¨Windows SAPI
            try:
                import win32com.client
                speaker = win32com.client.Dispatch("SAPI.SpVoice")
                speaker.Speak(text)
                # Windows SAPIä¸èƒ½ç›´æ¥ä¿å­˜æ–‡ä»¶ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
                return None
            except ImportError:
                st.warning("Windows TTSä¸å¯ç”¨ï¼Œéœ€è¦å®‰è£…pywin32")
                return None
        elif system == "Darwin":  # macOS
            # ä½¿ç”¨sayå‘½ä»¤
            cmd = ['say', '-v', 'Alex' if lang == 'en' else 'Ting-Ting', '-o', output_file, text]
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                return output_file
        elif system == "Linux":
            # ä½¿ç”¨espeak
            voice = 'en' if lang == 'en' else 'zh'
            cmd = ['espeak', '-v', voice, '-w', output_file, text]
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                return output_file
    except Exception as e:
        st.warning(f"ç³»ç»ŸTTSå¤±è´¥: {str(e)}")
    
    return None

def generate_audio_fallback(text, lang='en'):
    """å¤‡é€‰éŸ³é¢‘ç”Ÿæˆæ–¹æ¡ˆ"""
    # æ–¹æ¡ˆ1: å°è¯•gTTSï¼ˆåœ¨çº¿ï¼‰
    try:
        from gtts import gTTS
        with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as f:
            tts = gTTS(text=text, lang=lang)
            tts.save(f.name)
            return f.name
    except Exception as e:
        st.warning(f"gTTSå¤±è´¥: {str(e)}")
    
    # æ–¹æ¡ˆ2: åˆ›å»ºé™éŸ³éŸ³é¢‘ï¼ˆå®Œå…¨ç¦»çº¿æ–¹æ¡ˆï¼‰
    try:
        # ç”Ÿæˆé™éŸ³WAVæ–‡ä»¶
        import wave
        import struct
        
        sample_rate = 22050
        duration = 3  # 3ç§’é™éŸ³
        
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
            with wave.open(f.name, 'w') as wav_file:
                wav_file.setnchannels(1)  # å•å£°é“
                wav_file.setsampwidth(2)  # 2å­—èŠ‚æ ·æœ¬
                wav_file.setframerate(sample_rate)
                
                # ç”Ÿæˆé™éŸ³æ•°æ®
                frames = b''
                for i in range(int(sample_rate * duration)):
                    frames += struct.pack('<h', 0)  # 16ä½é™éŸ³
                
                wav_file.writeframes(frames)
            return f.name
    except Exception as e:
        st.warning(f"é™éŸ³éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")
        return None

def wrap_text(text, max_chars):
    """æ–‡æœ¬è‡ªåŠ¨æ¢è¡Œå¤„ç†"""
    if not text or str(text).strip().lower() in ['nan', 'none', '']:
        return [""]
    
    text = str(text).strip()
    if any('\u4e00' <= c <= '\u9fff' for c in text):
        max_chars = min(max_chars, 15)
    
    words = text.split()
    lines, current = [], []
    
    for word in words:
        test_line = ' '.join(current + [word])
        if len(test_line) <= max_chars:
            current.append(word)
        else:
            if current:
                lines.append(' '.join(current))
            if len(word) > max_chars:
                for i in range(0, len(word), max_chars):
                    lines.append(word[i:i+max_chars])
                current = []
            else:
                current = [word]
    
    if current:
        lines.append(' '.join(current))
    
    return lines if lines else [""]

def create_frame(english, chinese, phonetic, width=1280, height=720, 
                bg_color=(0,0,0), bg_image=None,
                eng_color=(255,255,255), chn_color=(0,255,255), pho_color=(255,255,0),
                eng_size=60, chn_size=50, pho_size=40):
    """åˆ›å»ºå•å¸§å›¾åƒ"""
    if bg_image and hasattr(bg_image, 'resize'):
        try:
            img = bg_image.resize((width, height), Image.Resampling.LANCZOS).convert('RGB')
        except:
            img = Image.new('RGB', (width, height), bg_color)
    else:
        img = Image.new('RGB', (width, height), bg_color)
    
    draw = ImageDraw.Draw(img)
    
    eng_lines = wrap_text(english, 30)
    chn_lines = wrap_text(chinese, 15)
    pho_lines = wrap_text(phonetic, 35) if phonetic and str(phonetic).strip().lower() not in ['nan', 'none', ''] else []
    
    line_spacing = 10
    total_height = 0
    
    total_height += len(eng_lines) * eng_size + line_spacing * max(0, len(eng_lines) - 1)
    
    if chn_lines:
        total_height += 20 + len(chn_lines) * chn_size + line_spacing * max(0, len(chn_lines) - 1)
    
    if pho_lines:
        total_height += 15 + len(pho_lines) * pho_size + line_spacing * max(0, len(pho_lines) - 1)
    
    y = (height - total_height) // 2
    
    for line in eng_lines:
        w = len(line) * eng_size // 2
        h = eng_size
        x = (width - w) // 2
        shadow_color = (0, 0, 0)
        draw.text((x+2, y+2), line, fill=shadow_color)
        draw.text((x, y), line, fill=eng_color)
        y += h + line_spacing
    
    if chn_lines:
        y += 10
        for line in chn_lines:
            w = len(line) * chn_size // 2
            h = chn_size
            x = (width - w) // 2
            draw.text((x+2, y+2), line, fill=shadow_color)
            draw.text((x, y), line, fill=chn_color)
            y += h + line_spacing
    
    if pho_lines:
        y += 5
        for line in pho_lines:
            w = len(line) * pho_size // 2
            h = pho_size
            x = (width - w) // 2
            draw.text((x+2, y+2), line, fill=shadow_color)
            draw.text((x, y), line, fill=pho_color)
            y += h + line_spacing
    
    return img

def create_sample_excel():
    """åˆ›å»ºç¤ºä¾‹Excelæ–‡ä»¶"""
    sample_data = {
        'è‹±è¯­': [
            "Hello, how are you?",
            "Where is the nearest restaurant?",
            "How much does this cost?",
            "Thank you very much",
            "Good morning"
        ],
        'ä¸­æ–‡': [
            "ä½ å¥½ï¼Œæœ€è¿‘æ€ä¹ˆæ ·ï¼Ÿ",
            "æœ€è¿‘çš„é¤å…åœ¨å“ªé‡Œï¼Ÿ",
            "è¿™ä¸ªå¤šå°‘é’±ï¼Ÿ",
            "éå¸¸æ„Ÿè°¢",
            "æ—©ä¸Šå¥½"
        ],
        'éŸ³æ ‡': [
            "/hÉ™ËˆloÊŠ, haÊŠ É‘Ër juË/",
            "/wer Éªz Ã°É™ ËˆnÉªrÉªst ËˆrÉ›stÉ™rÉ™nt/",
            "/haÊŠ mÊŒtÊƒ dÊŒz Ã°Éªs kÉ’st/",
            "/Î¸Ã¦Å‹k juË ËˆvÉ›ri mÊŒtÊƒ/",
            "/É¡ÊŠd ËˆmÉ”ËrnÉªÅ‹/"
        ]
    }
    return pd.DataFrame(sample_data)

# é¡µé¢UI
st.title("ğŸ¬ æ—…æ¸¸è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨ - ç¦»çº¿ç‰ˆ")
st.markdown("ç”ŸæˆåŒ…å«è‹±è¯­å¥å­ã€ä¸­æ–‡ç¿»è¯‘å’ŒéŸ³æ ‡çš„å­¦ä¹ è§†é¢‘ï¼ˆæ”¯æŒç¦»çº¿éŸ³é¢‘ï¼‰")

# æ£€æŸ¥TTSæ”¯æŒ
tts_status = check_system_tts()
st.info(f"TTSçŠ¶æ€: {tts_status}")

# æä¾›ç¤ºä¾‹æ–‡ä»¶ä¸‹è½½
st.header("ğŸ“‹ ç¤ºä¾‹æ–‡ä»¶")
sample_df = create_sample_excel()
st.dataframe(sample_df, height=200)

sample_csv = sample_df.to_csv(index=False).encode('utf-8')
st.download_button(
    "ä¸‹è½½ç¤ºä¾‹CSVæ–‡ä»¶",
    data=sample_csv,
    file_name="travel_english_sample.csv",
    mime="text/csv"
)

# æ–‡ä»¶ä¸Šä¼ 
st.header("1. ä¸Šä¼ æ•°æ®æ–‡ä»¶")
uploaded_file = st.file_uploader("é€‰æ‹©Excelæˆ–CSVæ–‡ä»¶", type=['xlsx', 'xls', 'csv'])

df = None
if uploaded_file:
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)
            
        required_cols = ['è‹±è¯­', 'ä¸­æ–‡', 'éŸ³æ ‡']
        missing = [c for c in required_cols if c not in df.columns]
        
        if missing:
            st.error(f"æ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—: {', '.join(missing)}")
        else:
            st.success(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼å…± {len(df)} æ¡æ•°æ®")
            st.dataframe(df.head(10), height=300)
            
    except Exception as e:
        st.error(f"æ–‡ä»¶å¤„ç†é”™è¯¯: {str(e)}")

if df is not None and not df.empty:
    # è‡ªå®šä¹‰è®¾ç½®
    st.header("2. è‡ªå®šä¹‰è®¾ç½®")
    
    bg_type = st.radio("èƒŒæ™¯ç±»å‹", ["çº¯è‰²", "å›¾ç‰‡"])
    bg_color = (0, 0, 0)
    
    if bg_type == "çº¯è‰²":
        bg_hex = st.color_picker("èƒŒæ™¯é¢œè‰²", "#000000")
        bg_color = tuple(int(bg_hex.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))
        st.session_state.bg_image = None
    else:
        bg_file = st.file_uploader("ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡", type=['jpg', 'jpeg', 'png'])
        if bg_file:
            try:
                st.session_state.bg_image = Image.open(bg_file)
                st.image(st.session_state.bg_image, caption="èƒŒæ™¯é¢„è§ˆ", width=300)
            except Exception as e:
                st.error(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}")
                st.session_state.bg_image = None
    
    st.subheader("æ–‡å­—æ ·å¼")
    col1, col2, col3 = st.columns(3)
    with col1:
        eng_color_hex = st.color_picker("è‹±è¯­é¢œè‰²", "#FFFFFF")
        eng_color = tuple(int(eng_color_hex.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))
        eng_size = st.slider("è‹±è¯­å­—å·", 20, 100, 60)
    with col2:
        chn_color_hex = st.color_picker("ä¸­æ–‡é¢œè‰²", "#00FFFF")
        chn_color = tuple(int(chn_color_hex.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))
        chn_size = st.slider("ä¸­æ–‡å­—å·", 20, 100, 50)
    with col3:
        pho_color_hex = st.color_picker("éŸ³æ ‡é¢œè‰²", "#FFFF00")
        pho_color = tuple(int(pho_color_hex.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))
        pho_size = st.slider("éŸ³æ ‡å­—å·", 16, 80, 40)
    
    st.subheader("è§†é¢‘è®¾ç½®")
    col4, col5 = st.columns(2)
    with col4:
        duration = st.slider("æ¯å¥æ˜¾ç¤ºæ—¶é—´(ç§’)", 2, 10, 5)
        fps = st.slider("å¸§ç‡", 10, 30, 24)
    with col5:
        tts_option = st.selectbox("TTSé€‰é¡¹", ["ç³»ç»ŸTTS", "åœ¨çº¿TTS", "æ— éŸ³é¢‘"])
        tts_lang = st.selectbox("è¯­éŸ³è¯­è¨€", ["è‹±è¯­", "ä¸­æ–‡"])
        tts_lang_code = "en" if tts_lang == "è‹±è¯­" else "zh"
    
    # é¢„è§ˆ
    st.header("3. é¢„è§ˆæ•ˆæœ")
    preview_idx = st.slider("é€‰æ‹©é¢„è§ˆè¡Œ", 0, len(df)-1, 0)
    row = df.iloc[preview_idx]
    
    try:
        preview_img = create_frame(
            english=str(row['è‹±è¯­']),
            chinese=str(row['ä¸­æ–‡']),
            phonetic=str(row['éŸ³æ ‡']) if pd.notna(row['éŸ³æ ‡']) else "",
            bg_color=bg_color,
            bg_image=st.session_state.bg_image,
            eng_color=eng_color,
            chn_color=chn_color,
            pho_color=pho_color,
            eng_size=eng_size,
            chn_size=chn_size,
            pho_size=pho_size
        )
        st.image(preview_img, caption=f"é¢„è§ˆ: {row['è‹±è¯­'][:50]}...", use_column_width=True)
    except Exception as e:
        st.error(f"é¢„è§ˆç”Ÿæˆå¤±è´¥: {str(e)}")
    
    # ç”Ÿæˆè§†é¢‘
    st.header("4. ç”Ÿæˆè§†é¢‘")
    
    if st.button("ğŸ¬ å¼€å§‹ç”Ÿæˆè§†é¢‘", type="primary", use_container_width=True):
        with st.spinner("æ­£åœ¨ç”Ÿæˆè§†é¢‘ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´..."):
            try:
                with tempfile.TemporaryDirectory() as temp_dir:
                    frames = []
                    audio_paths = []
                    total_frames = len(df) * duration * fps
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for idx, row in df.iterrows():
                        status_text.text(f"å¤„ç†ç¬¬ {idx + 1}/{len(df)} å¥: {row['è‹±è¯­'][:30]}...")
                        
                        frame = create_frame(
                            english=str(row['è‹±è¯­']),
                            chinese=str(row['ä¸­æ–‡']),
                            phonetic=str(row['éŸ³æ ‡']) if pd.notna(row['éŸ³æ ‡']) else "",
                            bg_color=bg_color,
                            bg_image=st.session_state.bg_image,
                            eng_color=eng_color,
                            chn_color=chn_color,
                            pho_color=pho_color,
                            eng_size=eng_size,
                            chn_size=chn_size,
                            pho_size=pho_size
                        )
                        
                        for _ in range(duration * fps):
                            frames.append(np.array(frame.convert('RGB')))
                        
                        # éŸ³é¢‘ç”Ÿæˆé€»è¾‘
                        if tts_option != "æ— éŸ³é¢‘":
                            audio_file = os.path.join(temp_dir, f"audio_{idx}.wav")
                            
                            if tts_option == "ç³»ç»ŸTTS":
                                audio_path = generate_audio_system(
                                    text=str(row['è‹±è¯­']),
                                    lang=tts_lang_code,
                                    output_file=audio_file
                                )
                            else:  # åœ¨çº¿TTS
                                audio_path = generate_audio_fallback(
                                    text=str(row['è‹±è¯­']),
                                    lang=tts_lang_code
                                )
                            
                            audio_paths.append(audio_path)
                        
                        current_progress = min((idx + 1) / len(df), 1.0)
                        progress_bar.progress(current_progress)
                    
                    status_text.text("æ­£åœ¨ä¿å­˜è§†é¢‘...")
                    
                    video_path = os.path.join(temp_dir, "video_no_audio.mp4")
                    try:
                        imageio.mimsave(video_path, frames, fps=fps, quality=8)
                    except Exception as e:
                        st.error(f"è§†é¢‘ä¿å­˜å¤±è´¥: {str(e)}")
                        return
                    
                    final_video_path = video_path
                    has_audio = False
                    
                    if tts_option != "æ— éŸ³é¢‘" and audio_paths and any(audio_paths):
                        status_text.text("æ­£åœ¨å¤„ç†éŸ³é¢‘...")
                        try:
                            # åˆå¹¶éŸ³é¢‘
                            audio_list_path = os.path.join(temp_dir, "audio_list.txt")
                            with open(audio_list_path, 'w') as f:
                                for audio_path in audio_paths:
                                    if audio_path and os.path.exists(audio_path):
                                        f.write(f"file '{audio_path}'\n")
                            
                            combined_audio_path = os.path.join(temp_dir, "combined_audio.wav")
                            cmd = [
                                'ffmpeg', '-y', '-f', 'concat', '-safe', '0',
                                '-i', audio_list_path, '-c', 'copy', combined_audio_path
                            ]
                            
                            result = subprocess.run(cmd, capture_output=True, text=True)
                            
                            if result.returncode == 0 and os.path.exists(combined_audio_path):
                                final_video_path = os.path.join(temp_dir, "video_with_audio.mp4")
                                merge_cmd = [
                                    'ffmpeg', '-y',
                                    '-i', video_path,
                                    '-i', combined_audio_path,
                                    '-c:v', 'copy',
                                    '-c:a', 'aac',
                                    '-shortest',
                                    final_video_path
                                ]
                                
                                merge_result = subprocess.run(merge_cmd, capture_output=True, text=True)
                                if merge_result.returncode == 0:
                                    has_audio = True
                                    st.success("âœ… å·²ç”Ÿæˆå¸¦éŸ³é¢‘çš„è§†é¢‘")
                        except Exception as e:
                            st.warning(f"éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}")
                    
                    try:
                        with open(final_video_path, "rb") as f:
                            video_bytes = f.read()
                        
                        progress_bar.progress(1.0)
                        status_text.text("è§†é¢‘ç”Ÿæˆå®Œæˆï¼")
                        
                        st.success("ğŸ‰ è§†é¢‘ç”Ÿæˆå®Œæˆï¼")
                        st.video(video_bytes)
                        
                        file_suffix = "_with_audio" if has_audio else "_no_audio"
                        st.download_button(
                            f"ğŸ“¥ ä¸‹è½½è§†é¢‘{'ï¼ˆå«éŸ³é¢‘ï¼‰' if has_audio else 'ï¼ˆæ— éŸ³é¢‘ï¼‰'}",
                            data=video_bytes,
                            file_name=f"travel_english_video{file_suffix}.mp4",
                            mime="video/mp4",
                            use_container_width=True
                        )
                        
                    except Exception as e:
                        st.error(f"è§†é¢‘æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
                        
            except Exception as e:
                st.error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
else:
    st.info("ğŸ‘† è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶æˆ–ä½¿ç”¨ç¤ºä¾‹æ•°æ®")

st.markdown("---")
st.markdown("### ğŸ’¡ ä½¿ç”¨è¯´æ˜")
st.markdown("""
**TTSé€‰é¡¹è¯´æ˜**:
- **ç³»ç»ŸTTS**: ä½¿ç”¨æ“ä½œç³»ç»Ÿè‡ªå¸¦çš„TTSå¼•æ“ï¼ˆéœ€è¦ç³»ç»Ÿæ”¯æŒï¼‰
- **åœ¨çº¿TTS**: ä½¿ç”¨gTTSåœ¨çº¿æœåŠ¡ï¼ˆéœ€è¦ç½‘ç»œï¼‰
- **æ— éŸ³é¢‘**: ç”Ÿæˆæ— éŸ³é¢‘è§†é¢‘

**ç³»ç»ŸTTSæ”¯æŒ**:
- Windows: ä½¿ç”¨SAPI
- macOS: ä½¿ç”¨sayå‘½ä»¤
- Linux: ä½¿ç”¨espeakï¼ˆéœ€è¦å®‰è£…ï¼‰
""")
