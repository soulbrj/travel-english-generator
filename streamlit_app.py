import streamlit as st
import pandas as pd
import time
import io
import os
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import imageio.v2 as imageio
from io import BytesIO
import base64
import tempfile

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ—…æ¸¸è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨",
    page_icon="ğŸ¬",
    layout="wide"
)

st.title("ğŸ¬ æ—…æ¸¸è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨")
st.markdown("### ğŸŒ é«˜çº§è‡ªå®šä¹‰è§†é¢‘ç”Ÿæˆ - ä¿®å¤ç‰ˆ")

# åˆå§‹åŒ–session state
if 'background_image' not in st.session_state:
    st.session_state.background_image = None

# ç‰¹æ€§ä»‹ç»
col1, col2, col3 = st.columns(3)
with col1:
    st.info("ğŸ¨ å®Œå…¨è‡ªå®šä¹‰\n\né¢œè‰²ã€å­—ä½“ã€èƒŒæ™¯éšæ„è°ƒæ•´")

with col2:
    st.info("ğŸ–¼ï¸ èƒŒæ™¯å›¾ç‰‡\n\næ”¯æŒè‡ªå®šä¹‰èƒŒæ™¯æˆ–çº¯è‰²")

with col3:
    st.info("ğŸ”¤ å­—ä½“æ”¯æŒ\n\nå®Œç¾æ˜¾ç¤ºä¸­æ–‡å’ŒéŸ³æ ‡")

# æ–‡ä»¶ä¸Šä¼ 
st.header("ğŸ“¤ ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ Excelæ–‡ä»¶")
uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=['xlsx', 'xls'], 
                                help="Excelæ–‡ä»¶å¿…é¡»åŒ…å«'è‹±è¯­','ä¸­æ–‡','éŸ³æ ‡'ä¸‰åˆ—")

def create_custom_font(size):
    """åˆ›å»ºè‡ªå®šä¹‰å­—ä½“å¯¹è±¡æ¥æ¨¡æ‹Ÿå­—å·æ•ˆæœ"""
    # åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿçš„å­—ä½“å¯¹è±¡æ¥ç»´æŠ¤å­—å·ä¿¡æ¯
    class CustomFont:
        def __init__(self, size):
            self.size = size
            # ä¼°ç®—å­—ç¬¦å®½åº¦ï¼ˆåƒç´ ï¼‰
            self.char_width = max(8, size // 2)
            self.char_height = size + 10
    
    return CustomFont(size)

def wrap_text(text, max_chars, font=None):
    """å°†æ–‡æœ¬æŒ‰æœ€å¤§å­—ç¬¦æ•°æ¢è¡Œ"""
    if not text or str(text) == 'nan':
        return [""]
    
    text = str(text)
    # å¦‚æœæ˜¯ä¸­æ–‡ï¼Œå‡å°‘æ¯è¡Œå­—ç¬¦æ•°
    if any('\u4e00' <= char <= '\u9fff' for char in text):
        max_chars = min(max_chars, 15)  # ä¸­æ–‡æ¯è¡Œæœ€å¤š15å­—
    
    words = text.split()
    lines = []
    current_line = []
    
    for word in words:
        test_line = ' '.join(current_line + [word])
        if len(test_line) <= max_chars:
            current_line.append(word)
        else:
            if current_line:
                lines.append(' '.join(current_line))
            # å¤„ç†è¶…é•¿å•è¯
            if len(word) > max_chars:
                for i in range(0, len(word), max_chars):
                    lines.append(word[i:i+max_chars])
                current_line = []
            else:
                current_line = [word]
    
    if current_line:
        lines.append(' '.join(current_line))
    
    return lines if lines else [text[:max_chars]]

def create_video_frame(text_english, text_chinese, text_phonetic, width=1280, height=720, 
                      bg_color=(0, 0, 0), bg_image=None, 
                      english_color=(255, 255, 255), chinese_color=(0, 255, 255), phonetic_color=(255, 255, 0),
                      english_size=60, chinese_size=50, phonetic_size=40,
                      text_bg_color=(0, 0, 0, 180), text_bg_radius=20):
    """åˆ›å»ºå•ä¸ªè§†é¢‘å¸§"""
    
    # åˆ›å»ºå›¾åƒ
    if bg_image:
        img = bg_image.resize((width, height)).convert('RGB')
    else:
        img = Image.new('RGB', (width, height), color=bg_color)
    
    draw = ImageDraw.Draw(img)
    
    # åˆ›å»ºå­—ä½“å¯¹è±¡ï¼ˆæ¨¡æ‹Ÿå­—å·æ•ˆæœï¼‰
    english_font = create_custom_font(english_size)
    chinese_font = create_custom_font(chinese_size)
    phonetic_font = create_custom_font(phonetic_size)
    
    # è®¡ç®—æ–‡æœ¬åŒºåŸŸæ€»é«˜åº¦
    english_lines = wrap_text(text_english, 35)
    chinese_lines = wrap_text(text_chinese, 15)  # ä¸­æ–‡æ¯è¡Œè¾ƒå°‘å­—ç¬¦
    phonetic_lines = wrap_text(text_phonetic, 40) if text_phonetic and str(text_phonetic).strip() and str(text_phonetic) != 'nan' else []
    
    total_text_height = (len(english_lines) * english_font.char_height + 
                        len(chinese_lines) * chinese_font.char_height + 
                        len(phonetic_lines) * phonetic_font.char_height + 80)
    
    # åˆ›å»ºæ–‡æœ¬èƒŒæ™¯åŒºåŸŸ
    text_bg_width = width - 100
    text_bg_height = total_text_height + 40
    text_bg_x = 50
    text_bg_y = (height - text_bg_height) // 2
    
    # ç»˜åˆ¶åœ†è§’çŸ©å½¢èƒŒæ™¯
    for i in range(text_bg_radius):
        radius = text_bg_radius - i
        alpha = int(text_bg_color[3] * (1 - i/text_bg_radius))
        bg_color_with_alpha = text_bg_color[:3] + (alpha,)
        
        # ç»˜åˆ¶å››ä¸ªè§’çš„åœ†å¼§
        for corner_x, corner_y in [(text_bg_x, text_bg_y), 
                                  (text_bg_x + text_bg_width - 2*radius, text_bg_y),
                                  (text_bg_x, text_bg_y + text_bg_height - 2*radius),
                                  (text_bg_x + text_bg_width - 2*radius, text_bg_y + text_bg_height - 2*radius)]:
            for x in range(radius):
                for y in range(radius):
                    if (x - radius)**2 + (y - radius)**2 <= radius**2:
                        img.putpixel((corner_x + x, corner_y + y), text_bg_color[:3])
                        img.putpixel((corner_x + text_bg_width - radius + x, corner_y + y), text_bg_color[:3])
                        img.putpixel((corner_x + x, corner_y + text_bg_height - radius + y), text_bg_color[:3])
                        img.putpixel((corner_x + text_bg_width - radius + x, corner_y + text_bg_height - radius + y), text_bg_color[:3])
    
    # ç»˜åˆ¶çŸ©å½¢ä¸»ä½“
    for x in range(text_bg_width - 2*text_bg_radius):
        for y in range(text_bg_height):
            img.putpixel((text_bg_x + text_bg_radius + x, text_bg_y + y), text_bg_color[:3])
    
    for y in range(text_bg_height - 2*text_bg_radius):
        for x in range(text_bg_width):
            img.putpixel((text_bg_x + x, text_bg_y + text_bg_radius + y), text_bg_color[:3])
    
    # ç»˜åˆ¶æ–‡æœ¬
    y_position = text_bg_y + 30
    
    # ç»˜åˆ¶è‹±è¯­å¥å­
    for i, line in enumerate(english_lines):
        text_width = len(line) * english_font.char_width
        x = text_bg_x + (text_bg_width - text_width) // 2
        y = y_position + i * english_font.char_height
        
        # ç»˜åˆ¶æ–‡æœ¬é˜´å½±ï¼ˆå¢å¼ºå¯è¯»æ€§ï¼‰
        shadow_color = (0, 0, 0)
        for dx in [-1, 0, 1]:
            for dy in [-1, 0, 1]:
                if dx == 0 and dy == 0:
                    continue
                draw.text((x + dx, y + dy), line, fill=shadow_color)
        
        # ç»˜åˆ¶ä¸»æ–‡æœ¬
        draw.text((x, y), line, fill=english_color)
    
    y_position += len(english_lines) * english_font.char_height + 20
    
    # ç»˜åˆ¶ä¸­æ–‡ç¿»è¯‘
    for i, line in enumerate(chinese_lines):
        text_width = len(line) * chinese_font.char_width
        x = text_bg_x + (text_bg_width - text_width) // 2
        y = y_position + i * chinese_font.char_height
        
        # ç»˜åˆ¶æ–‡æœ¬é˜´å½±
        for dx in [-1, 0, 1]:
            for dy in [-1, 0, 1]:
                if dx == 0 and dy == 0:
                    continue
                draw.text((x + dx, y + dy), line, fill=shadow_color)
        
        draw.text((x, y), line, fill=chinese_color)
    
    y_position += len(chinese_lines) * chinese_font.char_height + 15
    
    # ç»˜åˆ¶éŸ³æ ‡
    for i, line in enumerate(phonetic_lines):
        text_width = len(line) * phonetic_font.char_width
        x = text_bg_x + (text_bg_width - text_width) // 2
        y = y_position + i * phonetic_font.char_height
        
        # ç»˜åˆ¶æ–‡æœ¬é˜´å½±
        for dx in [-1, 0, 1]:
            for dy in [-1, 0, 1]:
                if dx == 0 and dy == 0:
                    continue
                draw.text((x + dx, y + dy), line, fill=shadow_color)
        
        draw.text((x, y), line, fill=phonetic_color)
    
    # æ·»åŠ åº•éƒ¨ä¿¡æ¯
    info_text = "æ—…æ¸¸è‹±è¯­å­¦ä¹ è§†é¢‘"
    info_width = len(info_text) * 10
    info_x = (width - info_width) // 2
    info_y = height - 40
    
    # ä¿¡æ¯æ–‡æœ¬é˜´å½±
    for dx in [-1, 0, 1]:
        for dy in [-1, 0, 1]:
            if dx == 0 and dy == 0:
                continue
            draw.text((info_x + dx, info_y + dy), info_text, fill=(0, 0, 0))
    
    draw.text((info_x, info_y), info_text, fill=(150, 150, 150))
    
    return img

def generate_video_from_dataframe(df, video_title, settings):
    """ä»DataFrameç”Ÿæˆè§†é¢‘"""
    # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶è€Œä¸æ˜¯å†…å­˜ç¼“å†²åŒº
    with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_file:
        temp_path = temp_file.name
    
    try:
        width, height = settings['resolution']
        fps = settings['fps']
        duration_per_sentence = settings['duration_per_sentence']
        
        # å‡†å¤‡èƒŒæ™¯å›¾ç‰‡
        bg_image = None
        if settings['background_type'] == 'image' and st.session_state.background_image:
            try:
                bg_image = Image.open(st.session_state.background_image).convert('RGB')
            except:
                bg_image = None
        
        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨ - ç›´æ¥å†™å…¥æ–‡ä»¶
        with imageio.get_writer(temp_path, fps=fps, 
                              codec='libx264', 
                              quality=8,
                              macro_block_size=1) as writer:  # é¿å…åˆ†è¾¨ç‡æ•´é™¤é—®é¢˜
            
            total_frames = len(df) * duration_per_sentence * fps + 3 * fps
            current_frame = 0
            
            # ä¸ºæ¯ä¸ªå¥å­ç”Ÿæˆè§†é¢‘å¸§
            for idx, row in df.iterrows():
                english = str(row['è‹±è¯­']) if pd.notna(row['è‹±è¯­']) else ""
                chinese = str(row['ä¸­æ–‡']) if pd.notna(row['ä¸­æ–‡']) else ""
                phonetic = str(row['éŸ³æ ‡']) if pd.notna(row['éŸ³æ ‡']) and str(row['éŸ³æ ‡']) != 'nan' else ""
                
                frames_for_sentence = duration_per_sentence * fps
                
                for frame_idx in range(frames_for_sentence):
                    frame_img = create_video_frame(
                        english, chinese, phonetic, width, height,
                        bg_color=settings['bg_color'],
                        bg_image=bg_image,
                        english_color=settings['english_color'],
                        chinese_color=settings['chinese_color'],
                        phonetic_color=settings['phonetic_color'],
                        english_size=settings['english_size'],
                        chinese_size=settings['chinese_size'],
                        phonetic_size=settings['phonetic_size'],
                        text_bg_color=settings['text_bg_color'],
                        text_bg_radius=settings['text_bg_radius']
                    )
                    
                    frame_array = np.array(frame_img)
                    writer.append_data(frame_array)
                    
                    current_frame += 1
                    yield current_frame / total_frames
            
            # æ·»åŠ ç»“æŸå¸§
            end_frames = 3 * fps
            end_img = create_end_frame(width, height, len(df), video_title, settings)
            for i in range(end_frames):
                end_array = np.array(end_img)
                writer.append_data(end_array)
                yield (total_frames - 3 * fps + i) / total_frames
        
        # è¯»å–ç”Ÿæˆçš„æ–‡ä»¶åˆ°å†…å­˜
        with open(temp_path, 'rb') as f:
            video_buffer = BytesIO(f.read())
        
        return video_buffer
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.unlink(temp_path)
        except:
            pass

def create_end_frame(width, height, sentence_count, title, settings):
    """åˆ›å»ºç»“æŸå¸§"""
    if settings['background_type'] == 'image' and st.session_state.background_image:
        try:
            img = Image.open(st.session_state.background_image).convert('RGB')
            img = img.resize((width, height))
        except:
            img = Image.new('RGB', (width, height), color=settings['bg_color'])
    else:
        img = Image.new('RGB', (width, height), color=settings['bg_color'])
    
    draw = ImageDraw.Draw(img)
    
    # ç»“æŸæ–‡å­—
    texts = [
        ("è§†é¢‘ç»“æŸ", settings['chinese_color']),
        (f"å…±å­¦ä¹  {sentence_count} ä¸ªå¥å­", (200, 200, 200)),
        ("è°¢è°¢è§‚çœ‹", settings['phonetic_color']),
        (title, settings['english_color'])
    ]
    
    # è®¡ç®—æ€»é«˜åº¦
    total_height = sum([60 if i == 3 else 40 for i in range(len(texts))]) + 20 * (len(texts) - 1)
    y_start = (height - total_height) // 2
    
    for i, (text, color) in enumerate(texts):
        font_size = 60 if i == 3 else 40  # æ ‡é¢˜ç”¨å¤§å­—å·
        font = create_custom_font(font_size)
        text_width = len(text) * font.char_width
        x = (width - text_width) // 2
        y = y_start
        
        # æ–‡æœ¬é˜´å½±
        shadow_color = (0, 0, 0)
        for dx in [-1, 0, 1]:
            for dy in [-1, 0, 1]:
                if dx == 0 and dy == 0:
                    continue
                draw.text((x + dx, y + dy), text, fill=shadow_color)
        
        draw.text((x, y), text, fill=color)
        y_start += font_size + 20
    
    return img

def get_video_download_link(video_buffer, filename):
    """ç”Ÿæˆè§†é¢‘ä¸‹è½½é“¾æ¥"""
    video_buffer.seek(0)
    b64 = base64.b64encode(video_buffer.read()).decode()
    href = f'<a href="data:video/mp4;base64,{b64}" download="{filename}" style="background-color: #4CAF50; color: white; padding: 14px 20px; text-align: center; text-decoration: none; display: inline-block; border-radius: 5px; font-size: 16px; margin: 10px;">ğŸ“¥ ä¸‹è½½MP4è§†é¢‘æ–‡ä»¶</a>'
    return href

def hex_to_rgb(hex_color):
    """å°†åå…­è¿›åˆ¶é¢œè‰²è½¬æ¢ä¸ºRGB"""
    hex_color = hex_color.lstrip('#')
    return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))

def hex_to_rgba(hex_color, alpha=255):
    """å°†åå…­è¿›åˆ¶é¢œè‰²è½¬æ¢ä¸ºRGBA"""
    rgb = hex_to_rgb(hex_color)
    return rgb + (alpha,)

if uploaded_file is not None:
    try:
        df = pd.read_excel(uploaded_file)
        
        required_columns = ['è‹±è¯­', 'ä¸­æ–‡', 'éŸ³æ ‡']
        if all(col in df.columns for col in required_columns):
            st.success(f"âœ… æ–‡ä»¶éªŒè¯æˆåŠŸï¼å…±æ‰¾åˆ° {len(df)} æ¡å¥å­")
            
            st.subheader("ğŸ“Š æ•°æ®é¢„è§ˆ")
            st.dataframe(df.head(10), use_container_width=True)
            
            # è§†é¢‘è®¾ç½®
            st.header("âš™ï¸ ç¬¬äºŒæ­¥ï¼šè§†é¢‘è®¾ç½®")
            
            # åŸºç¡€è®¾ç½®
            col1, col2 = st.columns(2)
            
            with col1:
                video_title = st.text_input("è§†é¢‘æ ‡é¢˜", "æ—…æ¸¸è‹±è¯­å­¦ä¹ è§†é¢‘")
                resolution_option = st.selectbox("åˆ†è¾¨ç‡", ["720p (1280x720)", "1080p (1920x1080)"])
                fps = st.selectbox("å¸§ç‡", [24, 30], index=0)
                duration_per_sentence = st.slider("æ¯å¥æ˜¾ç¤ºæ—¶é—´(ç§’)", 3, 10, 5)
                
            with col2:
                background_type = st.radio("èƒŒæ™¯ç±»å‹", ["çº¯è‰²èƒŒæ™¯", "å›¾ç‰‡èƒŒæ™¯"])
                if background_type == "å›¾ç‰‡èƒŒæ™¯":
                    bg_upload = st.file_uploader("ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡", type=['jpg', 'jpeg', 'png'], key="bg_upload")
                    if bg_upload:
                        st.session_state.background_image = bg_upload
                        st.image(bg_upload, caption="èƒŒæ™¯å›¾ç‰‡é¢„è§ˆ", width=300)
            
            # èƒŒæ™¯é¢œè‰²è®¾ç½®ï¼ˆçº¯è‰²èƒŒæ™¯æ—¶æ˜¾ç¤ºï¼‰
            if background_type == "çº¯è‰²èƒŒæ™¯":
                bg_color = st.color_picker("èƒŒæ™¯é¢œè‰²", "#000000")
                bg_color_rgb = hex_to_rgb(bg_color)
            else:
                bg_color_rgb = (0, 0, 0)  # å›¾ç‰‡èƒŒæ™¯æ—¶ä½¿ç”¨é»‘è‰²ä½œä¸ºfallback
            
            # æ–‡å­—æ ·å¼è®¾ç½®
            st.subheader("ğŸ¨ æ–‡å­—æ ·å¼è®¾ç½®")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("**è‹±è¯­è®¾ç½®**")
                english_color = st.color_picker("è‹±è¯­é¢œè‰²", "#FFFFFF", key="english")
                english_size = st.slider("è‹±è¯­å­—å·", 30, 100, 60, key="english_size")
                
            with col2:
                st.markdown("**ä¸­æ–‡è®¾ç½®**")
                chinese_color = st.color_picker("ä¸­æ–‡é¢œè‰²", "#00FFFF", key="chinese")
                chinese_size = st.slider("ä¸­æ–‡å­—å·", 20, 80, 45, key="chinese_size")
                
            with col3:
                st.markdown("**éŸ³æ ‡è®¾ç½®**")
                phonetic_color = st.color_picker("éŸ³æ ‡é¢œè‰²", "#FFFF00", key="phonetic")
                phonetic_size = st.slider("éŸ³æ ‡å­—å·", 20, 60, 35, key="phonetic_size")
            
            # æ–‡æœ¬èƒŒæ™¯è®¾ç½®
            st.subheader("ğŸ–¼ï¸ æ–‡æœ¬èƒŒæ™¯è®¾ç½®")
            col1, col2 = st.columns(2)
            
            with col1:
                text_bg_color = st.color_picker("æ–‡æœ¬èƒŒæ™¯é¢œè‰²", "#000000")
                text_bg_alpha = st.slider("èƒŒæ™¯é€æ˜åº¦", 0, 255, 180, key="text_bg_alpha")
                
            with col2:
                text_bg_radius = st.slider("åœ†è§’åŠå¾„", 0, 50, 20, key="text_bg_radius")
            
            text_bg_rgba = hex_to_rgba(text_bg_color, text_bg_alpha)
            
            # è§†é¢‘é¢„è§ˆ
            st.subheader("ğŸ¥ å®æ—¶é¢„è§ˆ")
            if len(df) > 0:
                preview_col1, preview_col2 = st.columns(2)
                
                with preview_col1:
                    # åˆ›å»ºé¢„è§ˆå¸§
                    preview_bg_image = None
                    if background_type == "å›¾ç‰‡èƒŒæ™¯" and st.session_state.background_image:
                        try:
                            preview_bg_image = Image.open(st.session_state.background_image).convert('RGB')
                        except:
                            preview_bg_image = None
                    
                    preview_frame = create_video_frame(
                        str(df.iloc[0]['è‹±è¯­']), 
                        str(df.iloc[0]['ä¸­æ–‡']), 
                        str(df.iloc[0]['éŸ³æ ‡']),
                        width=600, height=400,
                        bg_color=bg_color_rgb,
                        bg_image=preview_bg_image,
                        english_color=hex_to_rgb(english_color),
                        chinese_color=hex_to_rgb(chinese_color),
                        phonetic_color=hex_to_rgb(phonetic_color),
                        english_size=english_size,
                        chinese_size=chinese_size,
                        phonetic_size=phonetic_size,
                        text_bg_color=text_bg_rgba,
                        text_bg_radius=text_bg_radius
                    )
                    st.image(preview_frame, caption="å®æ—¶é¢„è§ˆ - ç¬¬ä¸€å¥", use_column_width=True)
                
                with preview_col2:
                    st.info("""
                    **é¢„è§ˆè¯´æ˜ï¼š**
                    - å·¦ä¾§æ˜¾ç¤ºå½“å‰è®¾ç½®çš„æ•ˆæœ
                    - æ–‡å­—ç°åœ¨æœ‰åœ†è§’èƒŒæ™¯åŒºåŸŸ
                    - å­—å·å˜åŒ–åº”è¯¥æ˜æ˜¾å¯è§
                    - ä¸­æ–‡å’ŒéŸ³æ ‡åº”è¯¥æ­£å¸¸æ˜¾ç¤º
                    """)
            
            # ç”Ÿæˆè®¾ç½®
            resolution_map = {
                "720p (1280x720)": (1280, 720),
                "1080p (1920x1080)": (1920, 1080)
            }
            
            settings = {
                'resolution': resolution_map[resolution_option],
                'fps': fps,
                'duration_per_sentence': duration_per_sentence,
                'background_type': 'color' if background_type == "çº¯è‰²èƒŒæ™¯" else 'image',
                'bg_color': bg_color_rgb,
                'english_color': hex_to_rgb(english_color),
                'chinese_color': hex_to_rgb(chinese_color),
                'phonetic_color': hex_to_rgb(phonetic_color),
                'english_size': english_size,
                'chinese_size': chinese_size,
                'phonetic_size': phonetic_size,
                'text_bg_color': text_bg_rgba,
                'text_bg_radius': text_bg_radius
            }
            
            # ç”ŸæˆæŒ‰é’®
            st.header("ğŸ¬ ç¬¬ä¸‰æ­¥ï¼šç”ŸæˆMP4è§†é¢‘")
            
            if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆè§†é¢‘", type="primary", use_container_width=True):
                progress_bar = st.progress(0)
                status_text = st.empty()
                time_estimate = st.empty()
                
                total_frames = len(df) * duration_per_sentence * fps + 3 * fps
                estimated_time = total_frames / fps
                
                st.info(f"""
                **è§†é¢‘è§„æ ¼ï¼š**
                - æ€»æ—¶é•¿: {estimated_time:.1f}ç§’
                - åˆ†è¾¨ç‡: {resolution_option}
                - å¸§ç‡: {fps}fps
                - å¥å­æ•°é‡: {len(df)}å¥
                - èƒŒæ™¯ç±»å‹: {background_type}
                """)
                
                try:
                    progress_generator = generate_video_from_dataframe(df, video_title, settings)
                    
                    start_time = time.time()
                    video_buffer = None
                    
                    for progress in progress_generator:
                        progress_bar.progress(progress)
                        elapsed = time.time() - start_time
                        if progress > 0:
                            total_estimated = elapsed / progress
                            remaining = total_estimated - elapsed
                            status_text.text(f"ç”Ÿæˆè¿›åº¦: {progress*100:.1f}%")
                            time_estimate.text(f"é¢„è®¡å‰©ä½™: {remaining:.0f}ç§’")
                    
                    # è·å–æœ€ç»ˆçš„video_buffer
                    video_buffer = list(progress_generator)[-1] if hasattr(progress_generator, '__next__') else None
                    
                    if video_buffer:
                        st.balloons()
                        st.success("ğŸ‰ MP4è§†é¢‘ç”Ÿæˆå®Œæˆï¼")
                        
                        filename = f"{video_title}.mp4"
                        download_link = get_video_download_link(video_buffer, filename)
                        
                        st.markdown(download_link, unsafe_allow_html=True)
                        
                        # è§†é¢‘ä¿¡æ¯
                        st.subheader("ğŸ“Š ç”Ÿæˆæ€»ç»“")
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("è§†é¢‘æ—¶é•¿", f"{estimated_time:.1f}ç§’")
                        with col2:
                            st.metric("æ–‡ä»¶å¤§å°", f"{len(video_buffer.getvalue()) / (1024*1024):.1f}MB")
                        with col3:
                            st.metric("åˆ†è¾¨ç‡", resolution_option.split(' ')[0])
                        with col4:
                            st.metric("å¸§ç‡", f"{fps}fps")
                    else:
                        st.error("âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼šæ— æ³•åˆ›å»ºè§†é¢‘æ–‡ä»¶")
                    
                except Exception as e:
                    st.error(f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
                    st.info("""
                    **æ•…éšœæ’é™¤å»ºè®®ï¼š**
                    1. å‡å°‘å¥å­æ•°é‡ï¼ˆå»ºè®®5-10å¥ï¼‰
                    2. ä½¿ç”¨720påˆ†è¾¨ç‡
                    3. ç¡®ä¿æœ‰è¶³å¤Ÿçš„å­˜å‚¨ç©ºé—´
                    4. é‡å¯åº”ç”¨é‡è¯•
                    """)
                    
        else:
            st.error("âŒ Excelæ–‡ä»¶å¿…é¡»åŒ…å«'è‹±è¯­','ä¸­æ–‡','éŸ³æ ‡'ä¸‰åˆ—")
            
    except Exception as e:
        st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")

else:
    # æä¾›ç¤ºä¾‹æ–‡ä»¶ä¸‹è½½
    st.header("ğŸ“ ç¤ºä¾‹æ–‡ä»¶")
    
    example_data = {
        'è‹±è¯­': ['Where is the gate?', 'Window seat, please.'],
        'ä¸­æ–‡': ['ç™»æœºå£åœ¨å“ªï¼Ÿ', 'è¯·ç»™æˆ‘é çª—åº§ä½ã€‚'],
        'éŸ³æ ‡': ['/weÉ™ Éªz Ã°É™ É¡eÉªt/', '/ËˆwÉªndÉ™ÊŠ siËt pliËz/']
    }
    example_df = pd.DataFrame(example_data)
    
    st.write("**ç¤ºä¾‹æ•°æ®æ ¼å¼**:")
    st.dataframe(example_df, use_container_width=True)
    
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        example_df.to_excel(writer, index=False, sheet_name='æ—…æ¸¸è‹±è¯­')
    excel_data = output.getvalue()
    
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½ç¤ºä¾‹Excelæ¨¡æ¿",
        data=excel_data,
        file_name="æ—…æ¸¸è‹±è¯­æ¨¡æ¿.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        use_container_width=True
    )

# é¡µè„š
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>ğŸ¬ æ—…æ¸¸è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨ â€¢ ğŸ¨ å®Œå…¨è‡ªå®šä¹‰ â€¢ ğŸ”¤ ä¸­æ–‡æ”¯æŒ</p>
</div>
""", unsafe_allow_html=True)
