import streamlit as st
import pandas as pd
import os
import numpy as np
from PIL import Image, ImageDraw, ImageFont, ImageOps
import imageio.v2 as imageio
import tempfile
import shutil
from pydub import AudioSegment
import subprocess
import traceback
import asyncio

# æ£€æŸ¥ffmpegæ˜¯å¦å¯ç”¨
def check_ffmpeg():
    ffmpeg_path = shutil.which('ffmpeg')  # æ£€æŸ¥ffmpegæ˜¯å¦åœ¨PATHä¸­
    if not ffmpeg_path:
        st.warning("æœªæ£€æµ‹åˆ° ffmpegã€‚è¯·å®‰è£… ffmpeg å¹¶ç¡®ä¿ PATH é…ç½®æ­£ç¡®ã€‚")
    else:
        st.success(f"æ£€æµ‹åˆ° ffmpegï¼š{ffmpeg_path}")
    return ffmpeg_path

# æ£€æŸ¥ffmpeg
check_ffmpeg()  # åœ¨åº”ç”¨å¯åŠ¨æ—¶æ£€æŸ¥ffmpeg

# edge-tts ç”¨äºå¤šéŸ³è‰² TTS
try:
    import edge_tts
    EDGE_TTS_AVAILABLE = True
except Exception:
    EDGE_TTS_AVAILABLE = False

# é¡µé¢é…ç½®
st.set_page_config(page_title="æ—…è¡Œè‹±è¯­è§†é¢‘ç”Ÿæˆå™¨", page_icon="ğŸ¬", layout="wide")

# ä¼šè¯çŠ¶æ€
if 'bg_image' not in st.session_state:
    st.session_state.bg_image = None
if 'audio_available' not in st.session_state:
    st.session_state.audio_available = EDGE_TTS_AVAILABLE

# -----------------------
# å·¥å…·å‡½æ•°
# -----------------------
def wrap_text(text, max_chars):
    if not text or str(text).strip().lower() == 'nan':
        return [""]
    text = str(text).strip()
    if any('\u4e00' <= c <= '\u9fff' for c in text):
        max_chars = min(max_chars, 15)
    words = text.split()
    lines, current = [], []
    for word in words:
        test_line = ' '.join(current + [word])
        if len(test_line) <= max_chars:
            current.append(word)
        else:
            if current:
                lines.append(' '.join(current))
            if len(word) > max_chars:
                for i in range(0, len(word), max_chars):
                    lines.append(word[i:i+max_chars])
                current = []
            else:
                current = [word]
    if current:
        lines.append(' '.join(current))
    return lines

def get_font(size):
    try:
        candidates = [
            "SimHei", "msyh.ttc", "NotoSansCJK-Regular.ttc",
            "WenQuanYi Micro Hei", "Arial Unicode MS", "DejaVuSans.ttf"
        ]
        for f in candidates:
            try:
                return ImageFont.truetype(f, size)
            except Exception:
                continue
        return ImageFont.load_default()
    except:
        return ImageFont.load_default()

def create_frame(english, chinese, phonetic, width=1280, height=720,
                 bg_color=(0,0,0), bg_image=None,
                 eng_color=(255,255,255), chn_color=(0,255,255), pho_color=(255,255,0),
                 eng_size=60, chn_size=50, pho_size=40):
    """
    åˆ›å»ºä¸€å¸§å›¾ç‰‡
    é¡ºåºï¼šè‹±è¯­ï¼ˆä¸Šï¼‰ -> éŸ³æ ‡ï¼ˆä¸­ï¼‰ -> ä¸­æ–‡ï¼ˆä¸‹ï¼‰
    """
    if bg_image:
        try:
            img = ImageOps.fit(bg_image.convert('RGB'), (width, height), Image.Resampling.LANCZOS)
        except Exception:
            img = Image.new('RGB', (width, height), bg_color)
    else:
        img = Image.new('RGB', (width, height), bg_color)

    draw = ImageDraw.Draw(img)
    eng_font = get_font(eng_size)
    chn_font = get_font(chn_size)
    pho_font = get_font(pho_size)

    eng_lines = wrap_text(english, 30)
    chn_lines = wrap_text(chinese, 15)
    pho_lines = wrap_text(phonetic, 35) if phonetic else []

    line_spacing = 10
    total_height = 0

    # è‹±è¯­é«˜åº¦
    for line in eng_lines:
        _, _, _, h = draw.textbbox((0,0), line, font=eng_font)
        total_height += h
    total_height += line_spacing * (len(eng_lines)-1)

    # éŸ³æ ‡é«˜åº¦
    if pho_lines:
        total_height += 20
        for line in pho_lines:
            _, _, _, h = draw.textbbox((0,0), line, font=pho_font)
            total_height += h
        total_height += line_spacing * (len(pho_lines)-1)

    # ä¸­æ–‡é«˜åº¦
    if chn_lines:
        total_height += 20
        for line in chn_lines:
            _, _, _, h = draw.textbbox((0,0), line, font=chn_font)
            total_height += h
        total_height += line_spacing * (len(chn_lines)-1)

    y = (height - total_height)//2

    # ç»˜åˆ¶è‹±è¯­
    for line in eng_lines:
        w, h = draw.textbbox((0,0), line, font=eng_font)[2:]
        x = (width - w)//2
        draw.text((x+1, y+1), line, font=eng_font, fill=(0,0,0,128))
        draw.text((x, y), line, font=eng_font, fill=eng_color)
        y += h + line_spacing

    # éŸ³æ ‡ï¼ˆåœ¨è‹±è¯­ä¸‹ï¼‰
    if pho_lines:
        y += 10
        for line in pho_lines:
            w, h = draw.textbbox((0,0), line, font=pho_font)[2:]
            x = (width - w)//2
            draw.text((x+1, y+1), line, font=pho_font, fill=(0,0,0,128))
            draw.text((x, y), line, font=pho_font, fill=pho_color)
            y += h + line_spacing

    # ä¸­æ–‡ï¼ˆåœ¨éŸ³æ ‡ä¸‹ï¼‰
    if chn_lines:
        y += 10
        for line in chn_lines:
            w, h = draw.textbbox((0,0), line, font=chn_font)[2:]
            x = (width - w)//2
            draw.text((x+1, y+1), line, font=chn_font, fill=(0,0,0,128))
            draw.text((x, y), line, font=chn_font, fill=chn_color)
            y += h + line_spacing

    return img

# -----------------------
# Edge TTS helpers
# -----------------------
VOICE_OPTIONS = {
    "English - Female (US) - aria_us_female": "en-US-AriaNeural",
    "English - Female (US) - Jenny": "en-US-JennyNeural",
    "English - Male (US) - Guy": "en-US-GuyNeural",
    "English - Female (UK) - Kate": "en-GB-LibbyNeural",
    "Chinese - Female (CN) - Xiaoxiao": "zh-CN-XiaoxiaoNeural",
    "Chinese - Male (CN) - Yunfeng": "zh-CN-YunfengNeural"
}

async def _edge_tts_save(ssml_text: str, voice_name: str, out_path: str):
    communicator = edge_tts.Communicate(ssml=ssml_text, voice=voice_name)
    await communicator.save(out_path)

def generate_edge_audio(text, voice, speed=1.0, out_path=None):
    if not EDGE_TTS_AVAILABLE:
        return None
    pct = int((speed - 1.0) * 100)
    pct_str = f"{pct:+d}%"
    ssml = f"<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xml:lang='en-US'>" \
           f"<voice name='{voice}'><prosody rate='{pct_str}'>{escape_xml(text)}</prosody></voice></speak>"
    if out_path is None:
        fd, out_path = tempfile.mkstemp(suffix='.mp3')
        os.close(fd)
    try:
        asyncio.run(_edge_tts_save(ssml, voice, out_path))
        return out_path
    except Exception as e:
        st.warning(f"edge-tts ç”ŸæˆéŸ³é¢‘å¤±è´¥: {e}")
        return None

def escape_xml(s: str):
    return (s.replace("&", "&amp;")
             .replace("<", "&lt;")
             .replace(">", "&gt;")
             .replace("'", "&apos;")
             .replace('"', "&quot;"))

# -----------------------
# éŸ³é¢‘åˆå¹¶ / è§†é¢‘åˆå¹¶
# -----------------------
def merge_audio_files(audio_paths, target_duration):
    combined = AudioSegment.empty()
    for p in audio_paths:
        if not p:
            combined += AudioSegment.silent(duration=int(target_duration*1000))
            continue
        try:
            audio = AudioSegment.from_file(p)
            if len(audio) > target_duration*1000:
                audio = audio[:int(target_duration*1000)]
            else:
                audio = audio + AudioSegment.silent(duration=int(target_duration*1000) - len(audio))
            combined += audio
            try:
                os.remove(p)
            except:
                pass
        except Exception as e:
            st.warning(f"å¤„ç†éŸ³é¢‘ç‰‡æ®µå¤±è´¥: {e}")
            combined += AudioSegment.silent(duration=int(target_duration*1000))
    return combined

def merge_video_audio(video_path, audio_path, output_path):
    if not check_ffmpeg():
        st.error("æœªæ£€æµ‹åˆ° ffmpegï¼Œæ— æ³•åˆå¹¶éŸ³é¢‘ã€‚")
        return None
    cmd = [
        "ffmpeg", "-y",
        "-i", video_path,
        "-i", audio_path,
        "-c:v", "copy",
        "-c:a", "aac",
        "-strict", "experimental",
        output_path
    ]
    try:
        res = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        if res.returncode != 0:
            st.error(f"ffmpeg åˆå¹¶å¤±è´¥: {res.stderr}")
            return None
        return output_path
    except Exception as e:
        st.error(f"è°ƒç”¨ ffmpeg å¤±è´¥: {e}")
        return None

# -----------------------
# UI ä¸ä¸»æµç¨‹
# -----------------------
st.title("ğŸ¬ æ—…è¡Œè‹±è¯­è§†é¢‘ç”Ÿæˆå™¨ï¼ˆæ–‡å­— + èƒŒæ™¯å›¾ï¼Œæ”¯æŒå¤šéŸ³è‰²ï¼‰")
st.markdown("ä¸Šä¼  Excelï¼ˆåˆ—åï¼šè‹±è¯­ã€ä¸­æ–‡ã€éŸ³æ ‡ï¼‰ï¼Œè‡ªå®šä¹‰æ ·å¼ä¸éŸ³è‰²ï¼Œç”Ÿæˆè§†é¢‘å¹¶ä¸‹è½½ã€‚")

# edge-tts çŠ¶æ€
if EDGE_TTS_AVAILABLE:
    st.success("edge-tts å·²å®‰è£…ï¼šæ”¯æŒå¤šéŸ³è‰² TTSã€‚")
else:
    st.warning("æœªæ£€æµ‹åˆ° edge-ttsï¼šå¤šéŸ³è‰²è¯­éŸ³åŠŸèƒ½ä¸å¯ç”¨ã€‚è¯·è¿è¡Œ `pip install edge-tts` å¹¶ç¡®ä¿ç½‘ç»œå¯ç”¨ã€‚")

# æ£€æŸ¥ ffmpeg
check_ffmpeg()  # è°ƒç”¨ffmpegæ£€æµ‹

# ä¸Šä¼  Excel
st.header("1. ä¸Šä¼  Excel æ–‡ä»¶")
uploaded = st.file_uploader("é€‰æ‹© Excel æ–‡ä»¶ï¼ˆå¿…é¡»åŒ…å«åˆ—ï¼šè‹±è¯­ã€ä¸­æ–‡ã€éŸ³æ ‡ï¼‰", type=["xlsx", "xls"])
if uploaded:
    try:
        df = pd.read_excel(uploaded)
    except Exception as e:
        st.error(f"è¯»å– Excel å¤±è´¥ï¼š{e}")
        df = None
else:
    df = None

if df is not None:
    required = ['è‹±è¯­','ä¸­æ–‡','éŸ³æ ‡']
    miss = [c for c in required if c not in df.columns]
    if miss:
        st.error(f"Excel ç¼ºå°‘åˆ—ï¼š{', '.join(miss)}")
        st.stop()
    st.dataframe(df, height=220)

    # è®¾ç½®é¢æ¿
    st.header("2. è‡ªå®šä¹‰è®¾ç½®")
    col_bg, col_txt = st.columns([1,2])

    with col_bg:
        bg_type = st.radio("èƒŒæ™¯ç±»å‹", ["çº¯è‰²","å›¾ç‰‡"], index=1)
        if bg_type == "çº¯è‰²":
            bg_hex = st.color_picker("èƒŒæ™¯é¢œè‰²", "#000000")
            bg_color = tuple(int(bg_hex[i:i+2],16) for i in (1,3,5))
            st.session_state.bg_image = None
        else:
            bg_file = st.file_uploader("ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡ (jpg/png)", type=["jpg","jpeg","png"], key="bg_img")
            if bg_file:
                try:
                    st.session_state.bg_image = Image.open(bg_file)
                    st.image(st.session_state.bg_image, caption="èƒŒæ™¯é¢„è§ˆ", use_column_width=False, width=300)
                except Exception as e:
                    st.error(f"æ‰“å¼€èƒŒæ™¯å›¾ç‰‡å¤±è´¥ï¼š{e}")
                    st.session_state.bg_image = None
            bg_color = (0,0,0)

    with col_txt:
        st.subheader("æ–‡å­—æ ·å¼ï¼ˆè‹±è¯­ / éŸ³æ ‡ / ä¸­æ–‡ï¼‰")
        c1, c2, c3 = st.columns(3)
        with c1:
            eng_color = st.color_picker("è‹±è¯­é¢œè‰²", "#FFFFFF")
            eng_color = tuple(int(eng_color[i:i+2],16) for i in (1,3,5))
            eng_size = st.slider("è‹±è¯­å­—å·", 20, 100, 60)
        with c2:
            pho_color = st.color_picker("éŸ³æ ‡é¢œè‰²", "#FFFF00")
            pho_color = tuple(int(pho_color[i:i+2],16) for i in (1,3,5))
            pho_size = st.slider("éŸ³æ ‡å­—å·", 16, 80, 40)
        with c3:
            chn_color = st.color_picker("ä¸­æ–‡é¢œè‰²", "#00FFFF")
            chn_color = tuple(int(chn_color[i:i+2],16) for i in (1,3,5))
            chn_size = st.slider("ä¸­æ–‡å­—å·", 20, 100, 50)

    st.subheader("éŸ³é¢‘è®¾ç½®ï¼ˆå¤šéŸ³è‰²ï¼‰")
    col_a1, col_a2, col_a3 = st.columns(3)
    with col_a1:
        tts_lang = st.selectbox("è¯­éŸ³è¯­è¨€", ["è‹±è¯­","ä¸­æ–‡"])
    with col_a2:
        # é€‰æ‹© voiceï¼ˆä» VOICE_OPTIONS ä¸­ç­›é€‰è¯­è¨€åŒ¹é…é¡¹ï¼‰
        voice_choices = {k:v for k,v in VOICE_OPTIONS.items() if (("English" in k and tts_lang=="è‹±è¯­") or ("Chinese" in k and tts_lang=="ä¸­æ–‡") or (tts_lang=="è‹±è¯­" and "English" in k) or (tts_lang=="ä¸­æ–‡" and "Chinese" in k))}
        voice_label = st.selectbox("éŸ³è‰² (ç¤ºä¾‹)", list(voice_choices.keys()))
        voice_name = voice_choices[voice_label]
    with col_a3:
        tts_speed = st.slider("è¯­é€Ÿ (0.5-2.0)", 0.5, 2.0, 1.0)

    st.subheader("è§†é¢‘å‚æ•°")
    col_v1, col_v2 = st.columns(2)
    with col_v1:
        per_duration = st.slider("æ¯å¥æ—¶é•¿ï¼ˆç§’ï¼‰", 2, 8, 4)
        fps = st.slider("å¸§ç‡", 8, 30, 20)
    with col_v2:
        width = st.selectbox("åˆ†è¾¨ç‡å®½åº¦", [640, 960, 1280], index=2)
        height = int(width * 9 / 16)

    # é¢„è§ˆå•è¡Œ
    st.header("3. é¢„è§ˆå•è¡Œ")
    if not df.empty:
        idx = st.slider("é€‰æ‹©è¦é¢„è§ˆçš„è¡Œ", 0, len(df)-1, 0)
        row = df.iloc[idx]
        preview_img = create_frame(
            english=str(row['è‹±è¯­']),
            chinese=str(row['ä¸­æ–‡']),
            phonetic=str(row['éŸ³æ ‡']) if pd.notna(row['éŸ³æ ‡']) else "",
            width=width, height=height,
            bg_color=bg_color, bg_image=st.session_state.bg_image,
            eng_color=eng_color, chn_color=chn_color, pho_color=pho_color,
            eng_size=eng_size, chn_size=chn_size, pho_size=pho_size
        )
        st.image(preview_img, caption="å¸§é¢„è§ˆ", use_column_width=False, width=width//2)

    # ç”ŸæˆæŒ‰é’®
    st.header("4. ç”Ÿæˆè§†é¢‘")
    if st.button("å¼€å§‹ç”Ÿæˆè§†é¢‘"):
        with st.spinner("æ­£åœ¨ç”Ÿæˆ â€” ä¼šä¸ºæ¯è¡Œç”Ÿæˆå¸§å’ŒéŸ³é¢‘ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼ˆå»ºè®®å…ˆç”¨å°‘é‡è¡Œæµ‹è¯•ï¼‰"):
            try:
                with tempfile.TemporaryDirectory() as tmpdir:
                    frames = []
                    audio_paths = []
                    total_frames = len(df) * per_duration * fps
                    progress = st.progress(0)
                    current = 0

                    # é€è¡Œç”Ÿæˆ
                    for i, row in df.iterrows():
                        eng = str(row['è‹±è¯­'])
                        chn = str(row['ä¸­æ–‡'])
                        pho = str(row['éŸ³æ ‡']) if pd.notna(row['éŸ³æ ‡']) else ""

                        # åˆ›å»ºä¸€å¼ å¸§å›¾
                        frame_img = create_frame(
                            english=eng, chinese=chn, phonetic=pho,
                            width=width, height=height,
                            bg_color=bg_color, bg_image=st.session_state.bg_image,
                            eng_color=eng_color, chn_color=chn_color, pho_color=pho_color,
                            eng_size=eng_size, chn_size=chn_size, pho_size=pho_size
                        )
                        # é‡å¤å¸§ä»¥è¾¾åˆ°æ—¶é—´
                        for _ in range(per_duration * fps):
                            frames.append(np.array(frame_img.convert('RGB')))

                        # ç”ŸæˆéŸ³é¢‘ï¼ˆedge-ttsï¼‰
                        audio_file = None
                        if EDGE_TTS_AVAILABLE:
                            # æŠŠè¦è¯»çš„æ–‡æœ¬æŒ‰è¯­è¨€é€‰æ‹©ä¸åŒå­—æ®µï¼ˆä¼˜å…ˆè‹±è¯­ï¼Œå¦‚æœæƒ³è¯»ä¸­æ–‡å¯æ”¹ï¼‰
                            speak_text = eng if tts_lang == "è‹±è¯­" else chn
                            audio_file = generate_edge_audio(speak_text, voice_name, speed=tts_speed)
                        audio_paths.append(audio_file)

                        current += per_duration * fps
                        progress.progress(min(current/total_frames, 1.0))

                    # ä¿å­˜æ— å£°è§†é¢‘ï¼ˆä¸´æ—¶ï¼‰
                    video_no_audio = os.path.join(tmpdir, "video_no_audio.mp4")
                    imageio.mimsave(video_no_audio, frames, fps=fps)

                    final_video = video_no_audio
                    # è‹¥æœ‰éŸ³é¢‘ä¸” ffmpeg å¯ç”¨ï¼Œåˆ™åˆå¹¶
                    if any(p for p in audio_paths if p is not None) and check_ffmpeg():
                        combined = merge_audio_files(audio_paths, per_duration)
                        audio_out = os.path.join(tmpdir, "combined.mp3")
                        combined.export(audio_out, format="mp3")
                        video_with_audio = os.path.join(tmpdir, "video_with_audio.mp4")
                        merged = merge_video_audio(video_no_audio, audio_out, video_with_audio)
                        if merged:
                            final_video = merged

                    # è¯»å–è§†é¢‘å¹¶å±•ç¤ºä¸ä¸‹è½½
                    with open(final_video, "rb") as f:
                        video_bytes = f.read()

                    st.success("è§†é¢‘ç”Ÿæˆå®Œæˆï¼")
                    st.video(video_bytes)
                    st.download_button("ä¸‹è½½è§†é¢‘", data=video_bytes, file_name="travel_english_video.mp4", mime="video/mp4")
                    progress.progress(1.0)

            except Exception as e:
                st.error(f"ç”Ÿæˆå¤±è´¥: {e}")
                st.text(traceback.format_exc())
