# ---------- åŸºæœ¬å¯¼å…¥ ----------
import os
import sys
import io
import json
import time
import math
import shutil
import hashlib
import tempfile
import asyncio
import traceback
import subprocess
from queue import Queue
from threading import Thread
from typing import List, Dict, Tuple, Optional

import streamlit as st
import pandas as pd
import numpy as np
from PIL import Image, ImageDraw, ImageFont, ImageOps, ImageColor

# imageio import (video writing later)
import imageio.v2 as imageio

# ---------- é…ç½® & å¸¸é‡ ----------
LIGHTWEIGHT_MODE = True  # å¯ç”¨è½»é‡æ¨¡å¼ï¼Œå‡å°‘ä¾èµ–

# å…¼å®¹ Streamlit Cloud çš„ä¸´æ—¶ç›®å½•å¤„ç†
APP_TMP = os.path.join(tempfile.gettempdir(), "english_video_app")
CACHE_DIR = os.path.join(APP_TMP, "cache")
SAMPLES_DIR = os.path.join(APP_TMP, "samples")
TEMPLATE_DIR = os.path.join(APP_TMP, "templates")
PROGRESS_FILE = os.path.join(APP_TMP, "learning_progress.json")

for p in (APP_TMP, CACHE_DIR, SAMPLES_DIR, TEMPLATE_DIR):
    os.makedirs(p, exist_ok=True)

# ---------- å¯é€‰ä¾èµ–æ£€æµ‹ ----------
try:
    import pyttsx3
    PYTTSX3_AVAILABLE = True
except Exception:
    PYTTSX3_AVAILABLE = False

try:
    import edge_tts
    EDGE_TTS_AVAILABLE = True
except Exception:
    EDGE_TTS_AVAILABLE = False

try:
    from pydub import AudioSegment
    PYDUB_AVAILABLE = True
except Exception:
    PYDUB_AVAILABLE = False

# ---------- ç®€åŒ–ç‰ˆ FFmpeg æ£€æµ‹ ----------
def ffmpeg_available() -> bool:
    """ç®€åŒ–ç‰ˆFFmpegæ£€æµ‹ï¼Œä¸å¼ºåˆ¶ä¾èµ–"""
    try:
        result = subprocess.run(["ffmpeg", "-version"], capture_output=True, timeout=5)
        return result.returncode == 0
    except:
        return False

# ---------- é«˜çº§UI theme & CSS ----------
PRIMARY_LIGHT = "#f8faff"
SECONDARY_LIGHT = "#f0f4ff"
ACCENT_PRIMARY = "#7c3aed"
ACCENT_SECONDARY = "#4f46e5"
ACCENT_GRADIENT_START = "#8b5cf6"
ACCENT_GRADIENT_END = "#6366f1"
SUCCESS_COLOR = "#10b981"
WARNING_COLOR = "#f59e0b"
ERROR_COLOR = "#ef4444"
CARD_BG = "rgba(255, 255, 255, 0.85)"
TEXT_DARK = "#1e293b"
TEXT_MUTED = "#64748b"
BORDER_COLOR = "rgba(99, 102, 241, 0.2)"

st.set_page_config(
    page_title="ğŸ¬ è‹±è¯­å­¦ä¹ è§†é¢‘ç”Ÿæˆå™¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown(f"""
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700&display=swap');
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+IPA:wght@400;700&display=swap');

:root {{
  --primary-light: {PRIMARY_LIGHT};
  --secondary-light: {SECONDARY_LIGHT};
  --accent-primary: {ACCENT_PRIMARY};
  --accent-secondary: {ACCENT_SECONDARY};
  --gradient-start: {ACCENT_GRADIENT_START};
  --gradient-end: {ACCENT_GRADIENT_END};
  --text-dark: {TEXT_DARK};
  --text-muted: {TEXT_MUTED};
  --card-bg: {CARD_BG};
  --border-color: {BORDER_COLOR};
}}

* {{
    font-family: 'Noto Sans SC', sans-serif !important;
}}

.stApp {{
  background: linear-gradient(135deg, {PRIMARY_LIGHT} 0%, {SECONDARY_LIGHT} 100%) !important;
  color: {TEXT_DARK} !important;
}}

.main-title {{
  background: linear-gradient(135deg, var(--gradient-start), var(--gradient-end));
  color: white;
  padding: 20px;
  border-radius: 16px;
  font-size: 24px;
  font-weight: 700;
  text-align: center;
  margin-bottom: 20px;
  box-shadow: 0 8px 25px rgba(99, 102, 241, 0.2);
}}

.card {{
  background: var(--card-bg);
  border-radius: 16px;
  padding: 20px;
  margin-bottom: 16px;
  border: 1px solid var(--border-color);
  box-shadow: 0 4px 20px rgba(99, 102, 241, 0.1);
}}

.card-header {{
  font-size: 18px;
  font-weight: 700;
  margin-bottom: 16px;
  color: {TEXT_DARK};
  display: flex;
  align-items: center;
  gap: 8px;
  padding-bottom: 12px;
  border-bottom: 1px solid var(--border-color);
}}

div.stButton > button {{
  background: linear-gradient(135deg, var(--gradient-start), var(--gradient-end));
  color: white;
  border-radius: 10px;
  padding: 10px 20px;
  font-weight: 600;
  border: none;
  transition: all 0.3s ease;
  box-shadow: 0 2px 10px rgba(99, 102, 241, 0.3);
  font-size: 14px;
}}

div.stButton > button:hover {{
  transform: translateY(-1px);
  box-shadow: 0 4px 15px rgba(99, 102, 241, 0.4);
}}

.stSuccess {{
  background: rgba(16, 185, 129, 0.1);
  border: 1px solid rgba(16, 185, 129, 0.3);
  border-radius: 10px;
  padding: 16px;
}}

.stInfo {{
  background: rgba(99, 102, 241, 0.1);
  border: 1px solid rgba(99, 102, 241, 0.3);
  border-radius: 10px;
  padding: 16px;
}}

.stWarning {{
  background: rgba(245, 158, 11, 0.1);
  border: 1px solid rgba(245, 158, 11, 0.3);
  border-radius: 10px;
  padding: 16px;
}}

/* å¯æ»šåŠ¨å†…å®¹åŒºåŸŸ */
.scrollable-content {{
  max-height: 400px;
  overflow-y: auto;
  padding-right: 8px;
}}

.scrollable-content::-webkit-scrollbar {{
  width: 6px;
}}

.scrollable-content::-webkit-scrollbar-track {{
  background: rgba(99, 102, 241, 0.1);
  border-radius: 3px;
}}

.scrollable-content::-webkit-scrollbar-thumb {{
  background: var(--accent-primary);
  border-radius: 3px;
}}

/* å®æ—¶é¢„è§ˆåŒºåŸŸ */
.live-preview-container {{
  background: rgba(255, 255, 255, 0.95);
  border-radius: 16px;
  padding: 20px;
  border: 2px solid var(--border-color);
  box-shadow: 0 8px 25px rgba(99, 102, 241, 0.1);
  height: 100%;
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
}}

.live-preview-title {{
  font-size: 18px;
  font-weight: 700;
  margin-bottom: 20px;
  color: {TEXT_DARK};
  text-align: center;
}}

.live-preview-image {{
  max-width: 100%;
  max-height: 300px;
  border-radius: 12px;
  box-shadow: 0 6px 20px rgba(0, 0, 0, 0.12);
  margin-bottom: 20px;
}}

.live-preview-text {{
  text-align: center;
  margin: 8px 0;
  font-size: 16px;
}}

.live-preview-english {{
  font-size: 22px;
  font-weight: 700;
  color: {TEXT_DARK};
  font-family: 'Arial', sans-serif;
}}

.live-preview-phonetic {{
  font-size: 16px;
  color: {TEXT_MUTED};
  font-style: italic;
  font-family: 'Noto Sans IPA', 'Arial Unicode MS', sans-serif;
  font-weight: 400;
}}

.live-preview-chinese {{
  font-size: 18px;
  color: {TEXT_DARK};
  font-family: 'Noto Sans SC', sans-serif;
}}
</style>
""", unsafe_allow_html=True)

# ---------- å…¬å…±å·¥å…·å‡½æ•° ----------
def now_ts() -> int:
    return int(time.time())

def ensure_dir(p: str):
    os.makedirs(p, exist_ok=True)

def safe_remove(path: str):
    try:
        if os.path.isdir(path):
            shutil.rmtree(path)
        elif os.path.exists(path):
            os.remove(path)
    except Exception:
        pass

def hash_text_meta(text: str, voice: str, speed: float, extra: dict = None) -> str:
    j = json.dumps({"t": text, "v": voice, "s": speed, "e": extra or {}}, ensure_ascii=False, sort_keys=True)
    return hashlib.sha256(j.encode("utf-8")).hexdigest()

def cache_get(key: str) -> str:
    return os.path.join(CACHE_DIR, f"{key}.mp3")

def cache_exists(key: str) -> bool:
    p = cache_get(key)
    return os.path.exists(p) and os.path.getsize(p) > 0

def cache_store(src: str, key: str):
    dst = cache_get(key)
    try:
        shutil.copy(src, dst)
    except Exception:
        pass

# ---------- å­—ä½“å¤„ç† ----------
def get_default_font():
    """è·å–é»˜è®¤å­—ä½“ï¼Œä¼˜å…ˆä½¿ç”¨Google Fonts"""
    return None  # ä½¿ç”¨CSSä¸­å®šä¹‰çš„å­—ä½“

def load_font(size, font_path=None):
    """åŠ è½½å­—ä½“"""
    try:
        # ä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿå­—ä½“
        system_fonts = [
            "NotoSansSC-Regular.ttf", "Arial.ttf", "simhei.ttf", "msyh.ttc"
        ]
        
        for font_name in system_fonts:
            try:
                return ImageFont.truetype(font_name, size)
            except:
                continue
                
        # ä½¿ç”¨é»˜è®¤å­—ä½“
        return ImageFont.load_default()
    except Exception as e:
        return ImageFont.load_default()

def load_phonetic_font(size):
    """åŠ è½½éŸ³æ ‡å­—ä½“"""
    try:
        # å°è¯•åŠ è½½éŸ³æ ‡ä¸“ç”¨å­—ä½“
        phonetic_fonts = [
            "NotoSansIPA-Regular.ttf", "Arial.ttf", "Times.ttf"
        ]
        
        for font_name in phonetic_fonts:
            try:
                return ImageFont.truetype(font_name, size)
            except:
                continue
                
        return load_font(size)
    except:
        return load_font(size)

# ---------- è¯­éŸ³ / é¢„è®¾åº“ ----------
EN_MALE = [
    "en-US-GuyNeural", "en-US-BenjaminNeural", "en-GB-RyanNeural",
]
EN_FEMALE = [
    "en-US-JennyNeural", "en-US-AriaNeural", "en-GB-SoniaNeural",
]
ZH_VOICES = [
    "zh-CN-XiaoxiaoNeural", "zh-CN-YunxiNeural", "zh-CN-XiaoyiNeural",
]

VOICE_STYLES = {
    "en-US-JennyNeural": "ç¾å¼è‹±è¯­ï¼Œæ¸…æ™°è‡ªç„¶",
    "en-US-AriaNeural": "ç¾å¼è‹±è¯­ï¼Œæ¸©æš–äº²åˆ‡", 
    "en-GB-SoniaNeural": "è‹±å¼è‹±è¯­ï¼Œä¼˜é›…çŸ¥æ€§",
    "en-US-GuyNeural": "ç¾å¼è‹±è¯­ï¼Œæ²‰ç¨³ä¸“ä¸š",
    "en-US-BenjaminNeural": "ç¾å¼è‹±è¯­ï¼Œæ¸©æš–å¯é ",
    "en-GB-RyanNeural": "è‹±å¼è‹±è¯­ï¼Œæ ‡å‡†ä¼˜é›…",
    "zh-CN-XiaoxiaoNeural": "æ™®é€šè¯ï¼Œç”œç¾å°‘å¥³éŸ³",
    "zh-CN-YunxiNeural": "æ™®é€šè¯ï¼Œæ¸©æš–é’å¹´éŸ³",
    "zh-CN-XiaoyiNeural": "æ™®é€šè¯ï¼Œæ´»æ³¼å°‘å¥³",
}

VOICE_LIBRARY = {
    "è‹±æ–‡å¥³å£°": EN_FEMALE, 
    "è‹±æ–‡ç”·å£°": EN_MALE, 
    "ä¸­æ–‡éŸ³è‰²": ZH_VOICES,
}

PRESET_MODES = {
    "åŸºç¡€å­¦ä¹ æ¨¡å¼": [
        {"content":"è‹±è¯­","category":"è‹±æ–‡å¥³å£°","speed":1.0,"pause":0.3},
        {"content":"éŸ³æ ‡","category":"è‹±æ–‡å¥³å£°","speed":1.0,"pause":0.2}
    ],
    "å¼ºåŒ–è®°å¿†æ¨¡å¼": [
        {"content":"è‹±è¯­","category":"è‹±æ–‡ç”·å£°","speed":0.95,"pause":0.5},
        {"content":"ä¸­æ–‡","category":"ä¸­æ–‡éŸ³è‰²","speed":1.0,"pause":0.8},
        {"content":"è‹±è¯­","category":"è‹±æ–‡å¥³å£°","speed":1.05,"pause":0.3}
    ],
    "ç†è§£ä¼˜å…ˆæ¨¡å¼": [
        {"content":"ä¸­æ–‡","category":"ä¸­æ–‡éŸ³è‰²","speed":1.0,"pause":0.5},
        {"content":"è‹±è¯­","category":"è‹±æ–‡å¥³å£°","speed":0.95,"pause":0.2}
    ]
}

def recommend_preset(goal: str) -> str:
    if not goal:
        return "åŸºç¡€å­¦ä¹ æ¨¡å¼"
    g = goal.lower()
    if "è®°å¿†" in g or "èƒŒè¯µ" in g:
        return "å¼ºåŒ–è®°å¿†æ¨¡å¼"
    if "ç†è§£" in g or "ç¿»è¯‘" in g:
        return "ç†è§£ä¼˜å…ˆæ¨¡å¼"
    return "åŸºç¡€å­¦ä¹ æ¨¡å¼"

def get_voice_display_name(voice_name: str) -> str:
    """è·å–éŸ³è‰²çš„æ˜¾ç¤ºåç§°"""
    parts = voice_name.split("-")
    if len(parts) >= 3:
        return f"{parts[2]} ({parts[1]})"
    return voice_name

def get_voice_style(voice_name: str) -> str:
    """è·å–éŸ³è‰²é£æ ¼æè¿°"""
    return VOICE_STYLES.get(voice_name, "ä¸“ä¸šè¯­éŸ³åˆæˆ")

# ---------- TTS è¾…åŠ©å‡½æ•° ----------
def generate_edge_mp3(text: str, voice: str, speed: float, out_mp3: str) -> bool:
    """åŒæ­¥å°è£… edge-tts"""
    if not EDGE_TTS_AVAILABLE:
        return False
    
    pct = int((speed - 1.0) * 100)
    rate_str = f"{pct:+d}%"
    
    try:
        return asyncio.run(_edge_save_async(text, voice, out_mp3, rate_str))
    except Exception as e:
        return False

async def _edge_save_async(text: str, voice: str, out_path: str, rate_str: str = "+0%") -> bool:
    """å¼‚æ­¥è°ƒç”¨ edge-tts ä¿å­˜"""
    if not EDGE_TTS_AVAILABLE:
        return False
    try:
        comm = edge_tts.Communicate(text=text, voice=voice, rate=rate_str)
        await comm.save(out_path)
        return True
    except Exception as e:
        return False

def generate_tts_cached(text: str, voice_category: Optional[str], voice_choice: Optional[str], speed: float, engine_pref: str, out_mp3: str) -> bool:
    """ç¼“å­˜å±‚ï¼šä¼˜å…ˆä½¿ç”¨ç¼“å­˜"""
    if not text or text.strip() == "":
        return False
        
    voice_name = voice_choice or (VOICE_LIBRARY.get(voice_category, [None])[0] if voice_category else None)
    if not voice_name:
        return False
        
    key = hash_text_meta(text, voice_name or "default", speed)
    
    if cache_exists(key):
        try:
            shutil.copy(cache_get(key), out_mp3)
            return True
        except Exception:
            pass
    
    # ä¸´æ—¶è¾“å‡º
    fd, tmpmp3 = tempfile.mkstemp(suffix=".mp3")
    os.close(fd)
    ok = False
    
    # ä¼˜å…ˆä½¿ç”¨åœ¨çº¿å¼•æ“
    if EDGE_TTS_AVAILABLE:
        ok = generate_edge_mp3(text, voice_name, speed, tmpmp3)
    
    if ok and os.path.exists(tmpmp3) and os.path.getsize(tmpmp3) > 0:
        try:
            cache_store(tmpmp3, key)
            shutil.copy(cache_get(key), out_mp3)
            safe_remove(tmpmp3)
            return True
        except Exception:
            try:
                shutil.copy(tmpmp3, out_mp3)
                safe_remove(tmpmp3)
                return True
            except:
                safe_remove(tmpmp3)
                return False
    safe_remove(tmpmp3)
    return False

# ---------- ç®€åŒ–ç‰ˆéŸ³é¢‘å¤„ç† ----------
def create_silent_audio(duration_s: float) -> bytes:
    """åˆ›å»ºé™éŸ³éŸ³é¢‘æ•°æ®"""
    # è¿”å›ç©ºçš„éŸ³é¢‘æ•°æ®
    return b""

def concat_audios_simple(audio_paths: List[str]) -> bytes:
    """ç®€åŒ–ç‰ˆéŸ³é¢‘åˆå¹¶"""
    # è¿”å›ç¬¬ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶çš„å†…å®¹
    if audio_paths and os.path.exists(audio_paths[0]):
        with open(audio_paths[0], 'rb') as f:
            return f.read()
    return b""

# ---------- é¢„è§ˆéŸ³é¢‘ç”Ÿæˆå‡½æ•° ----------
def generate_preview_audio(df, row_index, audio_segments):
    """ç”Ÿæˆé¢„è§ˆéŸ³é¢‘"""
    if df is None or row_index >= len(df):
        return None
    
    tmpdir = tempfile.mkdtemp(prefix="preview_")
    try:
        row = df.iloc[row_index]
        en = str(row.get("è‹±è¯­",""))
        ph = str(row.get("éŸ³æ ‡",""))
        cn = str(row.get("ä¸­æ–‡",""))
        
        seg_paths = []
        
        for seg_idx, seg in enumerate(audio_segments):
            text = en if seg["content"]=="è‹±è¯­" else (ph if seg["content"]=="éŸ³æ ‡" else cn)
            out_mp3 = os.path.join(tmpdir, f"preview_{seg_idx}_{seg['content']}.mp3")
            
            ok = generate_tts_cached(text, seg["voice_category"], seg["voice_choice"], seg["speed"], "åœ¨çº¿ä¼˜å…ˆ", out_mp3)
            if ok and os.path.exists(out_mp3):
                seg_paths.append(out_mp3)
        
        # è¿”å›ç¬¬ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ä½œä¸ºé¢„è§ˆ
        if seg_paths:
            return seg_paths[0]
        
        return None
    except Exception as e:
        st.error(f"é¢„è§ˆéŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
        return None

# ---------- éŸ³æ ‡å­—ç¬¦æ˜ å°„è¡¨ ----------
PHONETIC_CHAR_MAP = {
    'É¡': 'g',
    'Ëˆ': "'",
    'ËŒ': ",",
    'Ë': ':',
}

def convert_phonetic_text(text):
    """è½¬æ¢éŸ³æ ‡æ–‡æœ¬"""
    if not text:
        return ""
    
    converted = ''.join(PHONETIC_CHAR_MAP.get(char, char) for char in text)
    return converted

# ---------- é¡µé¢é¡¶éƒ¨ / å¯¼èˆª ----------
st.markdown(f'<div class="main-title">ğŸ¬ è‹±è¯­å­¦ä¹ è§†é¢‘ç”Ÿæˆå™¨</div>', unsafe_allow_html=True)

# ---------- æ•°æ®ç®¡ç†éƒ¨åˆ† ----------
st.markdown('<div class="card-header">ğŸ“ æ•°æ®ç®¡ç†</div>', unsafe_allow_html=True)
uploaded = st.file_uploader("ä¸Šä¼ Excel/CSVæ–‡ä»¶ï¼ˆéœ€è¦åŒ…å«è‹±è¯­ã€ä¸­æ–‡åˆ—ï¼‰", type=["xlsx","xls","csv"])
df = None
if uploaded:
    try:
        if uploaded.name.lower().endswith((".csv")):
            df = pd.read_csv(uploaded)
        else:
            df = pd.read_excel(uploaded)
        
        if "è‹±è¯­" not in df.columns or "ä¸­æ–‡" not in df.columns:
            st.error("æ–‡ä»¶å¿…é¡»åŒ…å«'è‹±è¯­'å’Œ'ä¸­æ–‡'åˆ—")
            df = None
        else:
            if "éŸ³æ ‡" not in df.columns:
                df["éŸ³æ ‡"] = ""
            st.success(f"æˆåŠŸåŠ è½½ {len(df)} æ¡æ•°æ®")
            st.dataframe(df.head(5), use_container_width=True)
    except Exception as e:
        st.error(f"æ–‡ä»¶è§£æå¤±è´¥ï¼š{e}")
else:
    st.info("è¯·ä¸Šä¼ åŒ…å«è‹±è¯­å’Œä¸­æ–‡åˆ—çš„æ•°æ®æ–‡ä»¶")

# ---------- éŸ³é¢‘è®¾ç½®éƒ¨åˆ† ----------
st.markdown('<div class="card-header">ğŸ”Š éŸ³é¢‘è®¾ç½®</div>', unsafe_allow_html=True)

# ä½¿ç”¨é€‰é¡¹å¡ç»„ç»‡éŸ³é¢‘è®¾ç½®
tab_audio_config, tab_voice_library = st.tabs(["ğŸµ éŸ³é¢‘ç¼–æ’", "ğŸ™ï¸ éŸ³è‰²åº“"])

with tab_audio_config:
    st.markdown('<div class="scrollable-content">', unsafe_allow_html=True)
    
    # éŸ³é¢‘æ®µæ•°
    n_segments = st.number_input("éŸ³é¢‘æ®µè½æ•°é‡", min_value=1, max_value=6, value=4, step=1, key="ui_n_segments")

    # æ„å»ºæ®µé…ç½®è¡¨
    audio_segments = []
    
    # é»˜è®¤éŸ³é¢‘ç¼–æ’è®¾ç½®
    default_segments = [
        {"content": "è‹±è¯­", "category": "è‹±æ–‡å¥³å£°", "voice_choice": None, "speed": 1.0, "pause": 0.3},
        {"content": "è‹±è¯­", "category": "è‹±æ–‡ç”·å£°", "voice_choice": None, "speed": 1.0, "pause": 0.3},
        {"content": "ä¸­æ–‡", "category": "ä¸­æ–‡éŸ³è‰²", "voice_choice": None, "speed": 1.0, "pause": 0.5},
        {"content": "è‹±è¯­", "category": "è‹±æ–‡å¥³å£°", "voice_choice": None, "speed": 1.0, "pause": 0.3}
    ]
    
    for si in range(int(n_segments)):
        st.markdown(f"**æ®µè½ {si+1}**", unsafe_allow_html=True)
        c1, c2, c3, c4 = st.columns([1.5, 1.2, 1, 1])
        
        # è·å–é»˜è®¤å€¼
        default_seg = default_segments[si] if si < len(default_segments) else default_segments[0]
        
        with c1:
            content = st.selectbox(f"å†…å®¹", ["è‹±è¯­", "éŸ³æ ‡", "ä¸­æ–‡"], 
                                 index=["è‹±è¯­", "éŸ³æ ‡", "ä¸­æ–‡"].index(default_seg["content"]), 
                                 key=f"ui_seg_content_{si}")
        with c2:
            category = st.selectbox(f"éŸ³è‰²ç±»å‹", ["è‹±æ–‡å¥³å£°", "è‹±æ–‡ç”·å£°", "ä¸­æ–‡éŸ³è‰²"], 
                                  index=["è‹±æ–‡å¥³å£°", "è‹±æ–‡ç”·å£°", "ä¸­æ–‡éŸ³è‰²"].index(default_seg["category"]), 
                                  key=f"ui_seg_cat_{si}")
        with c3:
            presets = VOICE_LIBRARY.get(category, [])
            voice_choice = st.selectbox(f"å…·ä½“éŸ³è‰²", ["è‡ªåŠ¨é€‰æ‹©"] + presets, 
                                      key=f"ui_seg_preset_{si}")
        with c4:
            speed = st.slider(f"è¯­é€Ÿ", 0.5, 2.0, default_seg["speed"], 0.1, key=f"ui_seg_speed_{si}")
        
        # å°†é…ç½®æ·»åŠ åˆ° audio_segments åˆ—è¡¨
        audio_segments.append({
            "content": content,
            "voice_category": category,
            "voice_choice": voice_choice if voice_choice != "è‡ªåŠ¨é€‰æ‹©" else None,
            "speed": speed,
            "pause": default_seg["pause"],
            "engine_pref": "åœ¨çº¿ä¼˜å…ˆ"
        })

with tab_voice_library:
    st.markdown('<div class="scrollable-content">', unsafe_allow_html=True)
    
    # ä½¿ç”¨é€‰é¡¹å¡ç»„ç»‡ä¸åŒéŸ³è‰²åˆ†ç±»
    tab1, tab2, tab3 = st.tabs(["ğŸ™ï¸ è‹±æ–‡å¥³å£°", "ğŸ™ï¸ è‹±æ–‡ç”·å£°", "ğŸ™ï¸ ä¸­æ–‡éŸ³è‰²"])
    
    with tab1:
        for voice in EN_FEMALE:
            with st.container():
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.write(f"**{get_voice_display_name(voice)}**")
                    st.caption(get_voice_style(voice))
                with col2:
                    if st.button("è¯•å¬", key=f"sample_{voice}"):
                        st.info("è¯•å¬åŠŸèƒ½éœ€è¦ç½‘ç»œè¿æ¥")
    
    with tab2:
        for voice in EN_MALE:
            with st.container():
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.write(f"**{get_voice_display_name(voice)}**")
                    st.caption(get_voice_style(voice))
                with col2:
                    if st.button("è¯•å¬", key=f"sample_{voice}"):
                        st.info("è¯•å¬åŠŸèƒ½éœ€è¦ç½‘ç»œè¿æ¥")
    
    with tab3:
        for voice in ZH_VOICES:
            with st.container():
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.write(f"**{get_voice_display_name(voice)}**")
                    st.caption(get_voice_style(voice))
                with col2:
                    if st.button("è¯•å¬", key=f"sample_{voice}"):
                        st.info("è¯•å¬åŠŸèƒ½éœ€è¦ç½‘ç»œè¿æ¥")

# ---------- Frame rendering ----------
def render_frame(en, ph, cn, conf, size=(640, 360)):
    """æ¸²æŸ“å•å¸§å›¾åƒ - ä¼˜åŒ–ä¸­æ–‡æ˜¾ç¤º"""
    W,H = size
    
    try:
        # åˆ›å»ºèƒŒæ™¯
        bg_color = conf.get("bg_color", "#F0F8FF")
        base = Image.new("RGB", (W,H), bg_color)
        draw = ImageDraw.Draw(base)

        # åŠ è½½å­—ä½“
        font_en = load_font(conf.get("english_size", 36))
        font_cn = load_font(conf.get("chinese_size", 32))
        phonetic_font = load_phonetic_font(conf.get("phonetic_size", 24))

        # é¢œè‰²è®¾ç½®
        english_color = conf.get("english_color", "#000000")
        phonetic_color = conf.get("phonetic_color", "#E67E22")
        chinese_color = conf.get("chinese_color", "#000000")
        
        # è®¡ç®—ä½ç½®
        text_area_width = int(W * 0.9)
        text_start_x = (W - text_area_width) // 2
        
        # è®¡ç®—æ€»é«˜åº¦
        total_height = (
            conf.get("english_size", 36) + 
            conf.get("phonetic_size", 24) + 
            conf.get("chinese_size", 32) + 40
        )
        
        start_y = (H - total_height) // 2
        
        # ç»˜åˆ¶æ–‡å­—èƒŒæ™¯æ¿
        padding = 20
        bg_rect = Image.new('RGBA', (text_area_width, total_height + padding), (255, 255, 255, 200))
        base.paste(bg_rect, (text_start_x, start_y - padding//2), bg_rect)
        
        # è‹±è¯­æ–‡æœ¬
        y = start_y
        bbox = draw.textbbox((0, 0), en, font=font_en)
        text_width = bbox[2] - bbox[0]
        x = text_start_x + (text_area_width - text_width) // 2
        draw.text((x, y), en, font=font_en, fill=english_color)
        
        # éŸ³æ ‡æ–‡æœ¬
        y += conf.get("english_size", 36) + 10
        converted_ph = convert_phonetic_text(ph)
        bbox = draw.textbbox((0, 0), f"/{converted_ph}/", font=phonetic_font)
        text_width = bbox[2] - bbox[0]
        x = text_start_x + (text_area_width - text_width) // 2
        draw.text((x, y), f"/{converted_ph}/", font=phonetic_font, fill=phonetic_color)
        
        # ä¸­æ–‡æ–‡æœ¬
        y += conf.get("phonetic_size", 24) + 10
        bbox = draw.textbbox((0, 0), cn, font=font_cn)
        text_width = bbox[2] - bbox[0]
        x = text_start_x + (text_area_width - text_width) // 2
        draw.text((x, y), cn, font=font_cn, fill=chinese_color)

        return base
    except Exception as e:
        # ç®€åŒ–é”™è¯¯å¤„ç†
        error_img = Image.new("RGB", (W, H), bg_color)
        draw = ImageDraw.Draw(error_img)
        draw.text((50, H//2), "æ¸²æŸ“é”™è¯¯", fill="red")
        return error_img

# ---------- æ•ˆæœé¢„è§ˆéƒ¨åˆ† ----------
st.markdown('<div class="card-header">ğŸ‘€ æ•ˆæœé¢„è§ˆ</div>', unsafe_allow_html=True)

if uploaded is not None and df is not None:
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    preview_col1, preview_col2 = st.columns([1, 1])
    
    with preview_col1:
        st.markdown("### ğŸ¨ æ˜¾ç¤ºè®¾ç½®")
        
        # èƒŒæ™¯è®¾ç½®
        bg_color = st.color_picker("èƒŒæ™¯é¢œè‰²", "#F0F8FF")
        
        # æ–‡å­—æ ·å¼
        col1, col2, col3 = st.columns(3)
        with col1:
            en_size = st.slider("è‹±è¯­å­—å·", 20, 60, 36)
            en_color = st.color_picker("è‹±è¯­é¢œè‰²", "#000000")
        with col2:
            ph_size = st.slider("éŸ³æ ‡å­—å·", 16, 40, 24)
            ph_color = st.color_picker("éŸ³æ ‡é¢œè‰²", "#E67E22")
        with col3:
            cn_size = st.slider("ä¸­æ–‡å­—å·", 20, 50, 32)
            cn_color = st.color_picker("ä¸­æ–‡é¢œè‰²", "#000000")
        
        st.info("ğŸ’¡ ä½¿ç”¨Google Fontsç¡®ä¿ä¸­è‹±æ–‡æ­£å¸¸æ˜¾ç¤º")
    
    with preview_col2:
        st.markdown("### ğŸ‘ï¸ å®æ—¶é¢„è§ˆ")
        
        # é€‰æ‹©é¢„è§ˆçš„è¡Œ
        preview_row = st.selectbox(
            "é€‰æ‹©é¢„è§ˆçš„å¥å­",
            options=list(range(len(df))),
            format_func=lambda i: f"{i+1}. {df.iloc[i]['è‹±è¯­'][:20]}...",
            key="preview_row"
        )
        
        # æ±‡æ€»æ ·å¼é…ç½®
        style_conf = {
            "bg_color": bg_color,
            "english_size": en_size,
            "english_color": en_color,
            "phonetic_size": ph_size,
            "phonetic_color": ph_color,
            "chinese_size": cn_size,
            "chinese_color": cn_color,
        }
        
        # å®æ—¶æ¸²æŸ“é¢„è§ˆ
        row = df.iloc[preview_row]
        en = str(row.get("è‹±è¯­",""))
        ph = str(row.get("éŸ³æ ‡",""))
        cn = str(row.get("ä¸­æ–‡",""))
        
        # ç”Ÿæˆé¢„è§ˆå›¾åƒ
        preview_image = render_frame(en, ph, cn, style_conf)
        
        # æ˜¾ç¤ºå®æ—¶é¢„è§ˆ
        st.markdown('<div class="live-preview-container">', unsafe_allow_html=True)
        st.image(preview_image, use_container_width=True)
        
        # æ˜¾ç¤ºé¢„è§ˆæ–‡æœ¬
        st.markdown(f'<div class="live-preview-text live-preview-english">{en}</div>', unsafe_allow_html=True)
        if ph and ph.strip():
            converted_ph_display = convert_phonetic_text(ph)
            st.markdown(f'<div class="live-preview-text live-preview-phonetic">/{converted_ph_display}/</div>', unsafe_allow_html=True)
        st.markdown(f'<div class="live-preview-text live-preview-chinese">{cn}</div>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)
        
        # éŸ³é¢‘é¢„è§ˆ
        st.markdown("### ğŸ”Š éŸ³é¢‘é¢„è§ˆ")
        if st.button("ç”ŸæˆéŸ³é¢‘é¢„è§ˆ", use_container_width=True):
            with st.spinner("ç”Ÿæˆä¸­..."):
                preview_audio = generate_preview_audio(df, preview_row, audio_segments)
                if preview_audio:
                    st.audio(preview_audio, format="audio/mp3")
                    st.success("éŸ³é¢‘é¢„è§ˆç”Ÿæˆå®Œæˆï¼")
                else:
                    st.error("éŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")

# ---------- ç”Ÿæˆä¸ä¸‹è½½éƒ¨åˆ† ----------
st.markdown('<div class="card-header">ğŸ“¤ ç”Ÿæˆå†…å®¹</div>', unsafe_allow_html=True)

if not ffmpeg_available():
    st.warning("""
    âš ï¸ **è§†é¢‘ç”ŸæˆåŠŸèƒ½å—é™**
    
    å½“å‰ç¯å¢ƒæœªæ£€æµ‹åˆ°FFmpegï¼Œè§†é¢‘ç”ŸæˆåŠŸèƒ½ä¸å¯ç”¨ã€‚
    ä½†æ‚¨ä»ç„¶å¯ä»¥ï¼š
    - âœ… ç”Ÿæˆå•å¼ å­¦ä¹ å¡ç‰‡å›¾ç‰‡
    - âœ… ç”ŸæˆéŸ³é¢‘å†…å®¹
    - âœ… é¢„è§ˆå­¦ä¹ æ•ˆæœ
    """)

if uploaded is not None and df is not None:
    # ç”Ÿæˆå­¦ä¹ å¡ç‰‡
    st.markdown("### ğŸ–¼ï¸ ç”Ÿæˆå­¦ä¹ å¡ç‰‡")
    
    selected_rows = st.multiselect(
        "é€‰æ‹©è¦ç”Ÿæˆå¡ç‰‡çš„å¥å­", 
        options=list(range(len(df))),
        format_func=lambda i: f"{i+1}. {df.iloc[i]['è‹±è¯­'][:20]}...",
        default=[0] if len(df) > 0 else []
    )
    
    if st.button("ğŸ–¨ï¸ ç”Ÿæˆå­¦ä¹ å¡ç‰‡", use_container_width=True):
        if selected_rows:
            with st.spinner("ç”Ÿæˆå­¦ä¹ å¡ç‰‡ä¸­..."):
                # ç”Ÿæˆæ ·å¼é…ç½®
                style_conf = {
                    "bg_color": bg_color,
                    "english_size": en_size,
                    "english_color": en_color,
                    "phonetic_size": ph_size,
                    "phonetic_color": ph_color,
                    "chinese_size": cn_size,
                    "chinese_color": cn_color,
                }
                
                # åˆ›å»ºZIPæ–‡ä»¶åŒ…å«æ‰€æœ‰å›¾ç‰‡
                import zipfile
                zip_buffer = io.BytesIO()
                
                with zipfile.ZipFile(zip_buffer, 'w') as zip_file:
                    for idx in selected_rows:
                        row = df.iloc[idx]
                        en = str(row.get("è‹±è¯­",""))
                        ph = str(row.get("éŸ³æ ‡",""))
                        cn = str(row.get("ä¸­æ–‡",""))
                        
                        # ç”Ÿæˆå›¾ç‰‡
                        img = render_frame(en, ph, cn, style_conf, (800, 450))
                        
                        # ä¿å­˜åˆ°å†…å­˜
                        img_buffer = io.BytesIO()
                        img.save(img_buffer, format='PNG')
                        
                        # æ·»åŠ åˆ°ZIP
                        zip_file.writestr(f"card_{idx+1}_{en[:10]}.png", img_buffer.getvalue())
                
                # æä¾›ä¸‹è½½
                st.success(f"æˆåŠŸç”Ÿæˆ {len(selected_rows)} å¼ å­¦ä¹ å¡ç‰‡")
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½å­¦ä¹ å¡ç‰‡åŒ…",
                    data=zip_buffer.getvalue(),
                    file_name="english_learning_cards.zip",
                    mime="application/zip",
                    use_container_width=True
                )
        else:
            st.warning("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªå¥å­")
    
    # ç”ŸæˆéŸ³é¢‘åŒ…
    st.markdown("### ğŸ”Š ç”ŸæˆéŸ³é¢‘åŒ…")
    
    if st.button("ğŸµ ç”ŸæˆéŸ³é¢‘æ–‡ä»¶", use_container_width=True):
        if selected_rows:
            with st.spinner("ç”ŸæˆéŸ³é¢‘æ–‡ä»¶ä¸­..."):
                # åˆ›å»ºZIPæ–‡ä»¶åŒ…å«æ‰€æœ‰éŸ³é¢‘
                zip_buffer = io.BytesIO()
                
                with zipfile.ZipFile(zip_buffer, 'w') as zip_file:
                    for idx in selected_rows:
                        row = df.iloc[idx]
                        en = str(row.get("è‹±è¯­",""))
                        
                        # ç”Ÿæˆç¬¬ä¸€ä¸ªéŸ³é¢‘æ®µ
                        if audio_segments:
                            seg = audio_segments[0]
                            text = en if seg["content"]=="è‹±è¯­" else ""
                            
                            # ä¸´æ—¶æ–‡ä»¶
                            fd, tmp_mp3 = tempfile.mkstemp(suffix=".mp3")
                            os.close(fd)
                            
                            if generate_tts_cached(text, seg["voice_category"], seg["voice_choice"], seg["speed"], "åœ¨çº¿ä¼˜å…ˆ", tmp_mp3):
                                with open(tmp_mp3, 'rb') as f:
                                    zip_file.writestr(f"audio_{idx+1}_{en[:10]}.mp3", f.read())
                            
                            safe_remove(tmp_mp3)
                
                st.success(f"æˆåŠŸç”Ÿæˆ {len(selected_rows)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½éŸ³é¢‘åŒ…",
                    data=zip_buffer.getvalue(),
                    file_name="english_audio_files.zip",
                    mime="application/zip",
                    use_container_width=True
                )
        else:
            st.warning("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªå¥å­")

# ---------- ä¾§è¾¹æ  ----------
st.sidebar.header("ğŸ“¦ åŠŸèƒ½")
st.sidebar.info("""
**ä¸»è¦åŠŸèƒ½ï¼š**
- ğŸ“ æ•°æ®ç®¡ç†
- ğŸ”Š å¤šéŸ³è‰²éŸ³é¢‘
- ğŸ¨ å­¦ä¹ å¡ç‰‡
- ğŸ‘€ å®æ—¶é¢„è§ˆ
""")

st.sidebar.header("ğŸ”§ ç³»ç»ŸçŠ¶æ€")
st.sidebar.write(f"âœ… è¯­éŸ³åˆæˆ: {'å¯ç”¨' if EDGE_TTS_AVAILABLE else 'éœ€å®‰è£…'}")
st.sidebar.write(f"âœ… å›¾ç‰‡ç”Ÿæˆ: å¯ç”¨")
st.sidebar.write(f"ğŸ”¶ è§†é¢‘åˆæˆ: {'å¯ç”¨' if ffmpeg_available() else 'éœ€FFmpeg'}")

if not EDGE_TTS_AVAILABLE:
    st.sidebar.warning("å®‰è£…è¯­éŸ³åˆæˆ: `pip install edge-tts`")

if not ffmpeg_available():
    st.sidebar.warning("è§†é¢‘åŠŸèƒ½éœ€è¦å®‰è£…FFmpeg")

st.sidebar.header("ğŸ’¡ ä½¿ç”¨æç¤º")
st.sidebar.info("""
1. ä¸Šä¼ åŒ…å«è‹±è¯­å’Œä¸­æ–‡çš„CSV/Excelæ–‡ä»¶
2. é…ç½®éŸ³é¢‘æ®µè½å’ŒéŸ³è‰²
3. è°ƒæ•´æ˜¾ç¤ºæ ·å¼
4. ç”Ÿæˆå­¦ä¹ å¡ç‰‡å’ŒéŸ³é¢‘
""")

# ---------- é¡µè„š ----------
st.markdown(
    """
    <div style='text-align: center; padding: 20px; color: #64748b; margin-top: 40px;'>
    Â© 2024 è‹±è¯­å­¦ä¹ è§†é¢‘ç”Ÿæˆå™¨ â€¢ ä¸“æ³¨äºè‹±è¯­å­¦ä¹ å†…å®¹åˆ¶ä½œ
    </div>
    """,
    unsafe_allow_html=True)
