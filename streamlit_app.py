import os
import shutil
import streamlit as st
import pandas as pd
import numpy as np
from PIL import Image, ImageDraw, ImageFont, ImageOps
import imageio.v2 as imageio
import tempfile
import subprocess
import traceback
import asyncio
import socket
import time

# -----------------------
# å·¥å…·å‡½æ•°
# -----------------------
def check_ffmpeg():
    ffmpeg_path = shutil.which("ffmpeg")
    return ffmpeg_path is not None

def is_internet_available(host="speech.platform.bing.com", port=443, timeout=3):
    """æ£€æŸ¥å¾®è½¯è¯­éŸ³æœåŠ¡æ˜¯å¦å¯è®¿é—®"""
    try:
        socket.create_connection((host, port), timeout=timeout)
        return True
    except OSError:
        return False

# -----------------------
# Edge-TTS åˆå§‹åŒ–
# -----------------------
try:
    import edge_tts
    EDGE_TTS_AVAILABLE = True
except Exception:
    EDGE_TTS_AVAILABLE = False

# -----------------------
# Streamlit é¡µé¢é…ç½®
# -----------------------
st.set_page_config(page_title="æ—…è¡Œè‹±è¯­è§†é¢‘ç”Ÿæˆå™¨", page_icon="ğŸ¬", layout="wide")

# -----------------------
# å¼‚æ­¥ TTS ç”Ÿæˆï¼ˆå®‰å…¨å°è£…ï¼‰
# -----------------------
async def _edge_tts_save_async(text: str, voice_name: str, out_path: str, rate: str = "+0%"):
    try:
        communicate = edge_tts.Communicate(text, voice_name, rate=rate)
        await communicate.save(out_path)
        return True
    except Exception as e:
        st.warning(f"TTSç”Ÿæˆå¤±è´¥: {e}")
        return False

def generate_edge_audio(text, voice, speed=1.0, out_path=None, retry=2):
    """å®‰å…¨ TTS ç”Ÿæˆï¼Œæ”¯æŒé‡è¯•ä¸ç½‘ç»œæ£€æµ‹"""
    if not EDGE_TTS_AVAILABLE:
        st.warning("Edge TTS æ¨¡å—æœªå®‰è£…")
        return None

    if not is_internet_available():
        st.warning("æ— æ³•è¿æ¥å¾®è½¯è¯­éŸ³æœåŠ¡ï¼Œå°†ä½¿ç”¨é™éŸ³ä»£æ›¿ã€‚")
        return None

    pct = int((speed - 1.0) * 100)
    rate_str = f"{pct:+d}%"

    if out_path is None:
        fd, out_path = tempfile.mkstemp(suffix=".mp3")
        os.close(fd)

    async def _safe_call():
        return await _edge_tts_save_async(text, voice, out_path, rate_str)

    for attempt in range(1, retry + 1):
        try:
            try:
                loop = asyncio.get_running_loop()
            except RuntimeError:
                loop = None

            if loop and loop.is_running():
                future = asyncio.ensure_future(_safe_call())
                asyncio.get_event_loop().run_until_complete(future)
                result = future.result()
            else:
                result = asyncio.run(_safe_call())

            if result and os.path.exists(out_path) and os.path.getsize(out_path) > 0:
                return out_path
            else:
                st.warning(f"TTS ç¬¬ {attempt} æ¬¡ç”Ÿæˆæ— éŸ³é¢‘æ•°æ®ï¼Œé‡è¯•ä¸­...")
                time.sleep(1)
        except Exception as e:
            st.warning(f"TTSç”Ÿæˆå¼‚å¸¸ï¼ˆç¬¬{attempt}æ¬¡ï¼‰: {e}")
            time.sleep(1)

    st.error("âŒ TTS å¤šæ¬¡ç”Ÿæˆå¤±è´¥ï¼Œå°†ä½¿ç”¨é™éŸ³ã€‚")
    if os.path.exists(out_path):
        os.unlink(out_path)
    return None

def preview_voice(voice_name, text, speed=1.0):
    """ç”Ÿæˆè¯•å¬éŸ³é¢‘"""
    if not EDGE_TTS_AVAILABLE:
        st.warning("Edge TTS æ¨¡å—ä¸å¯ç”¨")
        return None

    if not is_internet_available():
        st.warning("æ— æ³•è¿æ¥å¾®è½¯è¯­éŸ³æœåŠ¡ï¼Œè¯•å¬å°†ä½¿ç”¨é™éŸ³ã€‚")
        return None

    pct = int((speed - 1.0) * 100)
    rate_str = f"{pct:+d}%"

    async def _preview():
        temp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        temp.close()
        communicate = edge_tts.Communicate(text, voice_name, rate=rate_str)
        await communicate.save(temp.name)
        if os.path.exists(temp.name) and os.path.getsize(temp.name) > 0:
            with open(temp.name, "rb") as f:
                data = f.read()
            os.unlink(temp.name)
            return data
        return None

    try:
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = None

        if loop and loop.is_running():
            future = asyncio.ensure_future(_preview())
            asyncio.get_event_loop().run_until_complete(future)
            audio_bytes = future.result()
        else:
            audio_bytes = asyncio.run(_preview())
        return audio_bytes
    except Exception as e:
        st.warning(f"è¯•å¬å¤±è´¥: {e}")
        return None

# -----------------------
# å…¶ä»–è§†é¢‘ç”Ÿæˆã€ç»˜åˆ¶é€»è¾‘
# -----------------------

def wrap_text(text, max_chars):
    if not text or str(text).strip().lower() == "nan":
        return [""]
    text = str(text).strip()
    if any("\u4e00" <= c <= "\u9fff" for c in text):
        max_chars = min(max_chars, 15)
    words = text.split()
    lines, current = [], []
    for word in words:
        test_line = " ".join(current + [word])
        if len(test_line) <= max_chars:
            current.append(word)
        else:
            if current:
                lines.append(" ".join(current))
            if len(word) > max_chars:
                for i in range(0, len(word), max_chars):
                    lines.append(word[i:i + max_chars])
                current = []
            else:
                current = [word]
    if current:
        lines.append(" ".join(current))
    return lines

def get_font(size, bold=False):
    try:
        if bold:
            candidates = ["arialbd.ttf", "simhei.ttf", "msyhbd.ttc"]
        else:
            candidates = ["arial.ttf", "msyh.ttc", "simsun.ttc"]
        for c in candidates:
            try:
                return ImageFont.truetype(c, size)
            except:
                continue
        return ImageFont.load_default()
    except:
        return ImageFont.load_default()

def create_frame(english, chinese, phonetic, width=1280, height=720,
                 bg_color=(0,0,0), eng_color=(255,255,255),
                 chn_color=(173,216,230), pho_color=(255,255,0)):
    """ç”Ÿæˆå•å¸§å›¾ç‰‡"""
    img = Image.new("RGB", (width, height), bg_color)
    draw = ImageDraw.Draw(img)
    eng_font = get_font(80, True)
    pho_font = get_font(50)
    chn_font = get_font(60)
    y = height // 2 - 100
    for line in wrap_text(english, 40):
        w, h = draw.textsize(line, font=eng_font)
        draw.text(((width - w)//2, y), line, fill=eng_color, font=eng_font)
        y += h + 10
    for line in wrap_text(phonetic, 45):
        w, h = draw.textsize(line, font=pho_font)
        draw.text(((width - w)//2, y), line, fill=pho_color, font=pho_font)
        y += h + 10
    for line in wrap_text(chinese, 20):
        w, h = draw.textsize(line, font=chn_font)
        draw.text(((width - w)//2, y), line, fill=chn_color, font=chn_font)
        y += h + 10
    return img

def create_silent_audio(duration, output_path):
    """ç”Ÿæˆé™éŸ³éŸ³é¢‘"""
    cmd = ["ffmpeg", "-y", "-f", "lavfi", "-i", "anullsrc=r=44100:cl=stereo", "-t", str(duration), output_path]
    subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    return os.path.exists(output_path)

def merge_video_audio(video_path, audio_path, output_path):
    """åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘"""
    cmd = [
        "ffmpeg", "-y",
        "-i", video_path, "-i", audio_path,
        "-c:v", "copy", "-c:a", "aac", "-shortest", output_path
    ]
    subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    return os.path.exists(output_path)

def generate_video(df, settings, progress_bar):
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            video_path = os.path.join(tmpdir, "video.mp4")
            writer = imageio.get_writer(video_path, fps=settings["fps"], codec="libx264")
            audio_files = []
            for idx, row in df.iterrows():
                eng, chn = str(row["è‹±è¯­"]), str(row["ä¸­æ–‡"])
                pho = str(row["éŸ³æ ‡"]) if pd.notna(row["éŸ³æ ‡"]) else ""
                frame = np.array(create_frame(eng, chn, pho, width=settings["width"], height=settings["height"]))
                for _ in range(settings["fps"] * settings["duration"]):
                    writer.append_data(frame)
                progress_bar.progress((idx + 1) / len(df) * 0.7)
                audio_file = generate_edge_audio(eng, settings["voice"], speed=settings["speed"])
                if not audio_file:
                    audio_file = os.path.join(tmpdir, f"silent_{idx}.mp3")
                    create_silent_audio(settings["duration"], audio_file)
                audio_files.append(audio_file)
            writer.close()

            # åˆå¹¶éŸ³é¢‘
            combined_audio = os.path.join(tmpdir, "combined.mp3")
            list_file = os.path.join(tmpdir, "list.txt")
            with open(list_file, "w") as f:
                for a in audio_files:
                    f.write(f"file '{a}'\n")
            subprocess.run(["ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", list_file, "-c", "copy", combined_audio])
            progress_bar.progress(0.9)

            final_path = os.path.join(tmpdir, "final.mp4")
            merge_video_audio(video_path, combined_audio, final_path)
            progress_bar.progress(1.0)
            with open(final_path, "rb") as f:
                return f.read()
    except Exception as e:
        st.error(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
        return None

# -----------------------
# Streamlit UI
# -----------------------
st.title("ğŸ¬ æ—…è¡Œè‹±è¯­è§†é¢‘ç”Ÿæˆå™¨")

uploaded = st.file_uploader("ä¸Šä¼ Excelæ–‡ä»¶ï¼ˆéœ€å«è‹±è¯­ã€ä¸­æ–‡ã€éŸ³æ ‡åˆ—ï¼‰", type=["xlsx"])
if uploaded:
    df = pd.read_excel(uploaded)
    if not {"è‹±è¯­", "ä¸­æ–‡", "éŸ³æ ‡"}.issubset(df.columns):
        st.error("ç¼ºå°‘å¿…è¦åˆ—ï¼šè‹±è¯­ã€ä¸­æ–‡ã€éŸ³æ ‡")
        st.stop()
    st.dataframe(df.head())
    st.success(f"å…± {len(df)} è¡Œæ•°æ®")

    st.markdown("### å‚æ•°è®¾ç½®")
    width = st.selectbox("è§†é¢‘å®½åº¦", [640, 960, 1280, 1920], index=2)
    height = int(width * 9 / 16)
    fps = st.slider("å¸§ç‡", 8, 30, 20)
    duration = st.slider("æ¯æ¡æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰", 2, 8, 4)
    speed = st.slider("TTSè¯­é€Ÿ", 0.5, 2.0, 1.0)
    voices = {
        "Aria (å¥³å£°)": "en-US-AriaNeural",
        "Guy (ç”·å£°)": "en-US-GuyNeural",
        "Xiaoxiao (ä¸­æ–‡å¥³å£°)": "zh-CN-XiaoxiaoNeural",
    }
    voice_label = st.selectbox("é€‰æ‹©éŸ³è‰²", list(voices.keys()))
    voice = voices[voice_label]

    if st.button("ğŸ¥ ç”Ÿæˆè§†é¢‘"):
        progress = st.progress(0)
        settings = {
            "width": width,
            "height": height,
            "fps": fps,
            "duration": duration,
            "voice": voice,
            "speed": speed,
        }
        video_bytes = generate_video(df, settings, progress)
        if video_bytes:
            st.success("âœ… è§†é¢‘ç”Ÿæˆå®Œæˆï¼")
            st.video(video_bytes)
            st.download_button("ğŸ“¥ ä¸‹è½½è§†é¢‘", video_bytes, "output.mp4", "video/mp4")
