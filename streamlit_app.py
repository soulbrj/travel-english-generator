import os
import shutil
import streamlit as st
import pandas as pd
import numpy as np
from PIL import Image, ImageDraw, ImageFont, ImageOps
import imageio.v2 as imageio
import tempfile
import subprocess
import traceback
import asyncio
import base64

# æ£€æŸ¥ ffmpeg æ˜¯å¦å¯ç”¨ï¼ˆé™é»˜æ¨¡å¼ï¼‰
def check_ffmpeg():
    ffmpeg_path = shutil.which('ffmpeg')
    return ffmpeg_path

# edge-tts ç”¨äºå¤šéŸ³è‰² TTS
try:
    import edge_tts
    EDGE_TTS_AVAILABLE = True
except Exception:
    EDGE_TTS_AVAILABLE = False

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ—…è¡Œè‹±è¯­è§†é¢‘ç”Ÿæˆå™¨",
    page_icon="ğŸ¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼ - ç§»é™¤ä¸å¿…è¦çš„ç©ºç™½
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: 700;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 2rem;
    }
    .section-header {
        font-size: 1.5rem;
        font-weight: 600;
        color: #1f2937;
        margin: 1.5rem 0 1rem 0;
        padding-bottom: 0.5rem;
        border-bottom: 2px solid #e5e7eb;
    }
    .info-card {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin: 1rem 0;
    }
    .success-card {
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin: 1rem 0;
    }
    .warning-card {
        background: linear-gradient(135deg, #f6d365 0%, #fda085 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin: 1rem 0;
    }
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    }
    .stButton > button {
        width: 100%;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        padding: 0.75rem 1.5rem;
        border-radius: 8px;
        font-weight: 600;
        transition: all 0.3s ease;
    }
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
    }
    .upload-section {
        border: 2px dashed #667eea;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        background: rgba(102, 126, 234, 0.05);
        margin: 1rem 0;
    }
    .preview-section {
        background: #f8fafc;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
        border-left: 4px solid #667eea;
    }
    .setting-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
        border: 1px solid #e5e7eb;
        margin: 0.5rem 0;
    }
    .voice-preview-btn {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        color: white !important;
        border: none !important;
        border-radius: 6px !important;
        padding: 0.5rem 1rem !important;
        font-size: 0.9rem !important;
    }
    /* ç§»é™¤ä¸å¿…è¦çš„ç©ºç™½ */
    .stTabs [data-baseweb="tab-list"] {
        gap: 0px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        border-radius: 4px 4px 0px 0px;
        gap: 0px;
        padding-top: 10px;
        padding-bottom: 10px;
    }
</style>
""", unsafe_allow_html=True)

# ä¼šè¯çŠ¶æ€
if 'bg_image' not in st.session_state:
    st.session_state.bg_image = None
if 'audio_available' not in st.session_state:
    st.session_state.audio_available = EDGE_TTS_AVAILABLE
if 'generation_status' not in st.session_state:
    st.session_state.generation_status = None

# -----------------------
# å·¥å…·å‡½æ•°
# -----------------------
def wrap_text(text, max_chars):
    if not text or str(text).strip().lower() == 'nan':
        return [""]
    text = str(text).strip()
    if any('\u4e00' <= c <= '\u9fff' for c in text):
        max_chars = min(max_chars, 15)
    words = text.split()
    lines, current = [], []
    for word in words:
        test_line = ' '.join(current + [word])
        if len(test_line) <= max_chars:
            current.append(word)
        else:
            if current:
                lines.append(' '.join(current))
            if len(word) > max_chars:
                for i in range(0, len(word), max_chars):
                    lines.append(word[i:i+max_chars])
                current = []
            else:
                current = [word]
    if current:
        lines.append(' '.join(current))
    return lines

def get_phonetic_font(size, bold=False):
    """ä¸“é—¨ç”¨äºéŸ³æ ‡æ˜¾ç¤ºçš„å­—ä½“åŠ è½½å‡½æ•°"""
    try:
        # ä¼˜å…ˆå°è¯•ç›´æ¥åŠ è½½å·²çŸ¥çš„éŸ³æ ‡å­—ä½“æ–‡ä»¶
        font_files = [
            "DoulosSIL-R.ttf",
            "CharisSIL-R.ttf",
            "NotoSansIPA-Regular.ttf",
            "ArialUni.ttf",
            "l_10646.ttf",
            "DejaVuSans.ttf",
        ]
        
        # å°è¯•ä»ç³»ç»Ÿå­—ä½“ç›®å½•åŠ è½½
        system_font_paths = [
            "/usr/share/fonts/",
            "C:/Windows/Fonts/",
            "~/Library/Fonts/",
            "/Library/Fonts/",
        ]
        
        # å°è¯•åŠ è½½ç²—ä½“
        if bold:
            bold_fonts = [
                "DoulosSIL-B.ttf",
                "CharisSIL-B.ttf",
                "NotoSansIPA-Bold.ttf",
                "ArialUniBold.ttf",
                "DejaVuSans-Bold.ttf",
            ]
            for font in bold_fonts:
                try:
                    return ImageFont.truetype(font, size)
                except:
                    pass
                for path in system_font_paths:
                    font_path = os.path.join(path, font)
                    if os.path.exists(font_path):
                        try:
                            return ImageFont.truetype(font_path, size)
                        except:
                            continue
        
        # å°è¯•åŠ è½½å¸¸è§„å­—ä½“
        for font in font_files:
            try:
                return ImageFont.truetype(font, size)
            except:
                pass
            for path in system_font_paths:
                font_path = os.path.join(path, font)
                if os.path.exists(font_path):
                    try:
                        return ImageFont.truetype(font_path, size)
                    except:
                        continue
        
        # æœ€åä½¿ç”¨é»˜è®¤å­—ä½“
        return ImageFont.load_default()
    except Exception as e:
        return ImageFont.load_default()

def get_font(size, font_type="default", bold=False):
    """è·å–å­—ä½“ï¼Œæ”¯æŒéŸ³æ ‡ç¬¦å·å’Œä¸­æ–‡"""
    if font_type == "phonetic":
        return get_phonetic_font(size, bold)
    
    try:
        chinese_fonts = [
            "simhei.ttf",
            "msyh.ttc",
            "simsun.ttc",
            "STHeiti Light.ttc",
            "PingFang.ttc",
            "Arial Unicode MS",
            "SimHei", 
            "Microsoft YaHei",
            "WenQuanYi Micro Hei",
            "NotoSansCJK-Regular.ttc",
            "FZSTK.TTF",
            "SourceHanSansCN-Regular.otf",
        ]
        
        if bold:
            bold_fonts = [
                "simhei.ttf",
                "msyhbd.ttc",
                "STHeiti Medium.ttc",
                "PingFang SC Semibold.ttc",
                "Arial Unicode MS",
                "SimHei",
                "Arial Bold",
                "Arial-Bold",
                "arialbd.ttf"
            ]
            for f in chinese_fonts:
                try:
                    if f in bold_fonts or any(bold_font in f.lower() for bold_font in ['bold', 'bd', 'black', 'heavy']):
                        return ImageFont.truetype(f, size)
                except Exception:
                    continue
            for f in bold_fonts:
                try:
                    return ImageFont.truetype(f, size)
                except Exception:
                    continue
        
        for f in chinese_fonts:
            try:
                return ImageFont.truetype(f, size)
            except Exception:
                continue
        
        return ImageFont.load_default()
    except Exception as e:
        return ImageFont.load_default()

def create_frame(english, chinese, phonetic, width=1920, height=1080,
                 bg_color=(0,0,0), bg_image=None,
                 eng_color=(255,255,255), chn_color=(173,216,230), pho_color=(255,255,0),
                 eng_size=80, chn_size=60, pho_size=50,
                 text_bg_enabled=False, text_bg_color=(255,255,255,180), text_bg_padding=20,
                 text_bg_radius=30, text_bg_width=None, text_bg_height=None,
                 bold_text=True, eng_pho_spacing=30, pho_chn_spacing=30, line_spacing=15):
    """åˆ›å»ºä¸€å¸§å›¾ç‰‡"""
    if bg_image:
        try:
            img = ImageOps.fit(bg_image.convert('RGB'), (width, height), Image.Resampling.LANCZOS)
        except Exception:
            img = Image.new('RGB', (width, height), bg_color)
    else:
        img = Image.new('RGB', (width, height), bg_color)

    draw = ImageDraw.Draw(img)
    
    eng_font = get_font(eng_size, "phonetic", bold=bold_text)
    chn_font = get_font(chn_size, "chinese", bold=bold_text)
    pho_font = get_font(pho_size, "phonetic", bold=bold_text)

    eng_lines = wrap_text(english, 40)
    chn_lines = wrap_text(chinese, 20)
    pho_lines = wrap_text(phonetic, 45) if phonetic else []

    total_height = 0

    for line in eng_lines:
        bbox = draw.textbbox((0,0), line, font=eng_font)
        h = bbox[3] - bbox[1]
        total_height += h
    total_height += line_spacing * (len(eng_lines)-1)

    if pho_lines:
        total_height += eng_pho_spacing  # ä½¿ç”¨å¯è°ƒèŠ‚çš„è‹±è¯­-éŸ³æ ‡é—´è·
        for line in pho_lines:
            bbox = draw.textbbox((0,0), line, font=pho_font)
            h = bbox[3] - bbox[1]
            total_height += h
        total_height += line_spacing * (len(pho_lines)-1)

    if chn_lines:
        total_height += pho_chn_spacing  # ä½¿ç”¨å¯è°ƒèŠ‚çš„éŸ³æ ‡-ä¸­æ–‡é—´è·
        for line in chn_lines:
            bbox = draw.textbbox((0,0), line, font=chn_font)
            h = bbox[3] - bbox[1]
            total_height += h
        total_height += line_spacing * (len(chn_lines)-1)

    if text_bg_enabled:
        max_width = 0
        for line in eng_lines:
            bbox = draw.textbbox((0,0), line, font=eng_font)
            w = bbox[2] - bbox[0]
            max_width = max(max_width, w)
        for line in pho_lines:
            bbox = draw.textbbox((0,0), line, font=pho_font)
            w = bbox[2] - bbox[0]
            max_width = max(max_width, w)
        for line in chn_lines:
            bbox = draw.textbbox((0,0), line, font=chn_font)
            w = bbox[2] - bbox[0]
            max_width = max(max_width, w)
        
        if text_bg_width is None:
            bg_width = max_width + text_bg_padding * 2
        else:
            bg_width = text_bg_width
            
        if text_bg_height is None:
            bg_height = total_height + text_bg_padding * 2
        else:
            bg_height = text_bg_height
        
        bg_x = (width - bg_width) // 2
        bg_y = (height - bg_height) // 2
        
        bg_layer = Image.new('RGBA', (bg_width, bg_height), (0,0,0,0))
        bg_draw = ImageDraw.Draw(bg_layer)
        
        if text_bg_radius > 0:
            bg_draw.rounded_rectangle(
                [(0, 0), (bg_width, bg_height)],
                radius=text_bg_radius,
                fill=text_bg_color
            )
        else:
            bg_draw.rectangle(
                [(0, 0), (bg_width, bg_height)],
                fill=text_bg_color
            )
        
        img.paste(bg_layer, (bg_x, bg_y), bg_layer)

    y = (height - total_height)//2

    for line in eng_lines:
        bbox = draw.textbbox((0,0), line, font=eng_font)
        w = bbox[2] - bbox[0]
        h = bbox[3] - bbox[1]
        x = (width - w)//2
        shadow_offset = 3
        draw.text((x+shadow_offset, y+shadow_offset), line, font=eng_font, fill=(0,0,0,128))
        draw.text((x, y), line, font=eng_font, fill=eng_color)
        y += h + line_spacing

    if pho_lines:
        y += eng_pho_spacing  # ä½¿ç”¨å¯è°ƒèŠ‚çš„è‹±è¯­-éŸ³æ ‡é—´è·
        for line in pho_lines:
            bbox = draw.textbbox((0,0), line, font=pho_font)
            w = bbox[2] - bbox[0]
            h = bbox[3] - bbox[1]
            x = (width - w)//2
            shadow_offset = 3
            draw.text((x+shadow_offset, y+shadow_offset), line, font=pho_font, fill=(0,0,0,128))
            draw.text((x, y), line, font=pho_font, fill=pho_color)
            y += h + line_spacing

    if chn_lines:
        y += pho_chn_spacing  # ä½¿ç”¨å¯è°ƒèŠ‚çš„éŸ³æ ‡-ä¸­æ–‡é—´è·
        for line in chn_lines:
            bbox = draw.textbbox((0,0), line, font=chn_font)
            w = bbox[2] - bbox[0]
            h = bbox[3] - bbox[1]
            x = (width - w)//2
            shadow_offset = 3
            draw.text((x+shadow_offset, y+shadow_offset), line, font=chn_font, fill=(0,0,0,128))
            draw.text((x, y), line, font=chn_font, fill=chn_color)
            y += h + line_spacing

    return img

# -----------------------
# Edge TTS helpers
# -----------------------
VOICE_OPTIONS = {
    "English - Female (US) - Aria": "en-US-AriaNeural",
    "English - Female (US) - Jenny": "en-US-JennyNeural",
    "English - Female (US) - Sara": "en-US-SaraNeural",
    "English - Male (US) - Davis": "en-US-DavisNeural",
    "English - Male (US) - Guy": "en-US-GuyNeural",
    "English - Male (US) - Tony": "en-US-TonyNeural",
    "English - Male (US) - Brian": "en-US-BrianNeural",
    "English - Male (US) - Eric": "en-US-EricNeural",
    "English - Female (UK) - Libby": "en-GB-LibbyNeural",
    "English - Female (UK) - Sonia": "en-GB-SoniaNeural",
    "English - Male (UK) - Ryan": "en-GB-RyanNeural",
    "English - Male (UK) - Alfie": "en-GB-AlfieNeural",
    "English - Male (UK) - George": "en-GB-GeorgeNeural",
    "English - Female (AU) - Natasha": "en-AU-NatashaNeural",
    "English - Male (AU) - William": "en-AU-WilliamNeural",
    "Chinese - Female (CN) - Xiaoxiao": "zh-CN-XiaoxiaoNeural",
    "Chinese - Female (CN) - Xiaoyi": "zh-CN-XiaoyiNeural",
    "Chinese - Female (CN) - Xiaochen": "zh-CN-XiaochenNeural",
    "Chinese - Female (CN) - Xiaohan": "zh-CN-XiaohanNeural",
    "Chinese - Male (CN) - Yunfeng": "zh-CN-YunfengNeural",
    "Chinese - Male (CN) - Yunyang": "zh-CN-YunyangNeural",
    "Chinese - Male (CN) - Yunjian": "zh-CN-YunjianNeural",
    "Chinese - Male (CN) - Yunze": "zh-CN-YunzeNeural",
    "Chinese - Male (CN) - Yunkai": "zh-CN-YunkaiNeural",
    "Chinese - Male (CN) - Yunxi": "zh-CN-YunxiNeural",
    "Chinese - Male (CN) - Yunhao": "zh-CN-YunhaoNeural",
    "Chinese - Male (CN) - Yunlong": "zh-CN-YunlongNeural",
    "Chinese - Female (TW) - HsiaoChen": "zh-TW-HsiaoChenNeural",
    "Chinese - Female (TW) - HsiaoYu": "zh-TW-HsiaoYuNeural",
    "Chinese - Male (TW) - YunJhe": "zh-TW-YunJheNeural",
    "Chinese - Male (TW) - YunSong": "zh-TW-YunSongNeural"
}

async def _edge_tts_save(text: str, voice_name: str, out_path: str, rate: str = "+0%"):
    try:
        communicate = edge_tts.Communicate(text, voice_name, rate=rate)
        await communicate.save(out_path)
        return True
    except Exception as e:
        st.error(f"TTSç”Ÿæˆå¤±è´¥: {e}")
        return False

def generate_edge_audio(text, voice, speed=1.0, out_path=None):
    if not EDGE_TTS_AVAILABLE:
        st.warning("Edge TTS ä¸å¯ç”¨")
        return None
    
    pct = int((speed - 1.0) * 100)
    rate_str = f"{pct:+d}%"
    
    if out_path is None:
        fd, out_path = tempfile.mkstemp(suffix='.mp3')
        os.close(fd)
    
    try:
        success = asyncio.run(_edge_tts_save(text, voice, out_path, rate_str))
        if success and os.path.exists(out_path) and os.path.getsize(out_path) > 0:
            return out_path
        else:
            if os.path.exists(out_path):
                os.unlink(out_path)
            return None
    except Exception as e:
        st.error(f"ç”ŸæˆéŸ³é¢‘å¼‚å¸¸: {e}")
        if os.path.exists(out_path):
            os.unlink(out_path)
        return None

def preview_voice(voice_name, text, speed=1.0):
    if not EDGE_TTS_AVAILABLE:
        return None
    
    pct = int((speed - 1.0) * 100)
    rate_str = f"{pct:+d}%"
    
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as f:
            temp_path = f.name
        
        success = asyncio.run(_edge_tts_save(text, voice_name, temp_path, rate_str))
        if success and os.path.exists(temp_path) and os.path.getsize(temp_path) > 0:
            with open(temp_path, 'rb') as audio_file:
                audio_bytes = audio_file.read()
            os.unlink(temp_path)
            return audio_bytes
        else:
            if os.path.exists(temp_path):
                os.unlink(temp_path)
            return None
    except Exception as e:
        if os.path.exists(temp_path):
            os.unlink(temp_path)
        return None

# -----------------------
# éŸ³é¢‘åˆå¹¶ / è§†é¢‘åˆå¹¶ (ä½¿ç”¨ FFmpeg æ›¿ä»£ pydub)
# -----------------------
def create_silent_audio(duration, output_path):
    """åˆ›å»ºé™éŸ³éŸ³é¢‘æ–‡ä»¶"""
    cmd = [
        "ffmpeg", "-y", "-f", "lavfi", "-i", f"anullsrc=r=44100:cl=stereo",
        "-t", str(duration), "-q:a", "9", "-acodec", "libmp3lame", output_path
    ]
    try:
        subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        return os.path.exists(output_path) and os.path.getsize(output_path) > 0
    except Exception as e:
        st.warning(f"åˆ›å»ºé™éŸ³éŸ³é¢‘å¤±è´¥: {e}")
        return False

def adjust_audio_duration(input_path, target_duration, output_path):
    """è°ƒæ•´éŸ³é¢‘åˆ°æŒ‡å®šæ—¶é•¿"""
    if not input_path or not os.path.exists(input_path):
        return create_silent_audio(target_duration, output_path)
    
    cmd = [
        "ffmpeg", "-y", "-i", input_path,
        "-t", str(target_duration),
        "-af", "apad", "-acodec", "libmp3lame", output_path
    ]
    try:
        subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        return os.path.exists(output_path) and os.path.getsize(output_path) > 0
    except Exception as e:
        st.warning(f"è°ƒæ•´éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")
        return create_silent_audio(target_duration, output_path)

def merge_audio_files(audio_paths, target_duration, pause_duration):
    """ä½¿ç”¨ FFmpeg åˆå¹¶éŸ³é¢‘æ–‡ä»¶"""
    if not check_ffmpeg():
        st.error("æœªæ£€æµ‹åˆ° ffmpegï¼Œæ— æ³•åˆå¹¶éŸ³é¢‘ã€‚")
        return None
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    with tempfile.TemporaryDirectory() as tmpdir:
        # åˆ›å»ºæ–‡ä»¶åˆ—è¡¨
        list_file = os.path.join(tmpdir, "audio_list.txt")
        output_path = os.path.join(tmpdir, "combined.mp3")
        
        valid_files = []
        
        for i, audio_path in enumerate(audio_paths):
            if audio_path and os.path.exists(audio_path) and os.path.getsize(audio_path) > 0:
                # è°ƒæ•´éŸ³é¢‘æ—¶é•¿
                adjusted_audio = os.path.join(tmpdir, f"adjusted_{i}.mp3")
                if adjust_audio_duration(audio_path, target_duration, adjusted_audio):
                    valid_files.append(adjusted_audio)
                    
                    # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªéŸ³é¢‘ï¼Œæ·»åŠ åœé¡¿
                    if i < len(audio_paths) - 1:
                        pause_audio = os.path.join(tmpdir, f"pause_{i}.mp3")
                        if create_silent_audio(pause_duration, pause_audio):
                            valid_files.append(pause_audio)
                else:
                    # å¦‚æœè°ƒæ•´å¤±è´¥ï¼Œä½¿ç”¨é™éŸ³æ›¿ä»£
                    silent_audio = os.path.join(tmpdir, f"silent_{i}.mp3")
                    if create_silent_audio(target_duration, silent_audio):
                        valid_files.append(silent_audio)
                        
                        if i < len(audio_paths) - 1:
                            pause_audio = os.path.join(tmpdir, f"pause_{i}.mp3")
                            if create_silent_audio(pause_duration, pause_audio):
                                valid_files.append(pause_audio)
            else:
                # å¦‚æœéŸ³é¢‘ä¸å­˜åœ¨ï¼Œä½¿ç”¨é™éŸ³æ›¿ä»£
                silent_audio = os.path.join(tmpdir, f"silent_{i}.mp3")
                if create_silent_audio(target_duration, silent_audio):
                    valid_files.append(silent_audio)
                    
                    if i < len(audio_paths) - 1:
                        pause_audio = os.path.join(tmpdir, f"pause_{i}.mp3")
                        if create_silent_audio(pause_duration, pause_audio):
                            valid_files.append(pause_audio)
        
        if not valid_files:
            st.error("æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶å¯åˆå¹¶")
            return None
            
        # å†™å…¥æ–‡ä»¶åˆ—è¡¨
        with open(list_file, 'w') as f:
            for file_path in valid_files:
                f.write(f"file '{file_path}'\n")
        
        # ä½¿ç”¨ concat åè®®åˆå¹¶éŸ³é¢‘
        cmd = [
            "ffmpeg", "-y", "-f", "concat", "-safe", "0",
            "-i", list_file, "-c", "copy", output_path
        ]
        
        try:
            result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
            if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                return output_path
            else:
                st.error("åˆå¹¶åçš„éŸ³é¢‘æ–‡ä»¶æ— æ•ˆ")
                return None
        except subprocess.CalledProcessError as e:
            st.error(f"éŸ³é¢‘åˆå¹¶å¤±è´¥: {e.stderr.decode() if e.stderr else str(e)}")
            return None
        except Exception as e:
            st.error(f"éŸ³é¢‘åˆå¹¶å¼‚å¸¸: {e}")
            return None

def merge_video_audio(video_path, audio_path, output_path):
    """åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘"""
    if not check_ffmpeg():
        st.error("æœªæ£€æµ‹åˆ° ffmpegï¼Œæ— æ³•åˆå¹¶éŸ³é¢‘ã€‚")
        return None
        
    if not os.path.exists(video_path) or not os.path.exists(audio_path):
        st.error("è§†é¢‘æˆ–éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        return None
        
    cmd = [
        "ffmpeg", "-y",
        "-i", video_path,
        "-i", audio_path,
        "-c:v", "copy",
        "-c:a", "aac",
        "-strict", "experimental",
        "-shortest",  # ç¡®ä¿è§†é¢‘é•¿åº¦ä¸éŸ³é¢‘ä¸€è‡´
        output_path
    ]
    
    try:
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        if result.returncode == 0 and os.path.exists(output_path) and os.path.getsize(output_path) > 0:
            return output_path
        else:
            st.error(f"ffmpeg åˆå¹¶å¤±è´¥: {result.stderr}")
            return None
    except Exception as e:
        st.error(f"è°ƒç”¨ ffmpeg å¤±è´¥: {e}")
        return None

# -----------------------
# ä¼˜åŒ–çš„è§†é¢‘ç”Ÿæˆå‡½æ•° - ä¿®å¤é‡å¤è¿›åº¦æ¡é—®é¢˜
# -----------------------
def generate_video_with_optimization(df, settings, progress_bar, status_placeholder):
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            video_no_audio = os.path.join(tmpdir, "video_no_audio.mp4")
            final_video = os.path.join(tmpdir, "final_video.mp4")
            
            width = settings['width']
            height = settings['height']
            fps = settings['fps']
            per_duration = settings['per_duration']
            pause_duration = settings['pause_duration']
            bg_color = settings['bg_color']
            bg_image = settings['bg_image']
            eng_color = settings['eng_color']
            chn_color = settings['chn_color']
            pho_color = settings['pho_color']
            eng_size = settings['eng_size']
            chn_size = settings['chn_size']
            pho_size = settings['pho_size']
            text_bg_enabled = settings['text_bg_enabled']
            text_bg_color = settings['text_bg_color']
            text_bg_padding = settings['text_bg_padding']
            text_bg_radius = settings['text_bg_radius']
            text_bg_width = settings['text_bg_width']
            text_bg_height = settings['text_bg_height']
            bold_text = settings['bold_text']
            segment_order = settings['segment_order']
            voice_mapping = settings['voice_mapping']
            tts_speed = settings['tts_speed']
            eng_pho_spacing = settings['eng_pho_spacing']
            pho_chn_spacing = settings['pho_chn_spacing']
            line_spacing = settings['line_spacing']
            
            per_duration_frames = int(round(per_duration * fps))
            pause_duration_frames = int(round(pause_duration * fps))
            
            total_segments = len(df) * len(segment_order)
            total_frames = total_segments * per_duration_frames + (total_segments - 1) * pause_duration_frames
            current_frame = 0
            
            writer = None
            audio_paths = []
            
            try:
                # å…ˆé¢„ç”Ÿæˆæ‰€æœ‰éŸ³é¢‘
                status_placeholder.info("ğŸµ æ­£åœ¨ç”ŸæˆéŸ³é¢‘...")
                for i, row in df.iterrows():
                    eng = str(row['è‹±è¯­'])
                    chn = str(row['ä¸­æ–‡'])
                    
                    for j, segment_type in enumerate(segment_order):
                        voice, text_type = voice_mapping[segment_type]
                        text_to_speak = eng if text_type == "english" else chn
                        
                        audio_file = generate_edge_audio(text_to_speak, voice, speed=tts_speed)
                        audio_paths.append(audio_file)
                        
                        # æ›´æ–°éŸ³é¢‘ç”Ÿæˆè¿›åº¦
                        audio_progress = (i * len(segment_order) + j + 1) / (len(df) * len(segment_order)) * 0.3
                        progress_bar.progress(audio_progress)
                
                # ç”Ÿæˆè§†é¢‘å¸§
                status_placeholder.info("ğŸ¬ æ­£åœ¨ç”Ÿæˆè§†é¢‘...")
                writer = imageio.get_writer(video_no_audio, fps=fps, macro_block_size=1, format='FFMPEG', codec='libx264')
                
                for i, row in df.iterrows():
                    eng = str(row['è‹±è¯­'])
                    chn = str(row['ä¸­æ–‡'])
                    pho = str(row['éŸ³æ ‡']) if pd.notna(row['éŸ³æ ‡']) else ""
                    
                    frame_img = create_frame(
                        english=eng, chinese=chn, phonetic=pho,
                        width=width, height=height,
                        bg_color=bg_color, bg_image=bg_image,
                        eng_color=eng_color, chn_color=chn_color, pho_color=pho_color,
                        eng_size=eng_size, chn_size=chn_size, pho_size=pho_size,
                        text_bg_enabled=text_bg_enabled,
                        text_bg_color=text_bg_color,
                        text_bg_padding=text_bg_padding,
                        text_bg_radius=text_bg_radius,
                        text_bg_width=text_bg_width,
                        text_bg_height=text_bg_height,
                        bold_text=bold_text,
                        eng_pho_spacing=eng_pho_spacing,
                        pho_chn_spacing=pho_chn_spacing,
                        line_spacing=line_spacing
                    )
                    
                    frame_array = np.array(frame_img.convert('RGB'))
                    
                    # ä¸ºæ¯ä¸ªç‰‡æ®µé‡å¤å¸§
                    for segment_idx in range(len(segment_order)):
                        for _ in range(per_duration_frames):
                            writer.append_data(frame_array)
                            current_frame += 1
                            if current_frame % 10 == 0:
                                video_progress = 0.3 + 0.5 * (current_frame / total_frames)
                                progress_bar.progress(min(video_progress, 0.8))
                        
                        # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªç‰‡æ®µï¼Œæ·»åŠ åœé¡¿
                        if not (i == len(df) - 1 and segment_idx == len(segment_order) - 1):
                            for _ in range(pause_duration_frames):
                                writer.append_data(frame_array)
                                current_frame += 1
                                if current_frame % 10 == 0:
                                    video_progress = 0.3 + 0.5 * (current_frame / total_frames)
                                    progress_bar.progress(min(video_progress, 0.8))
            
            except Exception as e:
                st.error(f"ç”Ÿæˆè§†é¢‘è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                return None
            finally:
                if writer is not None:
                    writer.close()
            
            # æ£€æŸ¥æ— å£°è§†é¢‘æ˜¯å¦ç”ŸæˆæˆåŠŸ
            if not os.path.exists(video_no_audio) or os.path.getsize(video_no_audio) == 0:
                st.error("æ— å£°è§†é¢‘ç”Ÿæˆå¤±è´¥")
                return None
            
            # åˆå¹¶éŸ³é¢‘
            status_placeholder.info("ğŸ”Š æ­£åœ¨åˆå¹¶éŸ³é¢‘...")
            progress_bar.progress(0.85)
            
            if any(p for p in audio_paths if p is not None) and check_ffmpeg():
                combined_audio_path = merge_audio_files(audio_paths, per_duration, pause_duration)
                if combined_audio_path and os.path.exists(combined_audio_path) and os.path.getsize(combined_audio_path) > 0:
                    # åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘
                    status_placeholder.info("ğŸµ æ­£åœ¨åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘...")
                    progress_bar.progress(0.9)
                    
                    merged = merge_video_audio(video_no_audio, combined_audio_path, final_video)
                    if merged:
                        final_video = merged
                        progress_bar.progress(1.0)
                    else:
                        st.warning("éŸ³é¢‘åˆå¹¶å¤±è´¥ï¼Œå°†ä½¿ç”¨æ— å£°è§†é¢‘")
                        final_video = video_no_audio
                else:
                    st.warning("éŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼Œå°†ä½¿ç”¨æ— å£°è§†é¢‘")
                    final_video = video_no_audio
            else:
                st.warning("æ— æ³•ç”ŸæˆéŸ³é¢‘ï¼Œå°†ä½¿ç”¨æ— å£°è§†é¢‘")
                final_video = video_no_audio
            
            if os.path.exists(final_video) and os.path.getsize(final_video) > 0:
                with open(final_video, "rb") as f:
                    video_bytes = f.read()
                return video_bytes
            else:
                st.error("ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º")
                return None
                
    except Exception as e:
        st.error(f"ç”Ÿæˆå¤±è´¥: {e}")
        st.text(traceback.format_exc())
        return None

# -----------------------
# UI ä¸ä¸»æµç¨‹
# -----------------------
st.markdown('<h1 class="main-header">ğŸ¬ æ—…è¡Œè‹±è¯­è§†é¢‘ç”Ÿæˆå™¨</h1>', unsafe_allow_html=True)
st.markdown("### å¤šéŸ³è‰²å¾ªç¯æ’­æ”¾ â€¢ ä¸“ä¸šçº§è§†é¢‘åˆ¶ä½œ")

# ä¸Šä¼  Excel
st.markdown('<div class="section-header">ğŸ“ 1. ä¸Šä¼ æ•°æ®æ–‡ä»¶</div>', unsafe_allow_html=True)

uploaded = st.file_uploader(
    "é€‰æ‹© Excel æ–‡ä»¶",
    type=["xlsx", "xls"],
    help="å¿…é¡»åŒ…å«åˆ—ï¼šè‹±è¯­ã€ä¸­æ–‡ã€éŸ³æ ‡",
    key="excel_uploader"
)

if uploaded:
    try:
        df = pd.read_excel(uploaded)
    except Exception as e:
        st.error(f"è¯»å– Excel å¤±è´¥ï¼š{e}")
        df = None
else:
    df = None

if df is not None:
    required = ['è‹±è¯­','ä¸­æ–‡','éŸ³æ ‡']
    miss = [c for c in required if c not in df.columns]
    if miss:
        st.error(f"Excel ç¼ºå°‘åˆ—ï¼š{', '.join(miss)}")
        st.stop()
    
    # æ•°æ®é¢„è§ˆ
    st.markdown('<div class="preview-section">', unsafe_allow_html=True)
    st.subheader("ğŸ“Š æ•°æ®é¢„è§ˆ")
    st.dataframe(df.head(10), height=220, use_container_width=True)
    st.info(f"ğŸ“ˆ å…± {len(df)} è¡Œæ•°æ®ï¼Œé¢„è®¡ç”Ÿæˆ {len(df) * 4} æ®µéŸ³é¢‘")
    st.markdown('</div>', unsafe_allow_html=True)

    # è®¾ç½®é¢æ¿ - ä¿®å¤ç©ºç™½æ¡†é—®é¢˜
    st.markdown('<div class="section-header">ğŸ¨ 2. è‡ªå®šä¹‰è®¾ç½®</div>', unsafe_allow_html=True)
    
    # ä½¿ç”¨æ ‡ç­¾é¡µç»„ç»‡è®¾ç½® - ç§»é™¤ä¸å¿…è¦çš„ç©ºç™½
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ¨ æ ·å¼è®¾ç½®", "ğŸ”Š éŸ³é¢‘è®¾ç½®", "ğŸ“ æ–‡å­—èƒŒæ™¯", "âš™ï¸ è§†é¢‘å‚æ•°"])
    
    with tab1:
        # ä½¿ç”¨ç´§å‡‘å¸ƒå±€
        col_bg, col_txt = st.columns([1, 2])
        
        with col_bg:
            st.subheader("ğŸ¨ èƒŒæ™¯è®¾ç½®")
            bg_type = st.radio("èƒŒæ™¯ç±»å‹", ["çº¯è‰²", "å›¾ç‰‡"], horizontal=True, key="bg_type")
            if bg_type == "çº¯è‰²":
                bg_hex = st.color_picker("èƒŒæ™¯é¢œè‰²", "#000000", key="bg_color_picker")
                bg_color = tuple(int(bg_hex[i:i+2],16) for i in (1,3,5))
                st.session_state.bg_image = None
            else:
                bg_file = st.file_uploader("ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡", type=["jpg","jpeg","png"], key="bg_image_uploader")
                if bg_file:
                    try:
                        st.session_state.bg_image = Image.open(bg_file)
                        st.image(st.session_state.bg_image, caption="èƒŒæ™¯é¢„è§ˆ", use_container_width=True)
                    except Exception as e:
                        st.error(f"æ‰“å¼€èƒŒæ™¯å›¾ç‰‡å¤±è´¥ï¼š{e}")
                        st.session_state.bg_image = None
                bg_color = (0,0,0)

        with col_txt:
            st.subheader("ğŸ“ æ–‡å­—æ ·å¼")
            c1, c2, c3 = st.columns(3)
            with c1:
                st.markdown("**è‹±è¯­è®¾ç½®**")
                eng_color = st.color_picker("é¢œè‰²", "#FFFFFF", key="eng_color")
                eng_color = tuple(int(eng_color[i:i+2],16) for i in (1,3,5))
                eng_size = st.slider("å­—å·", 20, 120, 80, key="eng_size")
            with c2:
                st.markdown("**éŸ³æ ‡è®¾ç½®**")
                pho_color = st.color_picker("é¢œè‰²", "#FFFF00", key="pho_color")
                pho_color = tuple(int(pho_color[i:i+2],16) for i in (1,3,5))
                pho_size = st.slider("å­—å·", 16, 100, 50, key="pho_size")
            with c3:
                st.markdown("**ä¸­æ–‡è®¾ç½®**")
                chn_color = st.color_picker("é¢œè‰²", "#ADD8E6", key="chn_color")
                chn_color = tuple(int(chn_color[i:i+2],16) for i in (1,3,5))
                chn_size = st.slider("å­—å·", 20, 120, 60, key="chn_size")
            
            bold_text = st.checkbox("æ–‡å­—åŠ ç²—", value=True, key="bold_text")
            
            # æ–‡å­—é—´è·è®¾ç½® - ç´§å‡‘å¸ƒå±€
            st.markdown("---")
            st.subheader("ğŸ“ æ–‡å­—é—´è·è®¾ç½®")
            col_spacing1, col_spacing2, col_spacing3 = st.columns(3)
            with col_spacing1:
                eng_pho_spacing = st.slider("è‹±è¯­-éŸ³æ ‡é—´è·", 10, 100, 30, key="eng_pho_spacing")
            with col_spacing2:
                pho_chn_spacing = st.slider("éŸ³æ ‡-ä¸­æ–‡é—´è·", 10, 100, 50, key="pho_chn_spacing")
            with col_spacing3:
                line_spacing = st.slider("è¡Œå†…é—´è·", 5, 50, 15, key="line_spacing")

    with tab2:
        st.subheader("ğŸ”Š æ’­æ”¾é¡ºåºè®¾ç½®")
        
        col_order1, col_order2, col_order3, col_order4 = st.columns(4)
        with col_order1:
            segment1_type = st.selectbox("ç¬¬1æ®µ", ["è‹±æ–‡ç”·å£°", "è‹±æ–‡å¥³å£°", "ä¸­æ–‡éŸ³è‰²"], index=0, key="segment1")
        with col_order2:
            segment2_type = st.selectbox("ç¬¬2æ®µ", ["è‹±æ–‡ç”·å£°", "è‹±æ–‡å¥³å£°", "ä¸­æ–‡éŸ³è‰²"], index=1, key="segment2")
        with col_order3:
            segment3_type = st.selectbox("ç¬¬3æ®µ", ["è‹±æ–‡ç”·å£°", "è‹±æ–‡å¥³å£°", "ä¸­æ–‡éŸ³è‰²"], index=2, key="segment3")
        with col_order4:
            segment4_type = st.selectbox("ç¬¬4æ®µ", ["è‹±æ–‡ç”·å£°", "è‹±æ–‡å¥³å£°", "ä¸­æ–‡éŸ³è‰²"], index=0, key="segment4")
        
        st.markdown(f'<div class="success-card">ğŸµ æ’­æ”¾é¡ºåºï¼š{segment1_type} â†’ {segment2_type} â†’ {segment3_type} â†’ {segment4_type}</div>', unsafe_allow_html=True)

        st.subheader("ğŸ™ï¸ éŸ³è‰²é€‰æ‹©ä¸è¯•å¬")
        
        col_voice1, col_voice2, col_voice3 = st.columns(3)
        
        with col_voice1:
            st.markdown("**è‹±æ–‡ç”·å£°**")
            male_english_voices = {k:v for k,v in VOICE_OPTIONS.items() if "Male" in k and "English" in k}
            male_english_label = st.selectbox("é€‰æ‹©ç”·å£°éŸ³è‰²", list(male_english_voices.keys()), index=2, key="male_voice")
            male_english_voice = male_english_voices[male_english_label]
            
            if st.button("ğŸ§ è¯•å¬ç”·å£°", key="preview_male_english"):
                preview_text = "Hello, this is a preview of the male English voice."
                audio_bytes = preview_voice(male_english_voice, preview_text, tts_speed)
                if audio_bytes:
                    st.audio(audio_bytes, format="audio/mp3")
                else:
                    st.warning("è¯•å¬ç”Ÿæˆå¤±è´¥")

        with col_voice2:
            st.markdown("**è‹±æ–‡å¥³å£°**")
            female_english_voices = {k:v for k,v in VOICE_OPTIONS.items() if "Female" in k and "English" in k}
            female_english_label = st.selectbox("é€‰æ‹©å¥³å£°éŸ³è‰²", list(female_english_voices.keys()), index=2, key="female_voice")
            female_english_voice = female_english_voices[female_english_label]
            
            if st.button("ğŸ§ è¯•å¬å¥³å£°", key="preview_female_english"):
                preview_text = "Hello, this is a preview of the female English voice."
                audio_bytes = preview_voice(female_english_voice, preview_text, tts_speed)
                if audio_bytes:
                    st.audio(audio_bytes, format="audio/mp3")
                else:
                    st.warning("è¯•å¬ç”Ÿæˆå¤±è´¥")

        with col_voice3:
            st.markdown("**ä¸­æ–‡éŸ³è‰²**")
            chinese_voices = {k:v for k,v in VOICE_OPTIONS.items() if "Chinese" in k}
            chinese_label = st.selectbox("é€‰æ‹©ä¸­æ–‡éŸ³è‰²", list(chinese_voices.keys()), index=0, key="chinese_voice")
            chinese_voice = chinese_voices[chinese_label]
            
            if st.button("ğŸ§ è¯•å¬ä¸­æ–‡", key="preview_chinese"):
                preview_text = "ä½ å¥½ï¼Œè¿™æ˜¯ä¸­æ–‡éŸ³è‰²çš„é¢„è§ˆã€‚"
                audio_bytes = preview_voice(chinese_voice, preview_text, tts_speed)
                if audio_bytes:
                    st.audio(audio_bytes, format="audio/mp3")
                else:
                    st.warning("è¯•å¬ç”Ÿæˆå¤±è´¥")

        col_speed, col_pause = st.columns(2)
        with col_speed:
            tts_speed = st.slider("è¯­é€Ÿè°ƒèŠ‚", 0.5, 2.0, 1.0, 0.1, key="tts_speed")
            st.info(f"å½“å‰è¯­é€Ÿ: {tts_speed}x")
        with col_pause:
            pause_duration = st.slider("æ¯ç»„åœé¡¿æ—¶é—´ï¼ˆç§’ï¼‰", 0.0, 3.0, 0.5, 0.1, key="pause_duration")

    with tab3:
        st.subheader("ğŸ–¼ï¸ æ–‡å­—èƒŒæ™¯åŒºåŸŸ")
        text_bg_enabled = st.checkbox("å¯ç”¨æ–‡å­—èƒŒæ™¯åŒºåŸŸ", value=True, key="text_bg_enabled")
        if text_bg_enabled:
            col_bg_size1, col_bg_size2 = st.columns(2)
            with col_bg_size1:
                text_bg_width = st.slider("æ–‡å­—èƒŒæ™¯å®½åº¦", 520, 1600, 1000, key="text_bg_width")
            with col_bg_size2:
                text_bg_height = st.slider("æ–‡å­—èƒŒæ™¯é«˜åº¦", 200, 800, 400, key="text_bg_height")
                
            text_bg_hex = st.color_picker("æ–‡å­—èƒŒæ™¯é¢œè‰²", "#FFFFFF", key="text_bg_color")
            text_bg_rgb = tuple(int(text_bg_hex[i:i+2],16) for i in (1,3,5))
            text_bg_alpha = st.slider("æ–‡å­—èƒŒæ™¯é€æ˜åº¦", 0, 255, 180, key="text_bg_alpha")
            text_bg_color = text_bg_rgb + (text_bg_alpha,)
            text_bg_padding = st.slider("æ–‡å­—èƒŒæ™¯å†…è¾¹è·", 10, 50, 20, key="text_bg_padding")
            text_bg_radius = st.slider("æ–‡å­—èƒŒæ™¯åœ†è§’", 0, 50, 30, key="text_bg_radius")
        else:
            text_bg_color = (255,255,255,180)
            text_bg_padding = 20
            text_bg_radius = 30
            text_bg_width = None
            text_bg_height = None

    with tab4:
        st.subheader("âš™ï¸ è§†é¢‘å‚æ•°")
        col_v1, col_v2 = st.columns(2)
        with col_v1:
            per_duration = st.slider("æ¯æ®µéŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰", 2, 8, 4, key="per_duration")
            fps = st.slider("å¸§ç‡", 8, 30, 20, key="fps")
        with col_v2:
            width = st.selectbox("åˆ†è¾¨ç‡å®½åº¦", [640, 960, 1280, 1920], index=3, key="width")
            height = int(width * 9 / 16)
            st.info(f"åˆ†è¾¨ç‡: {width} Ã— {height}")

    # é¢„è§ˆå•è¡Œ
    st.markdown('<div class="section-header">ğŸ‘ï¸ 3. é¢„è§ˆæ•ˆæœ</div>', unsafe_allow_html=True)
    
    if not df.empty:
        st.markdown('<div class="preview-section">', unsafe_allow_html=True)
        col_preview1, col_preview2 = st.columns([1, 2])
        
        with col_preview1:
            idx = st.slider("é€‰æ‹©é¢„è§ˆè¡Œ", 0, min(len(df)-1, 9), 0, key="preview_row")
            row = df.iloc[idx]
            st.write(f"**è‹±è¯­:** {row['è‹±è¯­']}")
            st.write(f"**éŸ³æ ‡:** {row['éŸ³æ ‡'] if pd.notna(row['éŸ³æ ‡']) else 'æ— '}")
            st.write(f"**ä¸­æ–‡:** {row['ä¸­æ–‡']}")
        
        with col_preview2:
            preview_img = create_frame(
                english=str(row['è‹±è¯­']),
                chinese=str(row['ä¸­æ–‡']),
                phonetic=str(row['éŸ³æ ‡']) if pd.notna(row['éŸ³æ ‡']) else "",
                width=width, height=height,
                bg_color=bg_color, bg_image=st.session_state.bg_image,
                eng_color=eng_color, chn_color=chn_color, pho_color=pho_color,
                eng_size=eng_size, chn_size=chn_size, pho_size=pho_size,
                text_bg_enabled=text_bg_enabled,
                text_bg_color=text_bg_color,
                text_bg_padding=text_bg_padding,
                text_bg_radius=text_bg_radius,
                text_bg_width=text_bg_width,
                text_bg_height=text_bg_height,
                bold_text=bold_text,
                eng_pho_spacing=eng_pho_spacing,
                pho_chn_spacing=pho_chn_spacing,
                line_spacing=line_spacing
            )
            st.image(preview_img, caption="å¸§é¢„è§ˆ", use_container_width=True)
        st.markdown('</div>', unsafe_allow_html=True)

    # ç”ŸæˆæŒ‰é’® - ä¿®å¤é‡å¤è¿›åº¦æ¡é—®é¢˜
    st.markdown('<div class="section-header">ğŸš€ 4. ç”Ÿæˆè§†é¢‘</div>', unsafe_allow_html=True)
    
    if len(df) > 20:
        st.markdown(f'<div class="warning-card">âš ï¸ æ•°æ®é‡è¾ƒå¤§ï¼ˆ{len(df)} è¡Œï¼‰ï¼Œç”Ÿæˆå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ã€‚å»ºè®®åˆ†æ‰¹å¤„ç†æˆ–å‡å°‘æ¯æ®µéŸ³é¢‘æ—¶é•¿ã€‚</div>', unsafe_allow_html=True)
    
    col_gen1, col_gen2, col_gen3 = st.columns([1, 2, 1])
    with col_gen2:
        if st.button("ğŸ¬ å¼€å§‹ç”Ÿæˆè§†é¢‘", use_container_width=True, key="generate_button"):
            # åˆ›å»ºçŠ¶æ€å ä½ç¬¦å’Œå•ä¸€è¿›åº¦æ¡
            status_placeholder = st.empty()
            progress_bar = st.progress(0)
            
            with st.spinner("ğŸ¥ æ­£åœ¨ç”Ÿæˆè§†é¢‘ - ä¼šä¸ºæ¯è¡Œç”Ÿæˆ4æ®µéŸ³é¢‘ï¼Œè¯·è€å¿ƒç­‰å¾…..."):
                # åˆ›å»ºè¯­éŸ³ç±»å‹åˆ°å®é™…è¯­éŸ³çš„æ˜ å°„
                voice_mapping = {
                    "è‹±æ–‡ç”·å£°": (male_english_voice, "english"),
                    "è‹±æ–‡å¥³å£°": (female_english_voice, "english"), 
                    "ä¸­æ–‡éŸ³è‰²": (chinese_voice, "chinese")
                }
                
                # è·å–æ’­æ”¾é¡ºåº
                segment_order = [segment1_type, segment2_type, segment3_type, segment4_type]
                
                # æ”¶é›†æ‰€æœ‰è®¾ç½®
                settings = {
                    'width': width,
                    'height': height,
                    'fps': fps,
                    'per_duration': per_duration,
                    'pause_duration': pause_duration,
                    'bg_color': bg_color,
                    'bg_image': st.session_state.bg_image,
                    'eng_color': eng_color,
                    'chn_color': chn_color,
                    'pho_color': pho_color,
                    'eng_size': eng_size,
                    'chn_size': chn_size,
                    'pho_size': pho_size,
                    'text_bg_enabled': text_bg_enabled,
                    'text_bg_color': text_bg_color,
                    'text_bg_padding': text_bg_padding,
                    'text_bg_radius': text_bg_radius,
                    'text_bg_width': text_bg_width,
                    'text_bg_height': text_bg_height,
                    'bold_text': bold_text,
                    'segment_order': segment_order,
                    'voice_mapping': voice_mapping,
                    'tts_speed': tts_speed,
                    'eng_pho_spacing': eng_pho_spacing,
                    'pho_chn_spacing': pho_chn_spacing,
                    'line_spacing': line_spacing
                }
                
                # ä½¿ç”¨ä¼˜åŒ–çš„ç”Ÿæˆå‡½æ•°
                video_bytes = generate_video_with_optimization(df, settings, progress_bar, status_placeholder)
                
                if video_bytes:
                    status_placeholder.success("âœ… è§†é¢‘ç”Ÿæˆå®Œæˆï¼")
                    
                    # æ˜¾ç¤ºè§†é¢‘å’Œä¸‹è½½æŒ‰é’®
                    col_vid1, col_vid2, col_vid3 = st.columns([1, 2, 1])
                    with col_vid2:
                        st.video(video_bytes)
                        
                        # ä¸‹è½½æŒ‰é’®
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½è§†é¢‘",
                            data=video_bytes,
                            file_name="travel_english_video.mp4",
                            mime="video/mp4",
                            use_container_width=True,
                            key="download_button"
                        )
                else:
                    status_placeholder.error("è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®æˆ–é‡è¯•")

# ä¾§è¾¹æ ä¿¡æ¯
with st.sidebar:
    st.markdown("## â„¹ï¸ ä½¿ç”¨æŒ‡å—")
    
    with st.expander("ğŸ“ æ•°æ®æ ¼å¼è¦æ±‚", expanded=True):
        st.markdown("""
        Excel æ–‡ä»¶å¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—ï¼š
        - **è‹±è¯­**: è‹±æ–‡å¥å­
        - **ä¸­æ–‡**: ä¸­æ–‡ç¿»è¯‘  
        - **éŸ³æ ‡**: éŸ³æ ‡æ ‡æ³¨ï¼ˆå¯é€‰ï¼‰
        """)
    
    with st.expander("ğŸµ éŸ³é¢‘è®¾ç½®è¯´æ˜"):
        st.markdown("""
        - **æ’­æ”¾é¡ºåº**: è®¾ç½®4æ®µéŸ³é¢‘çš„æ’­æ”¾é¡ºåº
        - **éŸ³è‰²é€‰æ‹©**: ä¸ºä¸åŒè¯­è¨€é€‰æ‹©åˆé€‚éŸ³è‰²
        - **è¯­é€Ÿè°ƒèŠ‚**: 0.5x-2.0x å¯è°ƒ
        - **åœé¡¿æ—¶é—´**: æ¯ç»„ä¹‹é—´çš„é—´éš”
        """)
    
    with st.expander("ğŸ¨ æ ·å¼è®¾ç½®æç¤º"):
        st.markdown("""
        - **èƒŒæ™¯**: çº¯è‰²æˆ–è‡ªå®šä¹‰å›¾ç‰‡
        - **æ–‡å­—**: æ”¯æŒä¸­è‹±æ–‡å’ŒéŸ³æ ‡
        - **èƒŒæ™¯åŒºåŸŸ**: å¢å¼ºæ–‡å­—å¯è¯»æ€§
        - **å­—ä½“**: è‡ªåŠ¨é€‚é…æœ€ä½³å­—ä½“
        - **é—´è·**: å¯è°ƒèŠ‚æ–‡å­—é—´è·ç¦»
        """)
    
    with st.expander("âš™ï¸ ç³»ç»Ÿè¦æ±‚"):
        st.markdown("""
        - **ç½‘ç»œ**: éœ€è¦è”ç½‘
        - **æµè§ˆå™¨**: å»ºè®®ä½¿ç”¨ Chrome/Firefox
        - **æ•°æ®é‡**: å»ºè®®æ¯æ¬¡ä¸è¶…è¿‡50è¡Œ
        - **å¤„ç†æ—¶é—´**: æ ¹æ®æ•°æ®é‡å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ
        """)

# é¡µè„š
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: #666;'>"
    "ğŸ¬ æ—…è¡Œè‹±è¯­è§†é¢‘ç”Ÿæˆå™¨ | ä¸“ä¸šçº§å¤šéŸ³è‰²è§†é¢‘åˆ¶ä½œå·¥å…·"
    "</div>", 
    unsafe_allow_html=True
)

# éšè— Streamlit é»˜è®¤èœå•å’Œé¡µè„š
hide_streamlit_style = """
<style>
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
.stDeployButton {display:none;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)
