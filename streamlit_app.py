import streamlit as st
import pandas as pd
import os
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import imageio.v2 as imageio
import tempfile
import shutil
from gtts import gTTS
from pydub import AudioSegment
import subprocess
import traceback

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ—…æ¸¸è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨",
    page_icon="ğŸ¬",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'bg_image' not in st.session_state:
    st.session_state.bg_image = None
if 'audio_available' not in st.session_state:
    st.session_state.audio_available = True  # æ ‡è®°éŸ³é¢‘åŠŸèƒ½æ˜¯å¦å¯ç”¨


# --------------------------
# æ ¸å¿ƒåŠŸèƒ½å‡½æ•°
# --------------------------
def check_ffmpeg():
    """æ£€æŸ¥ffmpegæ˜¯å¦å¯ç”¨"""
    return shutil.which('ffmpeg') is not None

def wrap_text(text, max_chars):
    """æ–‡æœ¬è‡ªåŠ¨æ¢è¡Œå¤„ç†"""
    if not text or str(text).strip().lower() == 'nan':
        return [""]
    
    text = str(text).strip()
    # ä¸­æ–‡é€‚é…ï¼šå‡å°‘æ¯è¡Œå­—ç¬¦æ•°
    if any('\u4e00' <= c <= '\u9fff' for c in text):
        max_chars = min(max_chars, 15)
    
    words = text.split()
    lines, current = [], []
    for word in words:
        test_line = ' '.join(current + [word])
        if len(test_line) <= max_chars:
            current.append(word)
        else:
            if current:
                lines.append(' '.join(current))
            # å¤„ç†è¶…é•¿å•è¯
            if len(word) > max_chars:
                for i in range(0, len(word), max_chars):
                    lines.append(word[i:i+max_chars])
                current = []
            else:
                current = [word]
    if current:
        lines.append(' '.join(current))
    return lines

def get_font(size):
    """è·å–å­—ä½“ï¼ˆå…¼å®¹ä¸åŒç¯å¢ƒï¼‰"""
    try:
        # å°è¯•åŠ è½½ç³»ç»Ÿä¸­æ–‡å­—ä½“ï¼ˆå¤šå¹³å°å…¼å®¹ï¼‰
        for font_name in ["SimHei", "WenQuanYi Micro Hei", "Heiti TC", "Arial Unicode MS"]:
            return ImageFont.truetype(font_name, size)
        # åŠ è½½å¤±è´¥æ—¶è¿”å›é»˜è®¤å­—ä½“
        return ImageFont.load_default()
    except:
        return ImageFont.load_default()

def create_frame(english, chinese, phonetic, width=1280, height=720, 
                bg_color=(0,0,0), bg_image=None,
                eng_color=(255,255,255), chn_color=(0,255,255), pho_color=(255,255,0),
                eng_size=60, chn_size=50, pho_size=40):
    """åˆ›å»ºå•å¸§å›¾åƒï¼ˆæ–‡å­—å±…ä¸­æ˜¾ç¤ºï¼‰"""
    # åˆ›å»ºèƒŒæ™¯
    if bg_image:
        try:
            img = bg_image.resize((width, height), Image.Resampling.LANCZOS).convert('RGB')
        except:
            img = Image.new('RGB', (width, height), bg_color)
    else:
        img = Image.new('RGB', (width, height), bg_color)
    
    draw = ImageDraw.Draw(img)
    # è·å–å­—ä½“
    eng_font = get_font(eng_size)
    chn_font = get_font(chn_size)
    pho_font = get_font(pho_size)
    
    # æ–‡æœ¬æ¢è¡Œå¤„ç†
    eng_lines = wrap_text(english, 30)
    chn_lines = wrap_text(chinese, 15)
    pho_lines = wrap_text(phonetic, 35) if phonetic else []
    
    # è®¡ç®—æ–‡æœ¬æ€»é«˜åº¦ï¼ˆå«é—´è·ï¼‰
    line_spacing = 10
    total_height = 0
    # è‹±è¯­æ–‡æœ¬é«˜åº¦
    for line in eng_lines:
        _, _, _, h = draw.textbbox((0,0), line, font=eng_font)
        total_height += h
    total_height += line_spacing * (len(eng_lines) - 1)
    # ä¸­æ–‡æ–‡æœ¬é«˜åº¦ï¼ˆåŠ æ®µè½é—´è·ï¼‰
    if chn_lines:
        total_height += 20  # æ®µè½é—´è·
        for line in chn_lines:
            _, _, _, h = draw.textbbox((0,0), line, font=chn_font)
            total_height += h
        total_height += line_spacing * (len(chn_lines) - 1)
    # éŸ³æ ‡æ–‡æœ¬é«˜åº¦ï¼ˆåŠ æ®µè½é—´è·ï¼‰
    if pho_lines:
        total_height += 15  # æ®µè½é—´è·
        for line in pho_lines:
            _, _, _, h = draw.textbbox((0,0), line, font=pho_font)
            total_height += h
        total_height += line_spacing * (len(pho_lines) - 1)
    
    # è®¡ç®—èµ·å§‹Yåæ ‡ï¼ˆå‚ç›´å±…ä¸­ï¼‰
    y = (height - total_height) // 2
    
    # ç»˜åˆ¶è‹±è¯­
    for line in eng_lines:
        w, h = draw.textbbox((0,0), line, font=eng_font)[2:]
        x = (width - w) // 2
        # æ–‡æœ¬é˜´å½±ï¼ˆå¢å¼ºå¯è¯»æ€§ï¼‰
        draw.text((x+1, y+1), line, font=eng_font, fill=(0,0,0,128))
        draw.text((x, y), line, font=eng_font, fill=eng_color)
        y += h + line_spacing
    
    # ç»˜åˆ¶ä¸­æ–‡
    if chn_lines:
        y += 10  # æ®µè½é—´è·
        for line in chn_lines:
            w, h = draw.textbbox((0,0), line, font=chn_font)[2:]
            x = (width - w) // 2
            draw.text((x+1, y+1), line, font=chn_font, fill=(0,0,0,128))
            draw.text((x, y), line, font=chn_font, fill=chn_color)
            y += h + line_spacing
    
    # ç»˜åˆ¶éŸ³æ ‡
    if pho_lines:
        y += 5  # æ®µè½é—´è·
        for line in pho_lines:
            w, h = draw.textbbox((0,0), line, font=pho_font)[2:]
            x = (width - w) // 2
            draw.text((x+1, y+1), line, font=pho_font, fill=(0,0,0,128))
            draw.text((x, y), line, font=pho_font, fill=pho_color)
            y += h + line_spacing
    
    return img

def generate_audio(text, lang='en', speed=1.0):
    """ç”ŸæˆTTSéŸ³é¢‘"""
    try:
        tts = gTTS(text=text, lang=lang, slow=speed < 0.9)
        with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as f:
            tts.save(f.name)
            return f.name
    except Exception as e:
        st.error(f"éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")
        st.session_state.audio_available = False
        return None

def merge_audio_files(audio_paths, target_duration):
    """åˆå¹¶éŸ³é¢‘å¹¶åŒ¹é…è§†é¢‘æ—¶é•¿"""
    combined = AudioSegment.empty()
    for path in audio_paths:
        if not path:
            continue
        try:
            audio = AudioSegment.from_mp3(path)
            # ç¡®ä¿éŸ³é¢‘æ—¶é•¿ä¸è§†é¢‘å¸§æ—¶é•¿ä¸€è‡´
            if len(audio) > target_duration * 1000:  # è½¬æ¢ä¸ºæ¯«ç§’
                audio = audio[:int(target_duration * 1000)]
            else:
                # ä¸è¶³æ—¶è¡¥é™éŸ³
                silence = AudioSegment.silent(duration=int(target_duration * 1000) - len(audio))
                audio += silence
            combined += audio
            os.remove(path)  # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        except Exception as e:
            st.warning(f"éŸ³é¢‘ç‰‡æ®µå¤„ç†å¤±è´¥: {str(e)}")
    return combined

def merge_video_audio(video_path, audio_path, output_path):
    """ç”¨ffmpegåˆå¹¶éŸ³è§†é¢‘"""
    if not check_ffmpeg():
        st.error("æœªæ‰¾åˆ°ffmpegï¼Œè¯·å®‰è£…åé‡è¯•ï¼ˆhttps://ffmpeg.org/ï¼‰")
        return None
    
    cmd = [
        'ffmpeg', '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
        '-i', video_path,
        '-i', audio_path,
        '-c:v', 'copy',  # è§†é¢‘æµç›´æ¥å¤åˆ¶
        '-c:a', 'aac',   # éŸ³é¢‘è½¬ç ä¸ºAAC
        '-strict', 'experimental',
        output_path
    ]
    
    try:
        result = subprocess.run(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        if result.returncode != 0:
            st.error(f"ffmpegé”™è¯¯: {result.stderr}")
            return None
        return output_path
    except Exception as e:
        st.error(f"éŸ³è§†é¢‘åˆå¹¶å¤±è´¥: {str(e)}")
        return None


# --------------------------
# é¡µé¢UIä¸é€»è¾‘
# --------------------------
st.title("ğŸ¬ æ—…æ¸¸è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨")
st.markdown("ç”ŸæˆåŒ…å«è‹±è¯­å¥å­ã€ä¸­æ–‡ç¿»è¯‘å’ŒéŸ³æ ‡çš„å¸¦éŸ³é¢‘è§†é¢‘")

# æ£€æŸ¥ffmpegçŠ¶æ€
if not check_ffmpeg():
    st.warning("âš ï¸ æœªæ£€æµ‹åˆ°ffmpegï¼ŒéŸ³é¢‘åŠŸèƒ½å¯èƒ½æ— æ³•ä½¿ç”¨ï¼ˆéœ€å®‰è£…ffmpegæ”¯æŒï¼‰")

# 1. æ–‡ä»¶ä¸Šä¼ 
st.header("1. ä¸Šä¼ Excelæ–‡ä»¶")
uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=['xlsx', 'xls'])

if uploaded_file:
    try:
        df = pd.read_excel(uploaded_file)
        required_cols = ['è‹±è¯­', 'ä¸­æ–‡', 'éŸ³æ ‡']
        missing = [c for c in required_cols if c not in df.columns]
        
        if missing:
            st.error(f"Excelç¼ºå°‘å¿…è¦åˆ—: {', '.join(missing)}")
        else:
            st.success("æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
            st.dataframe(df, height=200)
            
            # 2. è‡ªå®šä¹‰è®¾ç½®
            st.header("2. è‡ªå®šä¹‰è®¾ç½®")
            
            # èƒŒæ™¯è®¾ç½®
            bg_type = st.radio("èƒŒæ™¯ç±»å‹", ["çº¯è‰²", "å›¾ç‰‡"])
            bg_color = (0,0,0)
            if bg_type == "çº¯è‰²":
                bg_hex = st.color_picker("èƒŒæ™¯é¢œè‰²", "#000000")
                bg_color = tuple(int(bg_hex[i:i+2], 16) for i in (1,3,5))
                st.session_state.bg_image = None
            else:
                bg_file = st.file_uploader("ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡", type=['jpg','jpeg','png'])
                if bg_file:
                    try:
                        st.session_state.bg_image = Image.open(bg_file)
                        st.image(st.session_state.bg_image, caption="èƒŒæ™¯é¢„è§ˆ", width=300)
                    except Exception as e:
                        st.error(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}")
                        st.session_state.bg_image = None
            
            # æ–‡å­—è®¾ç½®
            st.subheader("æ–‡å­—æ ·å¼")
            col1, col2, col3 = st.columns(3)
            with col1:
                eng_color = st.color_picker("è‹±è¯­é¢œè‰²", "#FFFFFF")
                eng_color = tuple(int(eng_color[i:i+2], 16) for i in (1,3,5))
                eng_size = st.slider("è‹±è¯­å­—å·", 20, 100, 60)
            with col2:
                chn_color = st.color_picker("ä¸­æ–‡é¢œè‰²", "#00FFFF")
                chn_color = tuple(int(chn_color[i:i+2], 16) for i in (1,3,5))
                chn_size = st.slider("ä¸­æ–‡å­—å·", 20, 100, 50)
            with col3:
                pho_color = st.color_picker("éŸ³æ ‡é¢œè‰²", "#FFFF00")
                pho_color = tuple(int(pho_color[i:i+2], 16) for i in (1,3,5))
                pho_size = st.slider("éŸ³æ ‡å­—å·", 16, 80, 40)
            
            # è§†é¢‘ä¸éŸ³é¢‘è®¾ç½®
            st.subheader("è§†é¢‘ä¸éŸ³é¢‘")
            col4, col5 = st.columns(2)
            with col4:
                duration = st.slider("æ¯å¥æ˜¾ç¤ºæ—¶é—´(ç§’)", 2, 10, 5)
                fps = st.slider("å¸§ç‡", 10, 30, 24)
            with col5:
                tts_lang = st.selectbox("è¯­éŸ³è¯­è¨€", ["è‹±è¯­", "ä¸­æ–‡"])
                tts_speed = st.slider("è¯­éŸ³é€Ÿåº¦", 0.5, 2.0, 1.0)
                tts_lang_code = "en" if tts_lang == "è‹±è¯­" else "zh-CN"
            
            # 3. é¢„è§ˆ
            st.header("3. é¢„è§ˆæ•ˆæœ")
            if not df.empty:
                preview_idx = st.slider("é€‰æ‹©é¢„è§ˆè¡Œ", 0, len(df)-1, 0)
                row = df.iloc[preview_idx]
                preview_img = create_frame(
                    english=str(row['è‹±è¯­']),
                    chinese=str(row['ä¸­æ–‡']),
                    phonetic=str(row['éŸ³æ ‡']) if pd.notna(row['éŸ³æ ‡']) else "",
                    bg_color=bg_color,
                    bg_image=st.session_state.bg_image,
                    eng_color=eng_color,
                    chn_color=chn_color,
                    pho_color=pho_color,
                    eng_size=eng_size,
                    chn_size=chn_size,
                    pho_size=pho_size
                )
                st.image(preview_img, caption="å¸§é¢„è§ˆ")
            
            # 4. ç”Ÿæˆè§†é¢‘
            st.header("4. ç”Ÿæˆè§†é¢‘")
            if st.button("å¼€å§‹ç”Ÿæˆ", type="primary"):
                with st.spinner("æ­£åœ¨ç”Ÿæˆè§†é¢‘..."):
                    try:
                        with tempfile.TemporaryDirectory() as temp_dir:
                            # ç”Ÿæˆè§†é¢‘å¸§
                            frames = []
                            audio_paths = []
                            total_frames = len(df) * duration * fps
                            progress = st.progress(0)
                            current = 0
                            
                            for idx, row in df.iterrows():
                                # ç”Ÿæˆå•å¸§
                                frame = create_frame(
                                    english=str(row['è‹±è¯­']),
                                    chinese=str(row['ä¸­æ–‡']),
                                    phonetic=str(row['éŸ³æ ‡']) if pd.notna(row['éŸ³æ ‡']) else "",
                                    bg_color=bg_color,
                                    bg_image=st.session_state.bg_image,
                                    eng_color=eng_color,
                                    chn_color=chn_color,
                                    pho_color=pho_color,
                                    eng_size=eng_size,
                                    chn_size=chn_size,
                                    pho_size=pho_size
                                )
                                # é‡å¤å¸§ä»¥è¾¾åˆ°æ—¶é•¿
                                for _ in range(duration * fps):
                                    frames.append(np.array(frame.convert('RGB')))
                                
                                # ç”Ÿæˆå¯¹åº”éŸ³é¢‘
                                if st.session_state.audio_available:
                                    audio_path = generate_audio(
                                        text=str(row['è‹±è¯­']),
                                        lang=tts_lang_code,
                                        speed=tts_speed
                                    )
                                    audio_paths.append(audio_path)
                                
                                # æ›´æ–°è¿›åº¦
                                current += duration * fps
                                progress.progress(min(current / total_frames, 1.0))
                            
                            # ä¿å­˜è§†é¢‘ï¼ˆæ— éŸ³é¢‘ï¼‰
                            video_path = os.path.join(temp_dir, "video_no_audio.mp4")
                            imageio.mimsave(video_path, frames, fps=fps)
                            
                            # å¤„ç†éŸ³é¢‘
                            final_video_path = video_path  # é»˜è®¤æ— éŸ³é¢‘
                            if st.session_state.audio_available and audio_paths:
                                # åˆå¹¶éŸ³é¢‘
                                combined_audio = merge_audio_files(audio_paths, duration)
                                audio_path = os.path.join(temp_dir, "combined_audio.mp3")
                                combined_audio.export(audio_path, format="mp3")
                                
                                # åˆå¹¶éŸ³è§†é¢‘
                                final_video_path = os.path.join(temp_dir, "video_with_audio.mp4")
                                if not merge_video_audio(video_path, audio_path, final_video_path):
                                    final_video_path = video_path  # åˆå¹¶å¤±è´¥åˆ™ä½¿ç”¨æ— éŸ³é¢‘ç‰ˆæœ¬
                            
                            # æä¾›ä¸‹è½½
                            with open(final_video_path, "rb") as f:
                                video_bytes = f.read()
                            
                            st.success("è§†é¢‘ç”Ÿæˆå®Œæˆï¼")
                            st.video(video_bytes)
                            st.download_button(
                                "ä¸‹è½½è§†é¢‘",
                                data=video_bytes,
                                file_name="travel_english_video.mp4",
                                mime="video/mp4"
                            )
                            progress.progress(1.0)
                            
                    except Exception as e:
                        st.error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
                        st.text(traceback.format_exc())  # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
    
    except Exception as e:
        st.error(f"æ–‡ä»¶å¤„ç†é”™è¯¯: {str(e)}")
else:
    st.info("è¯·å…ˆä¸Šä¼ åŒ…å«'è‹±è¯­'ã€'ä¸­æ–‡'ã€'éŸ³æ ‡'ä¸‰åˆ—çš„Excelæ–‡ä»¶")