import streamlit as st
import pandas as pd
import os
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import imageio.v2 as imageio
import tempfile
import shutil
from pydub import AudioSegment
import subprocess
import traceback

# å°è¯•å¯¼å…¥ gTTSï¼ˆå¦‚æœæ²¡æœ‰å®‰è£…åˆ™ç¦ç”¨è¯­éŸ³åŠŸèƒ½ï¼‰
try:
    from gtts import gTTS
    GTTS_AVAILABLE = True
except Exception:
    GTTS_AVAILABLE = False

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ—…æ¸¸è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨",
    page_icon="ğŸ¬",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'bg_image' not in st.session_state:
    st.session_state.bg_image = None
if 'audio_available' not in st.session_state:
    # åªæœ‰åœ¨ gTTS å¯ç”¨å¹¶ä¸”æœ¬æœº/éƒ¨ç½²ç¯å¢ƒå…è®¸å¤–ç½‘è¯·æ±‚æ—¶æ‰å¯èƒ½çœŸæ­£å¯ç”¨
    st.session_state.audio_available = GTTS_AVAILABLE


# --------------------------
# å·¥å…·å‡½æ•°
# --------------------------
def check_ffmpeg():
    """æ£€æŸ¥ffmpegæ˜¯å¦å¯ç”¨"""
    return shutil.which('ffmpeg') is not None


def wrap_text(text, max_chars):
    """æ–‡æœ¬è‡ªåŠ¨æ¢è¡Œå¤„ç†"""
    if not text or str(text).strip().lower() == 'nan':
        return [""]

    text = str(text).strip()
    # ä¸­æ–‡é€‚é…ï¼šå‡å°‘æ¯è¡Œå­—ç¬¦æ•°
    if any('\u4e00' <= c <= '\u9fff' for c in text):
        max_chars = min(max_chars, 15)

    words = text.split()
    lines, current = [], []
    for word in words:
        test_line = ' '.join(current + [word])
        if len(test_line) <= max_chars:
            current.append(word)
        else:
            if current:
                lines.append(' '.join(current))
            # å¤„ç†è¶…é•¿å•è¯
            if len(word) > max_chars:
                for i in range(0, len(word), max_chars):
                    lines.append(word[i:i + max_chars])
                current = []
            else:
                current = [word]
    if current:
        lines.append(' '.join(current))
    return lines


def get_font(size):
    """è·å–å­—ä½“ï¼ˆå…¼å®¹ä¸åŒç¯å¢ƒï¼‰"""
    try:
        # å°è¯•å¸¸è§ä¸­æ–‡/é€šç”¨å­—ä½“
        for font_name in ["SimHei", "WenQuanYi Micro Hei", "Heiti TC", "Arial Unicode MS", "NotoSansCJK-Regular.ttc"]:
            try:
                return ImageFont.truetype(font_name, size)
            except Exception:
                continue
        # é»˜è®¤
        return ImageFont.load_default()
    except:
        return ImageFont.load_default()


def create_frame(english, chinese, phonetic, width=1280, height=720,
                 bg_color=(0, 0, 0), bg_image=None,
                 eng_color=(255, 255, 255), chn_color=(0, 255, 255), pho_color=(255, 255, 0),
                 eng_size=60, chn_size=50, pho_size=40):
    """åˆ›å»ºå•å¸§å›¾åƒï¼ˆæ–‡å­—å±…ä¸­æ˜¾ç¤ºï¼‰
    é¡ºåºï¼šè‹±è¯­ï¼ˆä¸Šï¼‰ -> éŸ³æ ‡ï¼ˆä¸­ï¼‰ -> ä¸­æ–‡ï¼ˆä¸‹ï¼‰
    """
    # èƒŒæ™¯
    if bg_image:
        try:
            img = bg_image.resize((width, height), Image.Resampling.LANCZOS).convert('RGB')
        except Exception:
            img = Image.new('RGB', (width, height), bg_color)
    else:
        img = Image.new('RGB', (width, height), bg_color)

    draw = ImageDraw.Draw(img)
    eng_font = get_font(eng_size)
    chn_font = get_font(chn_size)
    pho_font = get_font(pho_size)

    # æ–‡æœ¬æ¢è¡Œ
    eng_lines = wrap_text(english, 30)
    chn_lines = wrap_text(chinese, 15)
    pho_lines = wrap_text(phonetic, 35) if phonetic else []

    # è®¡ç®—æ€»é«˜åº¦ï¼ˆè‹±è¯­ -> éŸ³æ ‡ -> ä¸­æ–‡ï¼‰
    line_spacing = 10
    total_height = 0

    # è‹±è¯­é«˜åº¦
    for line in eng_lines:
        _, _, _, h = draw.textbbox((0, 0), line, font=eng_font)
        total_height += h
    total_height += line_spacing * (len(eng_lines) - 1)

    # éŸ³æ ‡é«˜åº¦
    if pho_lines:
        total_height += 20  # æ®µè½é—´è·
        for line in pho_lines:
            _, _, _, h = draw.textbbox((0, 0), line, font=pho_font)
            total_height += h
        total_height += line_spacing * (len(pho_lines) - 1)

    # ä¸­æ–‡é«˜åº¦
    if chn_lines:
        total_height += 20
        for line in chn_lines:
            _, _, _, h = draw.textbbox((0, 0), line, font=chn_font)
            total_height += h
        total_height += line_spacing * (len(chn_lines) - 1)

    # èµ·å§‹ yï¼ˆå‚ç›´å±…ä¸­ï¼‰
    y = (height - total_height) // 2

    # ç»˜åˆ¶è‹±è¯­
    for line in eng_lines:
        w, h = draw.textbbox((0, 0), line, font=eng_font)[2:]
        x = (width - w) // 2
        # é˜´å½±å¢å¼ºå¯è¯»æ€§
        draw.text((x + 1, y + 1), line, font=eng_font, fill=(0, 0, 0, 128))
        draw.text((x, y), line, font=eng_font, fill=eng_color)
        y += h + line_spacing

    # ç»˜åˆ¶éŸ³æ ‡ï¼ˆæ”¾åœ¨è‹±è¯­ä¸‹ï¼‰
    if pho_lines:
        y += 10
        for line in pho_lines:
            w, h = draw.textbbox((0, 0), line, font=pho_font)[2:]
            x = (width - w) // 2
            draw.text((x + 1, y + 1), line, font=pho_font, fill=(0, 0, 0, 128))
            draw.text((x, y), line, font=pho_font, fill=pho_color)
            y += h + line_spacing

    # ç»˜åˆ¶ä¸­æ–‡ï¼ˆæ”¾åœ¨éŸ³æ ‡ä¸‹ï¼‰
    if chn_lines:
        y += 10
        for line in chn_lines:
            w, h = draw.textbbox((0, 0), line, font=chn_font)[2:]
            x = (width - w) // 2
            draw.text((x + 1, y + 1), line, font=chn_font, fill=(0, 0, 0, 128))
            draw.text((x, y), line, font=chn_font, fill=chn_color)
            y += h + line_spacing

    return img


def generate_audio(text, lang='en', speed=1.0):
    """ç”ŸæˆTTSéŸ³é¢‘ï¼›è‹¥ gTTS ä¸å¯ç”¨åˆ™è¿”å› Noneï¼ˆä¸æŠ›å¼‚å¸¸ï¼‰"""
    if not st.session_state.audio_available or not GTTS_AVAILABLE:
        return None
    try:
        # gTTS çš„ slow å‚æ•°æ˜¯å¸ƒå°”ï¼šTrue -> æ…¢é€Ÿï¼›è¿™é‡Œæˆ‘ä»¬æŠŠ speed<0.9 è§†ä¸ºæ…¢é€Ÿ
        tts = gTTS(text=text, lang=lang, slow=speed < 0.9)
        with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as f:
            tts.save(f.name)
            return f.name
    except Exception as e:
        # å‡ºé”™æ—¶ç¦ç”¨åç»­éŸ³é¢‘ç”Ÿæˆå¹¶æ˜¾ç¤ºè­¦å‘Š
        st.warning(f"éŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼ˆå·²ç¦ç”¨éŸ³é¢‘åŠŸèƒ½ï¼‰ï¼š{e}")
        st.session_state.audio_available = False
        return None


def merge_audio_files(audio_paths, target_duration):
    """åˆå¹¶éŸ³é¢‘å¹¶åŒ¹é…æ¯å¥æ—¶é•¿ï¼ˆç§’ï¼‰"""
    combined = AudioSegment.empty()
    for path in audio_paths:
        if not path:
            # å¦‚æœæŸå¥æ²¡æœ‰éŸ³é¢‘ï¼ˆç”Ÿæˆå¤±è´¥æˆ–ä¸å¯ç”¨ï¼‰ï¼Œè¡¥é™éŸ³
            silence = AudioSegment.silent(duration=int(target_duration * 1000))
            combined += silence
            continue
        try:
            audio = AudioSegment.from_mp3(path)
            if len(audio) > target_duration * 1000:
                audio = audio[:int(target_duration * 1000)]
            else:
                silence = AudioSegment.silent(duration=int(target_duration * 1000) - len(audio))
                audio += silence
            combined += audio
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(path)
            except Exception:
                pass
        except Exception as e:
            st.warning(f"å¤„ç†éŸ³é¢‘ç‰‡æ®µå¤±è´¥ï¼š{e}")
            silence = AudioSegment.silent(duration=int(target_duration * 1000))
            combined += silence
    return combined


def merge_video_audio(video_path, audio_path, output_path):
    """ç”¨ ffmpeg åˆå¹¶éŸ³è§†é¢‘æµï¼ˆéœ€è¦ç³»ç»Ÿå®‰è£… ffmpegï¼‰"""
    if not check_ffmpeg():
        st.error("æœªæ‰¾åˆ° ffmpegï¼Œæ— æ³•åˆå¹¶éŸ³è§†é¢‘ï¼ˆè¯·å®‰è£… ffmpegï¼‰ã€‚")
        return None

    cmd = [
        'ffmpeg', '-y',
        '-i', video_path,
        '-i', audio_path,
        '-c:v', 'copy',
        '-c:a', 'aac',
        '-strict', 'experimental',
        output_path
    ]
    try:
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        if result.returncode != 0:
            st.error(f"ffmpeg é”™è¯¯ï¼š{result.stderr}")
            return None
        return output_path
    except Exception as e:
        st.error(f"åˆå¹¶éŸ³è§†é¢‘å¤±è´¥ï¼š{e}")
        return None


# --------------------------
# Streamlit UI
# --------------------------
st.title("ğŸ¬ æ—…æ¸¸è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨")
st.markdown("ç”ŸæˆåŒ…å«è‹±è¯­ã€éŸ³æ ‡å’Œä¸­æ–‡çš„å¸¦éŸ³é¢‘è§†é¢‘ï¼ˆæ”¯æŒé¢œè‰²/å­—å·/èƒŒæ™¯/è¯­é€Ÿï¼‰")

# gTTS çŠ¶æ€æç¤º
if GTTS_AVAILABLE:
    st.info("æ£€æµ‹åˆ° gTTSï¼šè¯­éŸ³åŠŸèƒ½å¯ç”¨ï¼ˆå¦‚æœç½‘ç»œå’Œç¯å¢ƒå…è®¸ï¼‰ã€‚")
else:
    st.warning("æœªæ£€æµ‹åˆ° gTTSï¼šè¯­éŸ³åŠŸèƒ½å·²ç¦ç”¨ã€‚å¦‚éœ€å¯ç”¨ï¼Œè¯·åœ¨ shell ä¸­è¿è¡Œ `pip install gTTS`ï¼Œç„¶åé‡å¯ç¨‹åºã€‚")

# æ£€æŸ¥ ffmpeg
if not check_ffmpeg():
    st.warning("âš ï¸ æœªæ£€æµ‹åˆ° ffmpegã€‚è‹¥éœ€è¦è§†é¢‘å¸¦éŸ³é¢‘ï¼Œè¯·å®‰è£… ffmpeg å¹¶ç¡®ä¿å‘½ä»¤è¡Œå¯ç”¨ï¼ˆffmpeg -versionï¼‰ã€‚")

# ä¸Šä¼ æ–‡ä»¶
st.header("1. ä¸Šä¼ Excelæ–‡ä»¶")
uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶ï¼ˆå¿…é¡»åŒ…å«åˆ—ï¼šè‹±è¯­ã€ä¸­æ–‡ã€éŸ³æ ‡ï¼‰", type=['xlsx', 'xls'])

if uploaded_file:
    try:
        df = pd.read_excel(uploaded_file)
        required_cols = ['è‹±è¯­', 'ä¸­æ–‡', 'éŸ³æ ‡']
        missing = [c for c in required_cols if c not in df.columns]

        if missing:
            st.error(f"Excel ç¼ºå°‘å¿…è¦åˆ—: {', '.join(missing)}")
        else:
            st.success("æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
            st.dataframe(df, height=200)

            # è‡ªå®šä¹‰è®¾ç½®
            st.header("2. è‡ªå®šä¹‰è®¾ç½®")

            # èƒŒæ™¯è®¾ç½®
            bg_type = st.radio("èƒŒæ™¯ç±»å‹", ["çº¯è‰²", "å›¾ç‰‡"])
            bg_color = (0, 0, 0)
            if bg_type == "çº¯è‰²":
                bg_hex = st.color_picker("èƒŒæ™¯é¢œè‰²", "#000000")
                bg_color = tuple(int(bg_hex[i:i + 2], 16) for i in (1, 3, 5))
                st.session_state.bg_image = None
            else:
                bg_file = st.file_uploader("ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡", type=['jpg', 'jpeg', 'png'])
                if bg_file:
                    try:
                        st.session_state.bg_image = Image.open(bg_file)
                        st.image(st.session_state.bg_image, caption="èƒŒæ™¯é¢„è§ˆ", width=300)
                    except Exception as e:
                        st.error(f"èƒŒæ™¯å›¾ç‰‡å¤„ç†å¤±è´¥ï¼š{e}")
                        st.session_state.bg_image = None

            # æ–‡å­—æ ·å¼
            st.subheader("æ–‡å­—æ ·å¼")
            col1, col2, col3 = st.columns(3)
            with col1:
                eng_color = st.color_picker("è‹±è¯­é¢œè‰²", "#FFFFFF")
                eng_color = tuple(int(eng_color[i:i + 2], 16) for i in (1, 3, 5))
                eng_size = st.slider("è‹±è¯­å­—å·", 20, 100, 60)
            with col2:
                pho_color = st.color_picker("éŸ³æ ‡é¢œè‰²", "#FFFF00")
                pho_color = tuple(int(pho_color[i:i + 2], 16) for i in (1, 3, 5))
                pho_size = st.slider("éŸ³æ ‡å­—å·", 16, 80, 40)
            with col3:
                chn_color = st.color_picker("ä¸­æ–‡é¢œè‰²", "#00FFFF")
                chn_color = tuple(int(chn_color[i:i + 2], 16) for i in (1, 3, 5))
                chn_size = st.slider("ä¸­æ–‡å­—å·", 20, 100, 50)

            # è§†é¢‘ä¸éŸ³é¢‘è®¾ç½®
            st.subheader("è§†é¢‘ä¸éŸ³é¢‘")
            col4, col5 = st.columns(2)
            with col4:
                duration = st.slider("æ¯å¥æ˜¾ç¤ºæ—¶é—´(ç§’)", 2, 10, 5)
                fps = st.slider("å¸§ç‡", 10, 30, 24)
            with col5:
                tts_lang = st.selectbox("è¯­éŸ³è¯­è¨€", ["è‹±è¯­", "ä¸­æ–‡"])
                tts_speed = st.slider("è¯­éŸ³é€Ÿåº¦", 0.5, 2.0, 1.0)
                tts_lang_code = "en" if tts_lang == "è‹±è¯­" else "zh-CN"

            # é¢„è§ˆ
            st.header("3. é¢„è§ˆæ•ˆæœ")
            if not df.empty:
                preview_idx = st.slider("é€‰æ‹©é¢„è§ˆè¡Œ", 0, len(df) - 1, 0)
                row = df.iloc[preview_idx]
                preview_img = create_frame(
                    english=str(row['è‹±è¯­']),
                    chinese=str(row['ä¸­æ–‡']),
                    phonetic=str(row['éŸ³æ ‡']) if pd.notna(row['éŸ³æ ‡']) else "",
                    bg_color=bg_color,
                    bg_image=st.session_state.bg_image,
                    eng_color=eng_color,
                    chn_color=chn_color,
                    pho_color=pho_color,
                    eng_size=eng_size,
                    chn_size=chn_size,
                    pho_size=pho_size
                )
                st.image(preview_img, caption="å¸§é¢„è§ˆ")

            # ç”Ÿæˆè§†é¢‘
            st.header("4. ç”Ÿæˆè§†é¢‘")
            if st.button("å¼€å§‹ç”Ÿæˆ", type="primary"):
                with st.spinner("æ­£åœ¨ç”Ÿæˆè§†é¢‘...ï¼ˆå»ºè®®å…ˆç”¨å°‘é‡è¡Œå’Œè¾ƒä½å¸§ç‡æµ‹è¯•ï¼‰"):
                    try:
                        with tempfile.TemporaryDirectory() as temp_dir:
                            frames = []
                            audio_paths = []
                            total_frames = len(df) * duration * fps
                            progress = st.progress(0)
                            current = 0

                            # é€è¡Œç”Ÿæˆå¸§ä¸éŸ³é¢‘ï¼ˆå¸§é‡å¤ä»¥è¾¾åˆ°æ—¶é•¿ï¼‰
                            for idx, row in df.iterrows():
                                frame = create_frame(
                                    english=str(row['è‹±è¯­']),
                                    chinese=str(row['ä¸­æ–‡']),
                                    phonetic=str(row['éŸ³æ ‡']) if pd.notna(row['éŸ³æ ‡']) else "",
                                    bg_color=bg_color,
                                    bg_image=st.session_state.bg_image,
                                    eng_color=eng_color,
                                    chn_color=chn_color,
                                    pho_color=pho_color,
                                    eng_size=eng_size,
                                    chn_size=chn_size,
                                    pho_size=pho_size
                                )
                                for _ in range(duration * fps):
                                    frames.append(np.array(frame.convert('RGB')))

                                # ç”ŸæˆéŸ³é¢‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                                if st.session_state.audio_available:
                                    audio_path = generate_audio(
                                        text=str(row['è‹±è¯­']),
                                        lang=tts_lang_code,
                                        speed=tts_speed
                                    )
                                    audio_paths.append(audio_path)
                                else:
                                    audio_paths.append(None)

                                current += duration * fps
                                progress.progress(min(current / total_frames, 1.0))

                            # ä¿å­˜æ— éŸ³é¢‘è§†é¢‘ï¼ˆä¸´æ—¶ï¼‰
                            video_path = os.path.join(temp_dir, "video_no_audio.mp4")
                            imageio.mimsave(video_path, frames, fps=fps)

                            final_video_path = video_path
                            # å¦‚æœéŸ³é¢‘å¯ç”¨ä¸” ffmpeg å¯ç”¨ï¼Œåˆå¹¶éŸ³é¢‘
                            if st.session_state.audio_available and any(p is not None for p in audio_paths):
                                combined_audio = merge_audio_files(audio_paths, duration)
                                audio_path = os.path.join(temp_dir, "combined_audio.mp3")
                                combined_audio.export(audio_path, format="mp3")

                                final_video_path = os.path.join(temp_dir, "video_with_audio.mp4")
                                if not merge_video_audio(video_path, audio_path, final_video_path):
                                    final_video_path = video_path

                            # è¯»å–å¹¶æä¾›ä¸‹è½½
                            with open(final_video_path, "rb") as f:
                                video_bytes = f.read()

                            st.success("âœ… è§†é¢‘ç”Ÿæˆå®Œæˆï¼")
                            st.video(video_bytes)
                            st.download_button(
                                "ä¸‹è½½è§†é¢‘",
                                data=video_bytes,
                                file_name="travel_english_video.mp4",
                                mime="video/mp4"
                            )
                            progress.progress(1.0)

                    except Exception as e:
                        st.error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
                        st.text(traceback.format_exc())

    except Exception as e:
        st.error(f"æ–‡ä»¶å¤„ç†é”™è¯¯: {str(e)}")
else:
    st.info("è¯·å…ˆä¸Šä¼ åŒ…å« 'è‹±è¯­'ã€'ä¸­æ–‡'ã€'éŸ³æ ‡' ä¸‰åˆ—çš„ Excel æ–‡ä»¶")
