import streamlit as st
import pandas as pd
import time
import io
import os
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import imageio.v2 as imageio
from io import BytesIO
import base64
import requests

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ—…æ¸¸è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨",
    page_icon="ğŸ¬",
    layout="wide"
)

st.title("ğŸ¬ æ—…æ¸¸è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨")
st.markdown("### ğŸŒ é«˜çº§è‡ªå®šä¹‰è§†é¢‘ç”Ÿæˆ - æ”¯æŒä¸­æ–‡å­—ä½“å’ŒèƒŒæ™¯å›¾ç‰‡")

# åˆå§‹åŒ–session state
if 'background_image' not in st.session_state:
    st.session_state.background_image = None

# ç‰¹æ€§ä»‹ç»
col1, col2, col3 = st.columns(3)
with col1:
    st.info("ğŸ¨ å®Œå…¨è‡ªå®šä¹‰\n\né¢œè‰²ã€å­—ä½“ã€èƒŒæ™¯éšæ„è°ƒæ•´")

with col2:
    st.info("ğŸ–¼ï¸ èƒŒæ™¯å›¾ç‰‡\n\næ”¯æŒè‡ªå®šä¹‰èƒŒæ™¯æˆ–çº¯è‰²")

with col3:
    st.info("ğŸ”¤ å­—ä½“æ”¯æŒ\n\nå®Œç¾æ˜¾ç¤ºä¸­æ–‡å’ŒéŸ³æ ‡")

# æ–‡ä»¶ä¸Šä¼ 
st.header("ğŸ“¤ ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ Excelæ–‡ä»¶")
uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=['xlsx', 'xls'], 
                                help="Excelæ–‡ä»¶å¿…é¡»åŒ…å«'è‹±è¯­','ä¸­æ–‡','éŸ³æ ‡'ä¸‰åˆ—")

def load_font(font_path, size):
    """åŠ è½½å­—ä½“ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›é»˜è®¤å­—ä½“"""
    try:
        return ImageFont.truetype(font_path, size)
    except:
        try:
            # å°è¯•ç³»ç»Ÿé»˜è®¤å­—ä½“
            return ImageFont.load_default()
        except:
            # æœ€åå¤‡é€‰æ–¹æ¡ˆ
            return None

def get_available_fonts():
    """è·å–å¯ç”¨å­—ä½“åˆ—è¡¨"""
    fonts = {
        "é»˜è®¤å­—ä½“": "default",
        "Arial": "arial.ttf",
        "Times New Roman": "times.ttf",
        "Courier New": "cour.ttf",
        # ä¸­æ–‡å­—ä½“ - åœ¨Railwayä¸­å¯èƒ½ä¸å¯ç”¨ï¼Œä½†æä¾›é€‰é¡¹
        "å¾®è½¯é›…é»‘": "msyh.ttc",
        "å®‹ä½“": "simsun.ttc",
        "é»‘ä½“": "simhei.ttf"
    }
    return fonts

def wrap_text(text, max_chars, font=None):
    """å°†æ–‡æœ¬æŒ‰æœ€å¤§å­—ç¬¦æ•°æ¢è¡Œ"""
    if not text or str(text) == 'nan':
        return [""]
    
    text = str(text)
    words = text.split()
    lines = []
    current_line = []
    
    for word in words:
        # å¦‚æœå½“å‰è¡ŒåŠ ä¸Šæ–°å•è¯ä¸è¶…è¿‡æœ€å¤§å­—ç¬¦æ•°
        test_line = ' '.join(current_line + [word])
        if len(test_line) <= max_chars:
            current_line.append(word)
        else:
            if current_line:
                lines.append(' '.join(current_line))
            current_line = [word]
    
    if current_line:
        lines.append(' '.join(current_line))
    
    return lines if lines else [text[:max_chars]]

def create_video_frame(text_english, text_chinese, text_phonetic, width=1280, height=720, 
                      bg_color=(0, 0, 0), bg_image=None, 
                      english_color=(255, 255, 255), chinese_color=(0, 255, 255), phonetic_color=(255, 255, 0),
                      english_size=60, chinese_size=50, phonetic_size=40,
                      font_family="default"):
    """åˆ›å»ºå•ä¸ªè§†é¢‘å¸§"""
    
    # åˆ›å»ºå›¾åƒ
    if bg_image:
        # ä½¿ç”¨èƒŒæ™¯å›¾ç‰‡
        img = bg_image.resize((width, height))
        # æ·»åŠ åŠé€æ˜é»‘è‰²è¦†ç›–å±‚ï¼Œæé«˜æ–‡å­—å¯è¯»æ€§
        overlay = Image.new('RGBA', (width, height), (0, 0, 0, 128))
        img = Image.alpha_composite(img.convert('RGBA'), overlay).convert('RGB')
    else:
        # ä½¿ç”¨çº¯è‰²èƒŒæ™¯
        img = Image.new('RGB', (width, height), color=bg_color)
    
    draw = ImageDraw.Draw(img)
    
    # åŠ è½½å­—ä½“
    fonts = get_available_fonts()
    font_path = fonts.get(font_family, "default")
    
    english_font = load_font(font_path, english_size) if font_path != "default" else None
    chinese_font = load_font(font_path, chinese_size) if font_path != "default" else None
    phonetic_font = load_font(font_path, phonetic_size) if font_path != "default" else None
    
    # è®¡ç®—æ–‡æœ¬ä½ç½®
    y_start = height // 4
    
    # ç»˜åˆ¶è‹±è¯­å¥å­
    english_lines = wrap_text(text_english, 35)
    for i, line in enumerate(english_lines):
        y_pos = y_start + i * (english_size + 10)
        if english_font:
            try:
                bbox = draw.textbbox((0, 0), line, font=english_font)
                text_width = bbox[2] - bbox[0]
                x = (width - text_width) // 2
                draw.text((x, y_pos), line, fill=english_color, font=english_font, align='center')
            except:
                # å­—ä½“æ¸²æŸ“å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ–¹å¼
                x = (width - len(line) * (english_size // 2)) // 2
                draw.text((x, y_pos), line, fill=english_color, align='center')
        else:
            x = (width - len(line) * (english_size // 2)) // 2
            draw.text((x, y_pos), line, fill=english_color, align='center')
    
    # ç»˜åˆ¶ä¸­æ–‡ç¿»è¯‘
    chinese_y = y_start + len(english_lines) * (english_size + 10) + 30
    chinese_lines = wrap_text(text_chinese, 20)  # ä¸­æ–‡æ¯è¡Œè¾ƒå°‘å­—ç¬¦
    for i, line in enumerate(chinese_lines):
        y_pos = chinese_y + i * (chinese_size + 10)
        if chinese_font:
            try:
                bbox = draw.textbbox((0, 0), line, font=chinese_font)
                text_width = bbox[2] - bbox[0]
                x = (width - text_width) // 2
                draw.text((x, y_pos), line, fill=chinese_color, font=chinese_font, align='center')
            except:
                x = (width - len(line) * (chinese_size // 2)) // 2
                draw.text((x, y_pos), line, fill=chinese_color, align='center')
        else:
            x = (width - len(line) * (chinese_size // 2)) // 2
            draw.text((x, y_pos), line, fill=chinese_color, align='center')
    
    # ç»˜åˆ¶éŸ³æ ‡
    phonetic_y = chinese_y + len(chinese_lines) * (chinese_size + 10) + 20
    if text_phonetic and str(text_phonetic).strip() and str(text_phonetic) != 'nan':
        phonetic_lines = wrap_text(text_phonetic, 40)
        for i, line in enumerate(phonetic_lines):
            y_pos = phonetic_y + i * (phonetic_size + 5)
            if phonetic_font:
                try:
                    bbox = draw.textbbox((0, 0), line, font=phonetic_font)
                    text_width = bbox[2] - bbox[0]
                    x = (width - text_width) // 2
                    draw.text((x, y_pos), line, fill=phonetic_color, font=phonetic_font, align='center')
                except:
                    x = (width - len(line) * (phonetic_size // 2)) // 2
                    draw.text((x, y_pos), line, fill=phonetic_color, align='center')
            else:
                x = (width - len(line) * (phonetic_size // 2)) // 2
                draw.text((x, y_pos), line, fill=phonetic_color, align='center')
    
    # æ·»åŠ åº•éƒ¨è¾¹æ¡†å’Œä¿¡æ¯
    border_height = 3
    draw.rectangle([0, height - 60, width, height - 60 + border_height], fill=(100, 100, 100))
    
    info_text = "æ—…æ¸¸è‹±è¯­å­¦ä¹ è§†é¢‘ - è‡ªåŠ¨ç”Ÿæˆ"
    if chinese_font:
        try:
            bbox = draw.textbbox((0, 0), info_text, font=chinese_font)
            text_width = bbox[2] - bbox[0]
            x = (width - text_width) // 2
            draw.text((x, height - 40), info_text, fill=(150, 150, 150), font=chinese_font)
        except:
            x = (width - len(info_text) * 10) // 2
            draw.text((x, height - 40), info_text, fill=(150, 150, 150))
    else:
        x = (width - len(info_text) * 10) // 2
        draw.text((x, height - 40), info_text, fill=(150, 150, 150))
    
    return img

def generate_video_from_dataframe(df, video_title, settings):
    """ä»DataFrameç”Ÿæˆè§†é¢‘"""
    video_buffer = BytesIO()
    
    width, height = settings['resolution']
    fps = settings['fps']
    duration_per_sentence = settings['duration_per_sentence']
    
    # å‡†å¤‡èƒŒæ™¯å›¾ç‰‡
    bg_image = None
    if settings['background_type'] == 'image' and st.session_state.background_image:
        try:
            bg_image = Image.open(st.session_state.background_image).convert('RGB')
        except:
            bg_image = None
    
    # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
    with imageio.get_writer(video_buffer, format='FFMPEG', mode='I', fps=fps, 
                          codec='libx264', quality=8, 
                          pixelformat='yuv420p') as writer:
        
        # ä¸ºæ¯ä¸ªå¥å­ç”Ÿæˆè§†é¢‘å¸§
        total_frames = len(df) * duration_per_sentence * fps
        current_frame = 0
        
        for idx, row in df.iterrows():
            english = str(row['è‹±è¯­']) if pd.notna(row['è‹±è¯­']) else ""
            chinese = str(row['ä¸­æ–‡']) if pd.notna(row['ä¸­æ–‡']) else ""
            phonetic = str(row['éŸ³æ ‡']) if pd.notna(row['éŸ³æ ‡']) and str(row['éŸ³æ ‡']) != 'nan' else ""
            
            frames_for_sentence = duration_per_sentence * fps
            
            for frame_idx in range(frames_for_sentence):
                frame_img = create_video_frame(
                    english, chinese, phonetic, width, height,
                    bg_color=settings['bg_color'],
                    bg_image=bg_image,
                    english_color=settings['english_color'],
                    chinese_color=settings['chinese_color'],
                    phonetic_color=settings['phonetic_color'],
                    english_size=settings['english_size'],
                    chinese_size=settings['chinese_size'],
                    phonetic_size=settings['phonetic_size'],
                    font_family=settings['font_family']
                )
                
                frame_array = np.array(frame_img)
                writer.append_data(frame_array)
                
                current_frame += 1
                yield current_frame / total_frames
        
        # æ·»åŠ ç»“æŸå¸§
        end_frames = 3 * fps
        end_img = create_end_frame(width, height, len(df), video_title, settings)
        for i in range(end_frames):
            end_array = np.array(end_img)
            writer.append_data(end_array)
            yield (total_frames + i) / (total_frames + end_frames)

def create_end_frame(width, height, sentence_count, title, settings):
    """åˆ›å»ºç»“æŸå¸§"""
    bg_image = None
    if settings['background_type'] == 'image' and st.session_state.background_image:
        try:
            bg_image = Image.open(st.session_state.background_image).convert('RGB')
            bg_image = bg_image.resize((width, height))
            overlay = Image.new('RGBA', (width, height), (0, 0, 0, 180))
            bg_image = Image.alpha_composite(bg_image.convert('RGBA'), overlay).convert('RGB')
        except:
            bg_image = None
    
    if not bg_image:
        bg_image = Image.new('RGB', (width, height), color=settings['bg_color'])
    
    draw = ImageDraw.Draw(bg_image)
    
    fonts = get_available_fonts()
    font_path = fonts.get(settings['font_family'], "default")
    large_font = load_font(font_path, 60) if font_path != "default" else None
    medium_font = load_font(font_path, 40) if font_path != "default" else None
    
    # ç»“æŸæ–‡å­—
    texts = [
        ("è§†é¢‘ç»“æŸ", settings['chinese_color']),
        (f"å…±å­¦ä¹  {sentence_count} ä¸ªå¥å­", (200, 200, 200)),
        ("è°¢è°¢è§‚çœ‹", settings['phonetic_color']),
        (title, settings['english_color'])
    ]
    
    y_pos = height // 4
    for text, color in texts:
        if large_font or medium_font:
            try:
                font = large_font if text == title else medium_font
                bbox = draw.textbbox((0, 0), text, font=font)
                text_width = bbox[2] - bbox[0]
                x = (width - text_width) // 2
                draw.text((x, y_pos), text, fill=color, font=font, align='center')
            except:
                x = (width - len(text) * 15) // 2
                draw.text((x, y_pos), text, fill=color, align='center')
        else:
            x = (width - len(text) * 15) // 2
            draw.text((x, y_pos), text, fill=color, align='center')
        y_pos += 80
    
    return bg_image

def get_video_download_link(video_buffer, filename):
    """ç”Ÿæˆè§†é¢‘ä¸‹è½½é“¾æ¥"""
    video_buffer.seek(0)
    b64 = base64.b64encode(video_buffer.read()).decode()
    href = f'<a href="data:video/mp4;base64,{b64}" download="{filename}" style="background-color: #4CAF50; color: white; padding: 14px 20px; text-align: center; text-decoration: none; display: inline-block; border-radius: 5px; font-size: 16px; margin: 10px;">ğŸ“¥ ä¸‹è½½MP4è§†é¢‘æ–‡ä»¶</a>'
    return href

def hex_to_rgb(hex_color):
    """å°†åå…­è¿›åˆ¶é¢œè‰²è½¬æ¢ä¸ºRGB"""
    hex_color = hex_color.lstrip('#')
    return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))

if uploaded_file is not None:
    try:
        df = pd.read_excel(uploaded_file)
        
        required_columns = ['è‹±è¯­', 'ä¸­æ–‡', 'éŸ³æ ‡']
        if all(col in df.columns for col in required_columns):
            st.success(f"âœ… æ–‡ä»¶éªŒè¯æˆåŠŸï¼å…±æ‰¾åˆ° {len(df)} æ¡å¥å­")
            
            st.subheader("ğŸ“Š æ•°æ®é¢„è§ˆ")
            st.dataframe(df.head(10), use_container_width=True)
            
            # è§†é¢‘è®¾ç½®
            st.header("âš™ï¸ ç¬¬äºŒæ­¥ï¼šè§†é¢‘è®¾ç½®")
            
            # åŸºç¡€è®¾ç½®
            col1, col2 = st.columns(2)
            
            with col1:
                video_title = st.text_input("è§†é¢‘æ ‡é¢˜", "æ—…æ¸¸è‹±è¯­å­¦ä¹ è§†é¢‘")
                resolution_option = st.selectbox("åˆ†è¾¨ç‡", ["720p (1280x720)", "1080p (1920x1080)"])
                fps = st.selectbox("å¸§ç‡", [24, 30], index=0)
                duration_per_sentence = st.slider("æ¯å¥æ˜¾ç¤ºæ—¶é—´(ç§’)", 3, 10, 5)
                
            with col2:
                background_type = st.radio("èƒŒæ™¯ç±»å‹", ["çº¯è‰²èƒŒæ™¯", "å›¾ç‰‡èƒŒæ™¯"])
                font_family = st.selectbox("å­—ä½“", list(get_available_fonts().keys()))
            
            # èƒŒæ™¯è®¾ç½®
            if background_type == "çº¯è‰²èƒŒæ™¯":
                bg_color = st.color_picker("èƒŒæ™¯é¢œè‰²", "#000000")
                bg_color_rgb = hex_to_rgb(bg_color)
                background_image = None
            else:
                bg_upload = st.file_uploader("ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡", type=['jpg', 'jpeg', 'png'])
                if bg_upload:
                    st.session_state.background_image = bg_upload
                    st.image(bg_upload, caption="èƒŒæ™¯å›¾ç‰‡é¢„è§ˆ", width=300)
                    bg_color_rgb = (0, 0, 0)  # å›¾ç‰‡èƒŒæ™¯æ—¶ä½¿ç”¨é»‘è‰²ä½œä¸ºfallback
                else:
                    st.warning("è¯·ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡")
                    bg_color_rgb = (0, 0, 0)
            
            # æ–‡å­—æ ·å¼è®¾ç½®
            st.subheader("ğŸ¨ æ–‡å­—æ ·å¼è®¾ç½®")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("**è‹±è¯­è®¾ç½®**")
                english_color = st.color_picker("è‹±è¯­é¢œè‰²", "#FFFFFF", key="english")
                english_size = st.slider("è‹±è¯­å­—å·", 30, 100, 60, key="english_size")
                
            with col2:
                st.markdown("**ä¸­æ–‡è®¾ç½®**")
                chinese_color = st.color_picker("ä¸­æ–‡é¢œè‰²", "#00FFFF", key="chinese")
                chinese_size = st.slider("ä¸­æ–‡å­—å·", 20, 80, 45, key="chinese_size")
                
            with col3:
                st.markdown("**éŸ³æ ‡è®¾ç½®**")
                phonetic_color = st.color_picker("éŸ³æ ‡é¢œè‰²", "#FFFF00", key="phonetic")
                phonetic_size = st.slider("éŸ³æ ‡å­—å·", 20, 60, 35, key="phonetic_size")
            
            # è§†é¢‘é¢„è§ˆ
            st.subheader("ğŸ¥ å®æ—¶é¢„è§ˆ")
            if len(df) > 0:
                preview_col1, preview_col2 = st.columns(2)
                
                with preview_col1:
                    # åˆ›å»ºé¢„è§ˆå¸§
                    preview_frame = create_video_frame(
                        str(df.iloc[0]['è‹±è¯­']), 
                        str(df.iloc[0]['ä¸­æ–‡']), 
                        str(df.iloc[0]['éŸ³æ ‡']),
                        width=600, height=400,  # è¾ƒå°çš„é¢„è§ˆå°ºå¯¸
                        bg_color=bg_color_rgb,
                        bg_image=Image.open(st.session_state.background_image).convert('RGB') if st.session_state.background_image else None,
                        english_color=hex_to_rgb(english_color),
                        chinese_color=hex_to_rgb(chinese_color),
                        phonetic_color=hex_to_rgb(phonetic_color),
                        english_size=english_size,
                        chinese_size=chinese_size,
                        phonetic_size=phonetic_size,
                        font_family=font_family
                    )
                    st.image(preview_frame, caption="å®æ—¶é¢„è§ˆ - ç¬¬ä¸€å¥", use_column_width=True)
                
                with preview_col2:
                    st.info("""
                    **é¢„è§ˆè¯´æ˜ï¼š**
                    - å·¦ä¾§æ˜¾ç¤ºå½“å‰è®¾ç½®çš„æ•ˆæœ
                    - ä¸­æ–‡å’ŒéŸ³æ ‡åº”è¯¥æ­£å¸¸æ˜¾ç¤º
                    - é¢œè‰²å’Œå¤§å°å¯å®æ—¶è°ƒæ•´
                    - èƒŒæ™¯å›¾ç‰‡ä¼šæŒ‰æ¯”ä¾‹ç¼©æ”¾
                    """)
            
            # ç”Ÿæˆè®¾ç½®
            resolution_map = {
                "720p (1280x720)": (1280, 720),
                "1080p (1920x1080)": (1920, 1080)
            }
            
            settings = {
                'resolution': resolution_map[resolution_option],
                'fps': fps,
                'duration_per_sentence': duration_per_sentence,
                'background_type': 'color' if background_type == "çº¯è‰²èƒŒæ™¯" else 'image',
                'bg_color': bg_color_rgb,
                'english_color': hex_to_rgb(english_color),
                'chinese_color': hex_to_rgb(chinese_color),
                'phonetic_color': hex_to_rgb(phonetic_color),
                'english_size': english_size,
                'chinese_size': chinese_size,
                'phonetic_size': phonetic_size,
                'font_family': font_family
            }
            
            # ç”ŸæˆæŒ‰é’®
            st.header("ğŸ¬ ç¬¬ä¸‰æ­¥ï¼šç”ŸæˆMP4è§†é¢‘")
            
            if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆè§†é¢‘", type="primary", use_container_width=True):
                progress_bar = st.progress(0)
                status_text = st.empty()
                time_estimate = st.empty()
                
                total_frames = len(df) * duration_per_sentence * fps + 3 * fps
                estimated_time = total_frames / fps
                
                st.info(f"""
                **è§†é¢‘è§„æ ¼ï¼š**
                - æ€»æ—¶é•¿: {estimated_time:.1f}ç§’
                - åˆ†è¾¨ç‡: {resolution_option}
                - å¸§ç‡: {fps}fps
                - å¥å­æ•°é‡: {len(df)}å¥
                - èƒŒæ™¯ç±»å‹: {background_type}
                """)
                
                try:
                    video_buffer = BytesIO()
                    progress_generator = generate_video_from_dataframe(df, video_title, settings)
                    
                    start_time = time.time()
                    for progress in progress_generator:
                        progress_bar.progress(progress)
                        elapsed = time.time() - start_time
                        if progress > 0:
                            total_estimated = elapsed / progress
                            remaining = total_estimated - elapsed
                            status_text.text(f"ç”Ÿæˆè¿›åº¦: {progress*100:.1f}%")
                            time_estimate.text(f"é¢„è®¡å‰©ä½™: {remaining:.0f}ç§’")
                    
                    st.balloons()
                    st.success("ğŸ‰ MP4è§†é¢‘ç”Ÿæˆå®Œæˆï¼")
                    
                    filename = f"{video_title}.mp4"
                    download_link = get_video_download_link(video_buffer, filename)
                    
                    st.markdown(download_link, unsafe_allow_html=True)
                    
                    # è§†é¢‘ä¿¡æ¯
                    st.subheader("ğŸ“Š ç”Ÿæˆæ€»ç»“")
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("è§†é¢‘æ—¶é•¿", f"{estimated_time:.1f}ç§’")
                    with col2:
                        st.metric("æ–‡ä»¶å¤§å°", f"{len(video_buffer.getvalue()) / (1024*1024):.1f}MB")
                    with col3:
                        st.metric("åˆ†è¾¨ç‡", resolution_option.split(' ')[0])
                    with col4:
                        st.metric("å¸§ç‡", f"{fps}fps")
                    
                except Exception as e:
                    st.error(f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
                    st.info("""
                    **æ•…éšœæ’é™¤å»ºè®®ï¼š**
                    1. å‡å°‘å¥å­æ•°é‡ï¼ˆå»ºè®®10-20å¥ï¼‰
                    2. ä½¿ç”¨çº¯è‰²èƒŒæ™¯å‡å°‘å†…å­˜ä½¿ç”¨
                    3. é™ä½åˆ†è¾¨ç‡åˆ°720p
                    4. æ£€æŸ¥èƒŒæ™¯å›¾ç‰‡æ ¼å¼
                    """)
                    
        else:
            st.error("âŒ Excelæ–‡ä»¶å¿…é¡»åŒ…å«'è‹±è¯­','ä¸­æ–‡','éŸ³æ ‡'ä¸‰åˆ—")
            
    except Exception as e:
        st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")

else:
    # æä¾›ç¤ºä¾‹æ–‡ä»¶ä¸‹è½½
    st.header("ğŸ“ ç¤ºä¾‹æ–‡ä»¶")
    
    example_data = {
        'è‹±è¯­': ['Where is the gate?', 'Window seat, please.'],
        'ä¸­æ–‡': ['ç™»æœºå£åœ¨å“ªï¼Ÿ', 'è¯·ç»™æˆ‘é çª—åº§ä½ã€‚'],
        'éŸ³æ ‡': ['/weÉ™ Éªz Ã°É™ É¡eÉªt/', '/ËˆwÉªndÉ™ÊŠ siËt pliËz/']
    }
    example_df = pd.DataFrame(example_data)
    
    st.write("**ç¤ºä¾‹æ•°æ®æ ¼å¼**:")
    st.dataframe(example_df, use_container_width=True)
    
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        example_df.to_excel(writer, index=False, sheet_name='æ—…æ¸¸è‹±è¯­')
    excel_data = output.getvalue()
    
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½ç¤ºä¾‹Excelæ¨¡æ¿",
        data=excel_data,
        file_name="æ—…æ¸¸è‹±è¯­æ¨¡æ¿.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        use_container_width=True
    )

# ä½¿ç”¨è¯´æ˜
with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜å’ŒæŠ€å·§"):
    st.markdown("""
    ## ä½¿ç”¨æŒ‡å—
    
    ### è§£å†³ä¸­æ–‡ä¹±ç é—®é¢˜
    1. **é€‰æ‹©åˆé€‚å­—ä½“**ï¼šå°è¯•ä¸åŒçš„å­—ä½“é€‰é¡¹
    2. **è°ƒæ•´å­—å·**ï¼šé€‚å½“å¢å¤§ä¸­æ–‡å­—å·
    3. **ä½¿ç”¨çº¯è‰²èƒŒæ™¯**ï¼šå‡å°‘æ¸²æŸ“å¤æ‚åº¦
    
    ### è‡ªå®šä¹‰é€‰é¡¹è¯´æ˜
    - **èƒŒæ™¯å›¾ç‰‡**ï¼šæ”¯æŒJPGã€PNGæ ¼å¼ï¼Œä¼šè‡ªåŠ¨ç¼©æ”¾
    - **å­—ä½“é€‰æ‹©**ï¼šä¸åŒå­—ä½“å¯¹ä¸­æ–‡æ”¯æŒä¸åŒ
    - **é¢œè‰²è®¾ç½®**ï¼šå¯åˆ†åˆ«è®¾ç½®è‹±æ–‡ã€ä¸­æ–‡ã€éŸ³æ ‡é¢œè‰²
    - **å­—å·è°ƒæ•´**ï¼šæ ¹æ®å¥å­é•¿åº¦è°ƒæ•´åˆé€‚å­—å·
    
    ### æ€§èƒ½ä¼˜åŒ–å»ºè®®
    - å¥å­æ•°é‡ï¼š10-20å¥æœ€ä½³
    - åˆ†è¾¨ç‡ï¼š720på¤„ç†æ›´å¿«
    - èƒŒæ™¯ï¼šçº¯è‰²èƒŒæ™¯æ¯”å›¾ç‰‡èƒŒæ™¯æ›´å¿«
    """)

# é¡µè„š
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>ğŸ¬ æ—…æ¸¸è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨ â€¢ ğŸ¨ å®Œå…¨è‡ªå®šä¹‰ â€¢ ğŸ”¤ ä¸­æ–‡æ”¯æŒ</p>
</div>
""", unsafe_allow_html=True)
