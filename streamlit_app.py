import streamlit as st
import pandas as pd
import os
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import imageio.v2 as imageio
import tempfile
import shutil
from gtts import gTTS
from pydub import AudioSegment
import subprocess
import traceback
import gc
import ffmpeg  # æ³¨æ„ï¼šæ­¤å¤„å¯¼å…¥çš„æ˜¯ffmpeg-pythonåº“

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ—…æ¸¸è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨",
    page_icon="ğŸ¬",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'bg_image' not in st.session_state:
    st.session_state.bg_image = None
if 'audio_available' not in st.session_state:
    st.session_state.audio_available = True  # æ ‡è®°éŸ³é¢‘åŠŸèƒ½æ˜¯å¦å¯ç”¨

# --------------------------
# æ ¸å¿ƒåŠŸèƒ½å‡½æ•°
# --------------------------
def check_ffmpeg():
    """æ£€æŸ¥ç³»ç»Ÿffmpegæ˜¯å¦å¯ç”¨"""
    return shutil.which('ffmpeg') is not None

def wrap_text(text, max_chars):
    """æ–‡æœ¬è‡ªåŠ¨æ¢è¡Œå¤„ç†"""
    if not text or str(text).strip().lower() == 'nan':
        return [""]
    
    text = str(text).strip()
    # ä¸­æ–‡é€‚é…ï¼šå‡å°‘æ¯è¡Œå­—ç¬¦æ•°
    if any('\u4e00' <= c <= '\u9fff' for c in text):
        max_chars = min(max_chars, 15)
    
    words = text.split()
    lines, current = [], []
    for word in words:
        test_line = ' '.join(current + [word])
        if len(test_line) <= max_chars:
            current.append(word)
        else:
            if current:
                lines.append(' '.join(current))
            # å¤„ç†è¶…é•¿å•è¯
            if len(word) > max_chars:
                for i in range(0, len(word), max_chars):
                    lines.append(word[i:i+max_chars])
                current = []
            else:
                current = [word]
    if current:
        lines.append(' '.join(current))
    return lines

def get_font(size):
    """ä¼˜å…ˆåŠ è½½é¡¹ç›®å†…çš„ä¸­æ–‡å­—ä½“ï¼Œè§£å†³éƒ¨ç½²ç¯å¢ƒå­—ä½“ç¼ºå¤±é—®é¢˜"""
    try:
        # å°è¯•åŠ è½½é¡¹ç›®å†…çš„SimHeiå­—ä½“
        font_path = os.path.join(os.path.dirname(__file__), "fonts", "SimHei.ttf")
        return ImageFont.truetype(font_path, size)
    except:
        # å›é€€åˆ°ç³»ç»Ÿå­—ä½“
        font_candidates = ["WenQuanYi Micro Hei", "Heiti TC", "Arial Unicode MS"]
        for font_name in font_candidates:
            try:
                return ImageFont.truetype(font_name, size)
            except:
                continue
        st.warning("æœªæ‰¾åˆ°åˆé€‚çš„ä¸­æ–‡å­—ä½“ï¼Œä¸­æ–‡å¯èƒ½æ˜¾ç¤ºå¼‚å¸¸")
        return ImageFont.load_default()

def create_frame(english, chinese, phonetic, width=1280, height=720, 
                bg_color=(0,0,0), bg_image=None,
                eng_color=(255,255,255), chn_color=(0,255,255), pho_color=(255,255,0),
                eng_size=60, chn_size=50, pho_size=40):
    """åˆ›å»ºå•å¸§å›¾åƒï¼ˆæ–‡å­—å±…ä¸­æ˜¾ç¤ºï¼‰"""
    # åˆ›å»ºèƒŒæ™¯
    if bg_image:
        try:
            img = bg_image.resize((width, height), Image.Resampling.LANCZOS).convert('RGB')
        except:
            img = Image.new('RGB', (width, height), bg_color)
    else:
        img = Image.new('RGB', (width, height), bg_color)
    
    draw = ImageDraw.Draw(img)
    # è·å–å­—ä½“ï¼ˆæ˜ç¡®ä¼ é€’å­—å·ï¼‰
    eng_font = get_font(eng_size)
    chn_font = get_font(chn_size)
    pho_font = get_font(pho_size)
    
    # æ–‡æœ¬æ¢è¡Œå¤„ç†
    eng_lines = wrap_text(english, 30)
    chn_lines = wrap_text(chinese, 15)
    pho_lines = wrap_text(phonetic, 35) if phonetic else []
    
    # è®¡ç®—æ–‡æœ¬æ€»é«˜åº¦ï¼ˆå«é—´è·ï¼‰
    line_spacing = 10
    total_height = 0
    # è‹±è¯­æ–‡æœ¬é«˜åº¦
    for line in eng_lines:
        _, _, _, h = draw.textbbox((0,0), line, font=eng_font)
        total_height += h
    total_height += line_spacing * (len(eng_lines) - 1)
    # ä¸­æ–‡æ–‡æœ¬é«˜åº¦ï¼ˆåŠ æ®µè½é—´è·ï¼‰
    if chn_lines:
        total_height += 20  # æ®µè½é—´è·
        for line in chn_lines:
            _, _, _, h = draw.textbbox((0,0), line, font=chn_font)
            total_height += h
        total_height += line_spacing * (len(chn_lines) - 1)
    # éŸ³æ ‡æ–‡æœ¬é«˜åº¦ï¼ˆåŠ æ®µè½é—´è·ï¼‰
    if pho_lines:
        total_height += 15  # æ®µè½é—´è·
        for line in pho_lines:
            _, _, _, h = draw.textbbox((0,0), line, font=pho_font)
            total_height += h
        total_height += line_spacing * (len(pho_lines) - 1)
    
    # è®¡ç®—èµ·å§‹Yåæ ‡ï¼ˆå‚ç›´å±…ä¸­ï¼‰
    y = (height - total_height) // 2
    
    # ç»˜åˆ¶è‹±è¯­
    for line in eng_lines:
        w, h = draw.textbbox((0,0), line, font=eng_font)[2:]
        x = (width - w) // 2
        # æ–‡æœ¬é˜´å½±ï¼ˆå¢å¼ºå¯è¯»æ€§ï¼‰
        draw.text((x+1, y+1), line, font=eng_font, fill=(0,0,0,128))
        draw.text((x, y), line, font=eng_font, fill=eng_color)
        y += h + line_spacing
    
    # ç»˜åˆ¶ä¸­æ–‡
    if chn_lines:
        y += 10  # æ®µè½é—´è·
        for line in chn_lines:
            w, h = draw.textbbox((0,0), line, font=chn_font)[2:]
            x = (width - w) // 2
            draw.text((x+1, y+1), line, font=chn_font, fill=(0,0,0,128))
            draw.text((x, y), line, font=chn_font, fill=chn_color)
            y += h + line_spacing
    
    # ç»˜åˆ¶éŸ³æ ‡
    if pho_lines:
        y += 5  # æ®µè½é—´è·
        for line in pho_lines:
            w, h = draw.textbbox((0,0), line, font=pho_font)[2:]
            x = (width - w) // 2
            draw.text((x+1, y+1), line, font=pho_font, fill=(0,0,0,128))
            draw.text((x, y), line, font=pho_font, fill=pho_color)
            y += h + line_spacing
    
    return img

def generate_audio(text, lang='en', speed=1.0):
    """ç”ŸæˆTTSéŸ³é¢‘"""
    try:
        tts = gTTS(text=text, lang=lang, slow=speed < 0.9)
        with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as f:
            tts.save(f.name)
            return f.name
    except Exception as e:
        st.error(f"éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")
        st.session_state.audio_available = False
        return None

def merge_audio_files(audio_paths, target_duration):
    """åˆå¹¶éŸ³é¢‘å¹¶åŒ¹é…è§†é¢‘æ—¶é•¿"""
    combined = AudioSegment.empty()
    for path in audio_paths:
        if not path:
            continue
        try:
            audio = AudioSegment.from_mp3(path)
            # ç¡®ä¿éŸ³é¢‘æ—¶é•¿ä¸è§†é¢‘å¸§æ—¶é•¿ä¸€è‡´
            if len(audio) > target_duration * 1000:  # è½¬æ¢ä¸ºæ¯«ç§’
                audio = audio[:int(target_duration * 1000)]
            else:
                # ä¸è¶³æ—¶è¡¥é™éŸ³
                silence = AudioSegment.silent(duration=int(target_duration * 1000) - len(audio))
                audio += silence
            combined += audio
            os.remove(path)  # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        except Exception as e:
            st.warning(f"éŸ³é¢‘ç‰‡æ®µå¤„ç†å¤±è´¥: {str(e)}")
    return combined

def merge_video_audio(video_path, audio_path, output_path):
    """ç”¨ffmpegåˆå¹¶éŸ³è§†é¢‘ï¼ˆé€‚é…æ—§ç‰ˆffmpeg-python APIï¼‰"""
    try:
        # åˆ†åˆ«åˆ›å»ºè¾“å…¥æµååˆå¹¶
        video = ffmpeg.input(video_path)
        audio = ffmpeg.input(audio_path)
        ffmpeg.output(video, audio, output_path, vcodec='copy', acodec='aac', strict='experimental').run(overwrite_output=True)
        return output_path
    except ffmpeg.Error as e:
        st.error(f"éŸ³è§†é¢‘åˆå¹¶å¤±è´¥: {e.stderr.decode()}")
        return None

# --------------------------
# é¡µé¢UIä¸é€»è¾‘
# --------------------------
st.title("ğŸ¬ æ—…æ¸¸è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨")
st.markdown("ç”ŸæˆåŒ…å«è‹±è¯­å¥å­ã€ä¸­æ–‡ç¿»è¯‘å’ŒéŸ³æ ‡çš„å¸¦éŸ³é¢‘è§†é¢‘")

# æ£€æŸ¥ffmpegçŠ¶æ€
if not check_ffmpeg():
    st.warning("âš ï¸ æœªæ£€æµ‹åˆ°ç³»ç»Ÿffmpegï¼ŒéŸ³é¢‘åŠŸèƒ½å¯èƒ½æ— æ³•ä½¿ç”¨ï¼ˆéœ€å®‰è£…ffmpegæ”¯æŒï¼‰")

# 1. æ–‡ä»¶ä¸Šä¼ 
st.header("1. ä¸Šä¼ Excelæ–‡ä»¶")
uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=['xlsx', 'xls'])

if uploaded_file:
    try:
        df = pd.read_excel(uploaded_file)
        required_cols = ['è‹±è¯­', 'ä¸­æ–‡', 'éŸ³æ ‡']
        missing = [c for c in required_cols if c not in df.columns]
        
        if missing:
            st.error(f"Excelç¼ºå°‘å¿…è¦åˆ—: {', '.join(missing)}")
        else:
            # é™åˆ¶æ•°æ®é‡ï¼Œé¿å…å†…å­˜æº¢å‡º
            if len(df) > 30:
                st.warning("Excelè¡Œæ•°è¶…è¿‡30è¡Œï¼Œå¯èƒ½å¯¼è‡´å†…å­˜æº¢å‡ºï¼Œè¯·æ‹†åˆ†æ–‡ä»¶åé‡è¯•")
                uploaded_file = None
            else:
                st.success("æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
                st.dataframe(df, height=200)
                
                # 2. è‡ªå®šä¹‰è®¾ç½®
                st.header("2. è‡ªå®šä¹‰è®¾ç½®")
                
                # èƒŒæ™¯è®¾ç½®
                bg_type = st.radio("èƒŒæ™¯ç±»å‹", ["çº¯è‰²", "å›¾ç‰‡"])
                bg_color = (0,0,0)
                if bg_type == "çº¯è‰²":
                    bg_hex = st.color_picker("èƒŒæ™¯é¢œè‰²", "#000000")
                    bg_color = tuple(int(bg_hex[i:i+2], 16) for i in (1,3,5))
                    st.session_state.bg_image = None
                else:
                    bg_file = st.file_uploader("ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡", type=['jpg','jpeg','png'])
                    if bg_file:
                        try:
                            st.session_state.bg_image = Image.open(bg_file)
                            st.image(st.session_state.bg_image, caption="èƒŒæ™¯é¢„è§ˆ", width=300)
                        except Exception as e:
                            st.error(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}")
                            st.session_state.bg_image = None
                
                # æ–‡å­—è®¾ç½®
                st.subheader("æ–‡å­—æ ·å¼")
                col1, col2, col3 = st.columns(3)
                with col1:
                    eng_color = st.color_picker("è‹±è¯­é¢œè‰²", "#FFFFFF")
                    eng_color = tuple(int(eng_color[i:i+2], 16) for i in (1,3,5))
                    eng_size = st.slider("è‹±è¯­å­—å·", 20, 100, 60)
                with col2:
                    chn_color = st.color_picker("ä¸­æ–‡é¢œè‰²", "#00FFFF")
                    chn_color = tuple(int(chn_color[i:i+2], 16) for i in (1,3,5))
                    chn_size = st.slider("ä¸­æ–‡å­—å·", 20, 100, 50)
                with col3:
                    pho_color = st.color_picker("éŸ³æ ‡é¢œè‰²", "#FFFF00")
                    pho_color = tuple(int(pho_color[i:i+2], 16) for i in (1,3,5))
                    pho_size = st.slider("éŸ³æ ‡å­—å·", 16, 80, 40)
                
                # è§†é¢‘ä¸éŸ³é¢‘è®¾ç½®
                st.subheader("è§†é¢‘ä¸éŸ³é¢‘")
                col4, col5 = st.columns(2)
                with col4:
                    duration = st.slider("æ¯å¥æ˜¾ç¤ºæ—¶é—´(ç§’)", 2, 10, 5)
                    fps = st.slider("å¸§ç‡", 10, 30, 24)
                    resolution = st.selectbox("è§†é¢‘åˆ†è¾¨ç‡", ["1280x720 (HD)", "1920x1080 (FHD)"])
                    res_num = resolution.split(' ')[0]
                    width, height = map(int, res_num.split('x'))
                with col5:
                    tts_lang = st.selectbox("è¯­éŸ³è¯­è¨€", ["è‹±è¯­", "ä¸­æ–‡"])
                    tts_speed = st.slider("è¯­éŸ³é€Ÿåº¦", 0.5, 2.0, 1.0)
                    tts_lang_code = "en" if tts_lang == "è‹±è¯­" else "zh-CN"
                
                # 3. é¢„è§ˆ
                st.header("3. é¢„è§ˆæ•ˆæœ")
                if not df.empty:
                    preview_idx = st.slider("é€‰æ‹©é¢„è§ˆè¡Œ", 0, len(df)-1, 0)
                    row = df.iloc[preview_idx]
                    preview_img = create_frame(
                        english=str(row['è‹±è¯­']),
                        chinese=str(row['ä¸­æ–‡']),
                        phonetic=str(row['éŸ³æ ‡']) if pd.notna(row['éŸ³æ ‡']) else "",
                        width=width,
                        height=height,
                        bg_color=bg_color,
                        bg_image=st.session_state.bg_image,
                        eng_color=eng_color,
                        chn_color=chn_color,
                        pho_color=pho_color,
                        eng_size=eng_size,
                        chn_size=chn_size,
                        pho_size=pho_size
                    )
                    st.image(preview_img, caption="å¸§é¢„è§ˆ")
                
                # 4. ç”Ÿæˆè§†é¢‘
                st.header("4. ç”Ÿæˆè§†é¢‘")
                if st.button("å¼€å§‹ç”Ÿæˆ", type="primary"):
                    with st.spinner("æ­£åœ¨ç”Ÿæˆè§†é¢‘..."):
                        try:
                            with tempfile.TemporaryDirectory() as temp_dir:
                                # ç”Ÿæˆè§†é¢‘å¸§ï¼ˆæµå¼å†™å…¥ï¼Œé¿å…å†…å­˜æº¢å‡ºï¼‰
                                audio_paths = []
                                total_frames = len(df) * duration * fps
                                progress = st.progress(0)
                                current = 0
                                
                                video_path = os.path.join(temp_dir, "video_no_audio.mp4")
                                with imageio.get_writer(video_path, fps=fps) as writer:
                                    for idx, row in df.iterrows():
                                        # ç”Ÿæˆå•å¸§
                                        frame = create_frame(
                                            english=str(row['è‹±è¯­']),
                                            chinese=str(row['ä¸­æ–‡']),
                                            phonetic=str(row['éŸ³æ ‡']) if pd.notna(row['éŸ³æ ‡']) else "",
                                            width=width,
                                            height=height,
                                            bg_color=bg_color,
                                            bg_image=st.session_state.bg_image,
                                            eng_color=eng_color,
                                            chn_color=chn_color,
                                            pho_color=pho_color,
                                            eng_size=eng_size,
                                            chn_size=chn_size,
                                            pho_size=pho_size
                                        )
                                        # ç›´æ¥å†™å…¥å¸§ï¼Œä¸ç¼“å­˜åˆ°åˆ—è¡¨
                                        writer.append_data(np.array(frame.convert('RGB')))
                                        # æ›´æ–°è¿›åº¦
                                        current += 1
                                        progress.progress(min(current / total_frames, 1.0))
                                        
                                        # ç”Ÿæˆå¯¹åº”éŸ³é¢‘
                                        if st.session_state.audio_available:
                                            audio_path = generate_audio(
                                                text=str(row['è‹±è¯­']),
                                                lang=tts_lang_code,
                                                speed=tts_speed
                                            )
                                            audio_paths.append(audio_path)
                                
                                # å¤„ç†éŸ³é¢‘
                                final_video_path = video_path  # é»˜è®¤æ— éŸ³é¢‘
                                if st.session_state.audio_available and audio_paths:
                                    # åˆå¹¶éŸ³é¢‘
                                    combined_audio = merge_audio_files(audio_paths, duration)
                                    audio_path = os.path.join(temp_dir, "combined_audio.mp3")
                                    combined_audio.export(audio_path, format="mp3")
                                    
                                    # åˆå¹¶éŸ³è§†é¢‘
                                    final_video_path = os.path.join(temp_dir, "video_with_audio.mp4")
                                    if not merge_video_audio(video_path, audio_path, final_video_path):
                                        final_video_path = video_path  # åˆå¹¶å¤±è´¥åˆ™ä½¿ç”¨æ— éŸ³é¢‘ç‰ˆæœ¬
                                
                                # æä¾›ä¸‹è½½
                                with open(final_video_path, "rb") as f:
                                    video_bytes = f.read()
                                
                                st.success("è§†é¢‘ç”Ÿæˆå®Œæˆï¼")
                                st.video(video_bytes)
                                st.download_button(
                                    "ä¸‹è½½è§†é¢‘",
                                    data=video_bytes,
                                    file_name="travel_english_video.mp4",
                                    mime="video/mp4"
                                )
                                progress.progress(1.0)
                                
                        except Exception as e:
                            st.error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
                            st.text(traceback.format_exc())  # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
                        finally:
                            gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
                            # æ¸…ç†ä¸´æ—¶èµ„æºï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
                            if 'temp_dir' in locals():
                                shutil.rmtree(temp_dir, ignore_errors=True)
    
    except Exception as e:
        st.error(f"æ–‡ä»¶å¤„ç†é”™è¯¯: {str(e)}")
else:
    st.info("è¯·å…ˆä¸Šä¼ åŒ…å«'è‹±è¯­'ã€'ä¸­æ–‡'ã€'éŸ³æ ‡'ä¸‰åˆ—çš„Excelæ–‡ä»¶")
