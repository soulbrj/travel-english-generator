# ---------- åŸºæœ¬å¯¼å…¥ ----------
import os
import sys
import io
import json
import time
import math
import shutil
import hashlib
import tempfile
import asyncio
import traceback
import subprocess
from queue import Queue
from threading import Thread
from typing import List, Dict, Tuple, Optional
import concurrent.futures

import streamlit as st
import pandas as pd
import numpy as np
from PIL import Image, ImageDraw, ImageFont, ImageOps, ImageColor

# imageio import (video writing later)
import imageio.v2 as imageio

# ---------- é…ç½® & å¸¸é‡ ----------
LIGHTWEIGHT_MODE = False  # True -> æ›´è½»é‡, ç¦ç”¨é˜Ÿåˆ—/æ¨¡æ¿/è¿›åº¦

# å…¼å®¹ Streamlit Cloud çš„ä¸´æ—¶ç›®å½•å¤„ç†
if 'STREAMLIT_SHARING_MODE' in os.environ or 'STREAMLIT_SERVER_HEADLESS' in os.environ:
    APP_TMP = os.path.join(tempfile.gettempdir(), "travel_english_tts_app")
else:
    APP_TMP = os.path.join(tempfile.gettempdir(), "travel_english_tts_app")

CACHE_DIR = os.path.join(APP_TMP, "cache")
SAMPLES_DIR = os.path.join(APP_TMP, "samples")
TEMPLATE_DIR = os.path.join(APP_TMP, "templates")
PROGRESS_FILE = os.path.join(APP_TMP, "learning_progress.json")

for p in (APP_TMP, CACHE_DIR, SAMPLES_DIR, TEMPLATE_DIR):
    os.makedirs(p, exist_ok=True)

# ---------- å¯é€‰ä¾èµ–æ£€æµ‹ ----------
try:
    import pyttsx3
    PYTTSX3_AVAILABLE = True
except Exception:
    PYTTSX3_AVAILABLE = False

try:
    import edge_tts
    EDGE_TTS_AVAILABLE = True
except Exception:
    EDGE_TTS_AVAILABLE = False

try:
    from pydub import AudioSegment
    PYDUB_AVAILABLE = True
except Exception:
    PYDUB_AVAILABLE = False

# ---------- è·¨å¹³å° FFmpeg æ£€æµ‹å‡½æ•° ----------
def find_ffmpeg_path():
    """è·¨å¹³å°æŸ¥æ‰¾ ffmpeg è·¯å¾„"""
    ffmpeg_path = shutil.which("ffmpeg")
    if ffmpeg_path:
        return ffmpeg_path
    
    possible_paths = []
    if sys.platform.startswith("win"):
        possible_paths = [
            r"C:\ffmpeg\bin\ffmpeg.exe",
            r"C:\Program Files\ffmpeg\bin\ffmpeg.exe",
        ]
    elif sys.platform.startswith("darwin"):
        possible_paths = [
            "/usr/local/bin/ffmpeg",
            "/opt/homebrew/bin/ffmpeg",
        ]
    else:
        possible_paths = [
            "/usr/bin/ffmpeg",
            "/usr/local/bin/ffmpeg",
        ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return path
    
    try:
        import imageio_ffmpeg as iioff
        ffexe = iioff.get_ffmpeg_exe()
        if ffexe and os.path.exists(ffexe):
            return ffexe
    except Exception:
        pass
    
    return None

def ffmpeg_available() -> bool:
    return find_ffmpeg_path() is not None

def run_ffmpeg_command(cmd):
    """è·¨å¹³å°è¿è¡Œ ffmpeg å‘½ä»¤"""
    ffmpeg_path = find_ffmpeg_path()
    if not ffmpeg_path:
        raise RuntimeError("FFmpeg not found")
    
    if cmd[0] == "ffmpeg":
        cmd[0] = ffmpeg_path
    
    env = os.environ.copy()
    
    try:
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, 
                              timeout=300, check=True, env=env)
        return True
    except subprocess.TimeoutExpired:
        raise RuntimeError("FFmpeg command timed out")
    except subprocess.CalledProcessError as e:
        error_msg = e.stderr.decode('utf-8', errors='ignore') if e.stderr else str(e)
        raise RuntimeError(f"FFmpeg command failed: {error_msg}")
    except Exception as e:
        raise RuntimeError(f"FFmpeg execution error: {str(e)}")

# ---------- é«˜çº§UI theme & CSS ----------
PRIMARY_LIGHT = "#f8faff"
SECONDARY_LIGHT = "#f0f4ff"
ACCENT_PRIMARY = "#7c3aed"
ACCENT_SECONDARY = "#4f46e5"
ACCENT_GRADIENT_START = "#8b5cf6"
ACCENT_GRADIENT_END = "#6366f1"
SUCCESS_COLOR = "#10b981"
WARNING_COLOR = "#f59e0b"
ERROR_COLOR = "#ef4444"
CARD_BG = "rgba(255, 255, 255, 0.85)"
TEXT_DARK = "#1e293b"
TEXT_MUTED = "#64748b"
BORDER_COLOR = "rgba(99, 102, 241, 0.2)"

st.set_page_config(
    page_title="ğŸ¬ è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨ - ä¸“ä¸šçº§å¤šéŸ³è‰²æ•™å­¦è§†é¢‘åˆ¶ä½œå¹³å°",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown(f"""
<style>
:root {{
  --primary-light: {PRIMARY_LIGHT};
  --secondary-light: {SECONDARY_LIGHT};
  --accent-primary: {ACCENT_PRIMARY};
  --accent-secondary: {ACCENT_SECONDARY};
  --gradient-start: {ACCENT_GRADIENT_START};
  --gradient-end: {ACCENT_GRADIENT_END};
  --text-dark: {TEXT_DARK};
  --text-muted: {TEXT_MUTED};
  --card-bg: {CARD_BG};
  --border-color: {BORDER_COLOR};
}}

.stApp {{
  background: linear-gradient(135deg, {PRIMARY_LIGHT} 0%, {SECONDARY_LIGHT} 100%) !important;
  color: {TEXT_DARK} !important;
}}

.main-title {{
  background: linear-gradient(135deg, var(--gradient-start), var(--gradient-end));
  color: white;
  padding: 24px 32px;
  border-radius: 20px;
  font-size: 28px;
  font-weight: 800;
  text-align: center;
  margin-bottom: 24px;
  box-shadow: 0 12px 40px rgba(99, 102, 241, 0.25);
}}

.navbar {{
  display: flex;
  gap: 12px;
  justify-content: center;
  padding: 16px 0;
  margin-bottom: 32px;
  background: rgba(255, 255, 255, 0.7);
  border-radius: 16px;
  border: 1px solid var(--border-color);
}}

.nav-btn {{
  padding: 12px 24px;
  border-radius: 12px;
  background: rgba(255, 255, 255, 0.9);
  color: {TEXT_DARK};
  cursor: pointer;
  font-weight: 600;
  font-size: 14px;
  transition: all 0.3s ease;
  border: 1px solid var(--border-color);
  box-shadow: 0 2px 8px rgba(99, 102, 241, 0.1);
  display: flex;
  align-items: center;
  gap: 8px;
}}

.nav-btn:hover {{
  background: white;
  transform: translateY(-2px);
  box-shadow: 0 6px 20px rgba(99, 102, 241, 0.2);
  border-color: var(--accent-primary);
}}

.card {{
  background: var(--card-bg);
  border-radius: 20px;
  padding: 24px;
  margin-bottom: 20px;
  border: 1px solid var(--border-color);
  box-shadow: 0 8px 32px rgba(99, 102, 241, 0.1);
  transition: all 0.3s ease;
}}

.card:hover {{
  box-shadow: 0 12px 40px rgba(99, 102, 241, 0.15);
  transform: translateY(-2px);
}}

.card-header {{
  font-size: 20px;
  font-weight: 700;
  margin-bottom: 20px;
  color: {TEXT_DARK};
  display: flex;
  align-items: center;
  gap: 12px;
  padding-bottom: 12px;
  border-bottom: 2px solid var(--border-color);
}}

div.stButton > button {{
  background: linear-gradient(135deg, var(--gradient-start), var(--gradient-end));
  color: white;
  border-radius: 12px;
  padding: 12px 24px;
  font-weight: 600;
  border: none;
  transition: all 0.3s ease;
  box-shadow: 0 4px 15px rgba(99, 102, 241, 0.3);
  font-size: 14px;
}}

div.stButton > button:hover {{
  transform: translateY(-2px);
  box-shadow: 0 8px 25px rgba(99, 102, 241, 0.4);
  background: linear-gradient(135deg, var(--gradient-end), var(--gradient-start));
}}

.footer {{
  text-align: center;
  padding: 24px;
  color: {TEXT_MUTED};
  margin-top: 40px;
  font-size: 14px;
  background: rgba(255, 255, 255, 0.7);
  border-radius: 16px;
  border: 1px solid var(--border-color);
}}

.voice-library {{
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
  gap: 16px;
  margin-top: 20px;
  max-height: 500px;
  overflow-y: auto;
  padding: 10px;
}}

.voice-card {{
  background: rgba(255, 255, 255, 0.9);
  border-radius: 16px;
  padding: 20px;
  border: 1px solid var(--border-color);
  transition: all 0.3s ease;
}}

.voice-card:hover {{
  border-color: var(--accent-primary);
  transform: translateY(-4px);
  box-shadow: 0 12px 32px rgba(99, 102, 241, 0.15);
  background: white;
}}

.voice-name {{
  font-weight: 700;
  color: {TEXT_DARK};
  margin-bottom: 8px;
  font-size: 16px;
}}

.voice-category {{
  font-size: 13px;
  color: {TEXT_MUTED};
  margin-bottom: 16px;
  font-weight: 500;
}}

.stProgress > div > div > div {{
  background: linear-gradient(90deg, var(--gradient-start), var(--gradient-end));
  border-radius: 8px;
}}

/* è‡ªå®šä¹‰Tabsæ ·å¼ */
.stTabs {{
  margin-top: 16px;
}}

.stTabs > div > div > div > div[data-baseweb="tab"][aria-selected="true"] {{
  background: transparent !important;
  color: var(--accent-primary) !important;
  border-bottom: 3px solid var(--accent-primary) !important;
  border-radius: 0 !important;
  box-shadow: none !important;
  font-weight: 700;
}}

.stTabs > div > div > div {{
  gap: 8px;
}}

.stTabs > div > div > div > div {{
  color: var(--text-dark);
  border-radius: 0;
  padding: 12px 20px;
  border: none;
  border-bottom: 2px solid transparent;
  background: transparent;
  transition: all 0.3s ease;
  font-weight: 500;
}}

.stTabs > div > div > div > div:hover  {{
  background: rgba(99, 102, 241, 0.05);
  border-bottom: 2px solid rgba(99, 102, 241, 0.3);
  color: var(--accent-primary);
}}

.stAudio {{
  margin: 12px 0;
  border-radius: 12px;
  overflow: hidden;
}}

.stSuccess {{
  background: rgba(16, 185, 129, 0.1);
  border: 1px solid rgba(16, 185, 129, 0.3);
  border-radius: 12px;
}}

.stError {{
  background: rgba(239, 68, 68, 0.1);
  border: 1px solid rgba(239, 68, 68, 0.3);
  border-radius: 12px;
}}

.stInfo {{
  background: rgba(99, 102, 241, 0.1);
  border: 1px solid rgba(99, 102, 241, 0.3);
  border-radius: 12px;
}}

/* å¯æ»šåŠ¨å†…å®¹åŒºåŸŸ */
.scrollable-content {{
  max-height: 400px;
  overflow-y: auto;
  padding-right: 8px;
}}

.scrollable-content::-webkit-scrollbar {{
  width: 6px;
}}

.scrollable-content::-webkit-scrollbar-track {{
  background: rgba(99, 102, 241, 0.1);
  border-radius: 3px;
}}

.scrollable-content::-webkit-scrollbar-thumb {{
  background: var(--accent-primary);
  border-radius: 3px;
}}

.scrollable-content::-webkit-scrollbar-thumb:hover {{
  background: var(--accent-secondary);
}}

/* ç´§å‡‘è¡¨æ ¼æ ·å¼ */
.compact-table {{
  font-size: 14px;
}}

.compact-table .dataframe {{
  width: 100%;
}}

.compact-table .dataframe th {{
  background: rgba(99, 102, 241, 0.1);
  padding: 8px 12px;
}}

.compact-table .dataframe td {{
  padding: 6px 12px;
}}

/* é¢„è§ˆåŒºåŸŸæ ·å¼ */
.preview-container {{
  border: 2px dashed var(--border-color);
  border-radius: 12px;
  padding: 20px;
  background: rgba(255, 255, 255, 0.5);
  margin: 16px 0;
}}

.preview-image {{
  max-width: 100%;
  border-radius: 8px;
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
}}

/* å®æ—¶é¢„è§ˆåŒºåŸŸ */
.live-preview-container {{
  background: rgba(255, 255, 255, 0.9);
  border-radius: 16px;
  padding: 20px;
  border: 2px solid var(--border-color);
  box-shadow: 0 8px 32px rgba(99, 102, 241, 0.1);
  height: 100%;
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
}}

.live-preview-title {{
  font-size: 18px;
  font-weight: 700;
  margin-bottom: 20px;
  color: {TEXT_DARK};
  text-align: center;
}}

.live-preview-image {{
  max-width: 100%;
  max-height: 400px;
  border-radius: 12px;
  box-shadow: 0 8px 24px rgba(0, 0, 0, 0.15);
  margin-bottom: 20px;
}}

.live-preview-text {{
  text-align: center;
  margin: 10px 0;
  font-size: 16px;
}}

.live-preview-english {{
  font-size: 24px;
  font-weight: 700;
  color: {TEXT_DARK};
}}

.live-preview-phonetic {{
  font-size: 18px;
  color: {TEXT_MUTED};
  font-style: italic;
}}

.live-preview-chinese {{
  font-size: 20px;
  color: {TEXT_DARK};
}}

/* åˆ é™¤æŒ‰é’®æ ·å¼ */
.delete-btn {{
  background: linear-gradient(135deg, #ef4444, #dc2626) !important;
  color: white !important;
  border-radius: 8px !important;
  padding: 6px 12px !important;
  font-weight: 500 !important;
  border: none !important;
  transition: all 0.3s ease !important;
  font-size: 12px !important;
  margin-top: 8px !important;
}}

.delete-btn:hover {{
  transform: translateY(-1px) !important;
  box-shadow: 0 4px 12px rgba(239, 68, 68, 0.3) !important;
  background: linear-gradient(135deg, #dc2626, #b91c1c) !important;
}}
</style>
""", unsafe_allow_html=True)

# ---------- å…¬å…±å·¥å…·å‡½æ•° ----------
def now_ts() -> int:
    return int(time.time())

def ensure_dir(p: str):
    os.makedirs(p, exist_ok=True)

def safe_remove(path: str):
    try:
        if os.path.isdir(path):
            shutil.rmtree(path)
        elif os.path.exists(path):
            os.remove(path)
    except Exception:
        pass

def hash_text_meta(text: str, voice: str, speed: float, extra: dict = None) -> str:
    j = json.dumps({"t": text, "v": voice, "s": speed, "e": extra or {}}, ensure_ascii=False, sort_keys=True)
    return hashlib.sha256(j.encode("utf-8")).hexdigest()

def cache_get(key: str) -> str:
    return os.path.join(CACHE_DIR, f"{key}.mp3")

def cache_exists(key: str) -> bool:
    p = cache_get(key)
    return os.path.exists(p) and os.path.getsize(p) > 0

def cache_store(src: str, key: str):
    dst = cache_get(key)
    try:
        shutil.copy(src, dst)
    except Exception:
        pass

# ---------- å­—ä½“æ£€æµ‹ä¸åŠ è½½ ----------
def find_font():
    """æŸ¥æ‰¾æ”¯æŒä¸­æ–‡å’ŒéŸ³æ ‡ç¬¦å·çš„å­—ä½“ - ä¸“é—¨é’ˆå¯¹Windowsä¼˜åŒ–"""
    cand = []
    if sys.platform.startswith("win"):
        # Windowsç³»ç»Ÿå­—ä½“è·¯å¾„
        windows_fonts_dir = r"C:\Windows\Fonts"
        
        # ä¼˜å…ˆé€‰æ‹©æ”¯æŒä¸­æ–‡å’ŒéŸ³æ ‡çš„å­—ä½“
        cand = [
            # æ”¯æŒéŸ³æ ‡çš„å­—ä½“ï¼ˆä¼˜å…ˆï¼‰
            os.path.join(windows_fonts_dir, "arialuni.ttf"),      # Arial Unicode MS - æ”¯æŒéŸ³æ ‡å’Œä¸­æ–‡
            os.path.join(windows_fonts_dir, "seguisym.ttf"),      # Segoe UI Symbol - æ”¯æŒéŸ³æ ‡
            os.path.join(windows_fonts_dir, "seguiemj.ttf"),      # Segoe UI Emoji - æ”¯æŒéŸ³æ ‡
            # æ”¯æŒä¸­æ–‡çš„å­—ä½“
            os.path.join(windows_fonts_dir, "simhei.ttf"),        # é»‘ä½“ - å¾ˆå¥½çš„ä¸­æ–‡æ”¯æŒ
            os.path.join(windows_fonts_dir, "msyh.ttc"),          # å¾®è½¯é›…é»‘ - ç°ä»£ä¸­æ–‡æ”¯æŒ
            os.path.join(windows_fonts_dir, "simsun.ttc"),        # å®‹ä½“ - ä¼ ç»Ÿä¸­æ–‡æ”¯æŒ
            # è‹±æ–‡å­—ä½“
            os.path.join(windows_fonts_dir, "arial.ttf"),         # Arial - è‹±æ–‡æ”¯æŒ
            os.path.join(windows_fonts_dir, "times.ttf"),         # Times New Roman
        ]
                
    elif sys.platform.startswith("darwin"):
        cand = [
            "/System/Library/Fonts/Arial Unicode.ttf",
            "/System/Library/Fonts/PingFang.ttf",
            "/System/Library/Fonts/STHeiti Light.ttc",
        ]
    else:
        cand = [
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
            "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc",
        ]
    
    # è¿”å›ç¬¬ä¸€ä¸ªå­˜åœ¨çš„å­—ä½“
    for font_path in cand:
        if os.path.exists(font_path):
            return font_path
    
    return None

DEFAULT_FONT = find_font()

def load_font(path, size, bold=False):
    """åŠ è½½å­—ä½“ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨å¤‡ç”¨å­—ä½“"""
    try:
        if path and os.path.exists(path):
            font = ImageFont.truetype(path, size)
            # å¦‚æœè¦æ±‚åŠ ç²—ï¼Œå°è¯•ä½¿ç”¨æè¾¹æ•ˆæœæ¨¡æ‹ŸåŠ ç²—
            return font
    except Exception as e:
        st.warning(f"å­—ä½“åŠ è½½å¤±è´¥ {path}: {e}")
    
    # å°è¯•å¤‡ç”¨å­—ä½“
    backup_fonts = []
    if sys.platform.startswith("win"):
        backup_fonts = [
            r"C:\Windows\Fonts\arial.ttf",
            r"C:\Windows\Fonts\times.ttf",
            r"C:\Windows\Fonts\cour.ttf",  # Courier New
        ]
    
    for font_path in backup_fonts:
        try:
            if os.path.exists(font_path):
                return ImageFont.truetype(font_path, size)
        except Exception:
            continue
    
    # æœ€åä½¿ç”¨é»˜è®¤å­—ä½“
    try:
        return ImageFont.load_default()
    except:
        # å¦‚æœè¿é»˜è®¤å­—ä½“éƒ½å¤±è´¥ï¼Œåˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„å­—ä½“
        return ImageFont.load_default()

# ---------- è¯­éŸ³ / é¢„è®¾åº“ ----------
# æ‰©å±•éŸ³è‰²åº“
EN_MALE = [
    "en-US-GuyNeural", "en-US-BenjaminNeural", "en-GB-RyanNeural",
    "en-US-BrianNeural", "en-AU-WilliamNeural", "en-CA-LiamNeural",
    "en-GB-AlfieNeural", "en-GB-ThomasNeural", "en-IE-ConnorNeural"
]
EN_FEMALE = [
    "en-US-JennyNeural", "en-US-AriaNeural", "en-GB-SoniaNeural",
    "en-US-AmberNeural", "en-US-AnaNeural", "en-AU-NatashaNeural",
    "en-CA-ClaraNeural", "en-GB-LibbyNeural", "en-GB-MaisieNeural",
    "en-IE-EmilyNeural", "en-NZ-MollyNeural"
]
ZH_VOICES = [
    "zh-CN-XiaoxiaoNeural", "zh-CN-YunxiNeural", "zh-CN-KangkangNeural",
    "zh-CN-YunxiaNeural", "zh-CN-YunyangNeural", "zh-CN-XiaoyiNeural",
    "zh-CN-XiaochenNeural", "zh-HK-HiuMaanNeural", "zh-HK-WanLungNeural",
    "zh-TW-HsiaoChenNeural", "zh-TW-YunJheNeural"
]

VOICE_LIBRARY = {
    "è‹±æ–‡å¥³å£°": EN_FEMALE, 
    "è‹±æ–‡ç”·å£°": EN_MALE, 
    "ä¸­æ–‡éŸ³è‰²": ZH_VOICES,
}

PRESET_MODES = {
    "åŸºç¡€å­¦ä¹ æ¨¡å¼": [{"content":"è‹±è¯­","category":"è‹±æ–‡å¥³å£°","speed":1.0,"pause":0.3},{"content":"éŸ³æ ‡","category":"è‹±æ–‡å¥³å£°","speed":1.0,"pause":0.2}],
    "å¼ºåŒ–è®°å¿†æ¨¡å¼": [{"content":"è‹±è¯­","category":"è‹±æ–‡ç”·å£°","speed":0.95,"pause":0.5},{"content":"ä¸­æ–‡","category":"ä¸­æ–‡éŸ³è‰²","speed":1.0,"pause":0.8},{"content":"è‹±è¯­","category":"è‹±æ–‡å¥³å£°","speed":1.05,"pause":0.3}],
    "ç†è§£ä¼˜å…ˆæ¨¡å¼": [{"content":"ä¸­æ–‡","category":"ä¸­æ–‡éŸ³è‰²","speed":1.0,"pause":0.5},{"content":"è‹±è¯­","category":"è‹±æ–‡å¥³å£°","speed":0.95,"pause":0.2}]
}

def recommend_preset(goal: str) -> str:
    if not goal:
        return "åŸºç¡€å­¦ä¹ æ¨¡å¼"
    g = goal.lower()
    if "è®°å¿†" in g or "èƒŒè¯µ" in g:
        return "å¼ºåŒ–è®°å¿†æ¨¡å¼"
    if "ç†è§£" in g or "ç¿»è¯‘" in g:
        return "ç†è§£ä¼˜å…ˆæ¨¡å¼"
    return "åŸºç¡€å­¦ä¹ æ¨¡å¼"

def get_voice_display_name(voice_name: str) -> str:
    """è·å–éŸ³è‰²çš„æ˜¾ç¤ºåç§°"""
    parts = voice_name.split("-")
    if len(parts) >= 3:
        return f"{parts[2]} ({parts[1]})"
    return voice_name

# ---------- æ¨¡æ¿ / è¿›åº¦ å­˜å– ----------
def save_template(name, style_conf, audio_segments, video_params):
    ensure_dir(TEMPLATE_DIR)
    p = os.path.join(TEMPLATE_DIR, f"{name}.json")
    json.dump({"style":style_conf,"audio":audio_segments,"video":video_params}, open(p,"w",encoding="utf-8"), ensure_ascii=False, indent=2)

def load_templates():
    ensure_dir(TEMPLATE_DIR)
    out=[]
    for f in os.listdir(TEMPLATE_DIR):
        if f.endswith(".json"):
            try:
                out.append((f[:-5], json.load(open(os.path.join(TEMPLATE_DIR,f),"r",encoding="utf-8"))))
            except:
                pass
    return out

def load_progress():
    try:
        return json.load(open(PROGRESS_FILE,"r",encoding="utf-8"))
    except:
        return {}

def save_progress(data):
    json.dump(data, open(PROGRESS_FILE,"w",encoding="utf-8"), ensure_ascii=False, indent=2)

# ---------- TTS è¾…åŠ©å‡½æ•° ----------
def generate_edge_mp3(text: str, voice: str, speed: float, out_mp3: str) -> bool:
    """åŒæ­¥å°è£… edge-tts"""
    if not EDGE_TTS_AVAILABLE:
        return False
    
    pct = int((speed - 1.0) * 100)
    rate_str = f"{pct:+d}%"
    
    try:
        return asyncio.run(_edge_save_async(text, voice, out_mp3, rate_str))
    except Exception as e:
        return False

async def _edge_save_async(text: str, voice: str, out_path: str, rate_str: str = "+0%") -> bool:
    """å¼‚æ­¥è°ƒç”¨ edge-tts ä¿å­˜"""
    if not EDGE_TTS_AVAILABLE:
        return False
    try:
        comm = edge_tts.Communicate(text=text, voice=voice, rate=rate_str)
        await comm.save(out_path)
        return True
    except Exception as e:
        return False

def generate_tts_cached(text: str, voice_category: Optional[str], voice_choice: Optional[str], speed: float, engine_pref: str, out_mp3: str) -> bool:
    """ç¼“å­˜å±‚ï¼šä¼˜å…ˆä½¿ç”¨ç¼“å­˜"""
    if not text or text.strip() == "":
        return False
        
    voice_name = voice_choice or (VOICE_LIBRARY.get(voice_category, [None])[0] if voice_category else None)
    if not voice_name:
        return False
        
    key = hash_text_meta(text, voice_name or "default", speed)
    
    if cache_exists(key):
        try:
            shutil.copy(cache_get(key), out_mp3)
            return True
        except Exception:
            pass
    
    # ä¸´æ—¶è¾“å‡º
    fd, tmpmp3 = tempfile.mkstemp(suffix=".mp3")
    os.close(fd)
    ok = False
    
    # ä¼˜å…ˆä½¿ç”¨åœ¨çº¿å¼•æ“
    if EDGE_TTS_AVAILABLE:
        ok = generate_edge_mp3(text, voice_name, speed, tmpmp3)
    
    if ok and os.path.exists(tmpmp3) and os.path.getsize(tmpmp3) > 0:
        try:
            cache_store(tmpmp3, key)
            shutil.copy(cache_get(key), out_mp3)
            safe_remove(tmpmp3)
            return True
        except Exception:
            try:
                shutil.copy(tmpmp3, out_mp3)
                safe_remove(tmpmp3)
                return True
            except:
                safe_remove(tmpmp3)
                return False
    safe_remove(tmpmp3)
    return False

# ---------- åŸºæœ¬éŸ³é¢‘å¤„ç† ----------
def create_silent_mp3(out_path: str, duration_s: float) -> bool:
    """åˆ›å»ºä¸€æ®µé™éŸ³ mp3"""
    try:
        if ffmpeg_available():
            cmd = ["ffmpeg","-y","-f","lavfi","-i",f"anullsrc=r=44100:cl=mono","-t",str(duration_s), out_path]
            run_ffmpeg_command(cmd)
            return os.path.exists(out_path)
    except Exception as e:
        pass
    
    # å¤‡ç”¨æ–¹æ¡ˆ
    try:
        with open(out_path, "wb") as f: 
            f.write(b"")
        return True
    except:
        return False

def concat_audios_ffmpeg(audio_paths: List[str], out_mp3: str) -> None:
    """ä½¿ç”¨ ffmpeg concat åˆå¹¶å¤šä¸ª mp3 æ–‡ä»¶"""
    if not audio_paths:
        raise ValueError("audio_paths empty")
    if not ffmpeg_available():
        raise RuntimeError("ffmpeg missing for audio concat")
    
    listfile = out_mp3 + "_list.txt"
    with open(listfile, "w", encoding="utf-8") as f:
        for p in audio_paths:
            f.write(f"file '{os.path.abspath(p)}'\n")
    
    cmd = ["ffmpeg","-y","-f","concat","-safe","0","-i",listfile,"-c","copy",out_mp3]
    run_ffmpeg_command(cmd)
    
    if not os.path.exists(out_mp3):
        raise RuntimeError("Audio concat failed: output file not created")
    
    safe_remove(listfile)

# ---------- é¢„è§ˆéŸ³é¢‘ç”Ÿæˆå‡½æ•° ----------
def generate_preview_audio(df, row_index, audio_segments):
    """ç”Ÿæˆé¢„è§ˆéŸ³é¢‘"""
    if df is None or row_index >= len(df):
        return None
    
    tmpdir = tempfile.mkdtemp(prefix="preview_")
    try:
        row = df.iloc[row_index]
        en = str(row.get("è‹±è¯­",""))
        ph = str(row.get("éŸ³æ ‡",""))
        cn = str(row.get("ä¸­æ–‡",""))
        
        seg_paths = []
        
        for seg_idx, seg in enumerate(audio_segments):
            text = en if seg["content"]=="è‹±è¯­" else (ph if seg["content"]=="éŸ³æ ‡" else cn)
            out_mp3 = os.path.join(tmpdir, f"preview_{seg_idx}_{seg['content']}.mp3")
            
            ok = generate_tts_cached(text, seg["voice_category"], seg["voice_choice"], seg["speed"], "åœ¨çº¿ä¼˜å…ˆ", out_mp3)
            if ok and os.path.exists(out_mp3):
                seg_paths.append(out_mp3)
            
            # æ·»åŠ åœé¡¿
            if seg.get("pause",0) > 0:
                pause_path = os.path.join(tmpdir, f"pause_{seg_idx}.mp3")
                create_silent_mp3(pause_path, seg["pause"])
                seg_paths.append(pause_path)
        
        # åˆå¹¶éŸ³é¢‘
        if seg_paths:
            merged_audio = os.path.join(tmpdir, "preview_merged.mp3")
            try:
                concat_audios_ffmpeg(seg_paths, merged_audio)
                return merged_audio
            except Exception as e:
                st.error(f"é¢„è§ˆéŸ³é¢‘åˆå¹¶å¤±è´¥: {e}")
        
        return None
    except Exception as e:
        st.error(f"é¢„è§ˆéŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
        return None
    finally:
        # æ³¨æ„ï¼šè¿™é‡Œä¸åˆ é™¤ä¸´æ—¶ç›®å½•ï¼Œå› ä¸ºéŸ³é¢‘æ–‡ä»¶è¿˜éœ€è¦ä½¿ç”¨
        pass

# ---------- éŸ³è‰²æ ·æœ¬åº“ ----------
def ensure_sample_voice(voice_name: str, sample_text: str = "Hello, this is a sample.") -> Optional[str]:
    """ç”Ÿæˆæˆ–è¿”å›ç¼“å­˜çš„éŸ³è‰²ç¤ºä¾‹ mp3 è·¯å¾„"""
    key = hashlib.sha1(f"sample::{voice_name}".encode()).hexdigest()
    out = cache_get(key)
    if os.path.exists(out):
        return out
    
    # ç”Ÿæˆç¤ºä¾‹
    fd, tmpmp3 = tempfile.mkstemp(suffix=".mp3")
    os.close(fd)
    ok = False
    
    if EDGE_TTS_AVAILABLE:
        ok = generate_edge_mp3(sample_text, voice_name, 1.0, tmpmp3)
    
    if ok and os.path.exists(tmpmp3):
        cache_store(tmpmp3, key)
        safe_remove(tmpmp3)
        return cache_get(key)
    
    safe_remove(tmpmp3)
    return None

# ---------- TXTæ–‡ä»¶è§£æå‡½æ•° ----------
def parse_txt_file(uploaded_file):
    """è§£æTXTæ–‡ä»¶å†…å®¹ä¸ºDataFrame"""
    content = uploaded_file.read().decode('utf-8')
    lines = content.strip().split('\n')
    
    data = []
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # è§£ææ ¼å¼ï¼šè‹±è¯­ - éŸ³æ ‡ - ä¸­æ–‡
        parts = line.split(' - ', 2)  # æœ€å¤šåˆ†å‰²æˆ3éƒ¨åˆ†
        if len(parts) == 3:
            english, phonetic, chinese = parts
            data.append({
                'è‹±è¯­': english.strip(),
                'éŸ³æ ‡': phonetic.strip(),
                'ä¸­æ–‡': chinese.strip()
            })
        elif len(parts) == 2:
            # å¦‚æœæ²¡æœ‰éŸ³æ ‡ï¼Œåªæœ‰è‹±è¯­å’Œä¸­æ–‡
            english, chinese = parts
            data.append({
                'è‹±è¯­': english.strip(),
                'éŸ³æ ‡': '',
                'ä¸­æ–‡': chinese.strip()
            })
        else:
            # å¦‚æœæ ¼å¼ä¸åŒ¹é…ï¼Œå°è¯•å…¶ä»–åˆ†éš”ç¬¦
            if ' - ' in line:
                # å·²ç»å°è¯•è¿‡ï¼Œè·³è¿‡
                continue
            elif ' /' in line and '/ ' in line:
                # å°è¯•è§£æåŒ…å«éŸ³æ ‡çš„æ ¼å¼
                phonetic_start = line.find(' /')
                phonetic_end = line.find('/ ')
                if phonetic_start != -1 and phonetic_end != -1:
                    english = line[:phonetic_start].strip()
                    phonetic = line[phonetic_start:phonetic_end+1].strip()
                    chinese = line[phonetic_end+1:].strip()
                    data.append({
                        'è‹±è¯­': english,
                        'éŸ³æ ‡': phonetic,
                        'ä¸­æ–‡': chinese
                    })
                else:
                    # å¦‚æœè¿˜æ˜¯æ— æ³•è§£æï¼Œå°†æ•´è¡Œä½œä¸ºè‹±è¯­
                    data.append({
                        'è‹±è¯­': line.strip(),
                        'éŸ³æ ‡': '',
                        'ä¸­æ–‡': ''
                    })
            else:
                # å¦‚æœè¿˜æ˜¯æ— æ³•è§£æï¼Œå°†æ•´è¡Œä½œä¸ºè‹±è¯­
                data.append({
                    'è‹±è¯­': line.strip(),
                    'éŸ³æ ‡': '',
                    'ä¸­æ–‡': ''
                })
    
    return pd.DataFrame(data)

# ---------- é¡µé¢é¡¶éƒ¨ / å¯¼èˆª ----------
st.markdown(f'<div class="main-title">ğŸ¬ è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨ - ä¸“ä¸šçº§å¤šéŸ³è‰²æ•™å­¦è§†é¢‘åˆ¶ä½œå¹³å°</div>', unsafe_allow_html=True)
st.markdown(f"""<div class="navbar">
  <div class="nav-btn">ğŸ“ æ•°æ®ç®¡ç†</div>
  <div class="nav-btn">ğŸ”Š éŸ³é¢‘è®¾ç½®</div>
  <div class="nav-btn">ğŸ‘€ æ•ˆæœé¢„è§ˆ</div>
  <div class="nav-btn">ğŸ“¤ ç”Ÿæˆè¾“å‡º</div>
</div>""", unsafe_allow_html=True)

# ---------- æ•°æ®ç®¡ç†éƒ¨åˆ† ----------
st.markdown('<div class="card-header">ğŸ“ æ•°æ®ç®¡ç†</div>', unsafe_allow_html=True)
uploaded = st.file_uploader("æ‹–æ‹½ä¸Šä¼  Excel/CSV/TXTï¼ˆå¿…é¡»åˆ—åï¼šè‹±è¯­ã€ä¸­æ–‡ï¼ŒéŸ³æ ‡å¯é€‰ï¼‰", type=["xlsx","xls","csv","txt"])
df = None
if uploaded:
    try:
        if uploaded.name.lower().endswith((".csv",".txt")):
            if uploaded.name.lower().endswith(".txt"):
                # ä½¿ç”¨æ–°çš„TXTæ–‡ä»¶è§£æå‡½æ•°
                df = parse_txt_file(uploaded)
            else:
                df = pd.read_csv(uploaded)
        else:
            df = pd.read_excel(uploaded)
            
        cols = [str(c).strip() for c in df.columns]
        df.columns = cols
        if "è‹±è¯­" not in df.columns or "ä¸­æ–‡" not in df.columns:
            st.error("å¿…é¡»åŒ…å«åˆ—åï¼š'è‹±è¯­' å’Œ 'ä¸­æ–‡'ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰ã€‚")
            df = None
        else:
            if "éŸ³æ ‡" not in df.columns:
                df["éŸ³æ ‡"] = ""
            st.success(f"è§£ææˆåŠŸï¼Œ{len(df)} è¡Œ")
            st.write("å‰ 10 è¡Œé¢„è§ˆï¼š")
            st.markdown('<div class="compact-table">', unsafe_allow_html=True)
            st.dataframe(df.head(10), width='stretch')
            
            if st.button("åœ¨é¡µé¢ä¸­ç¼–è¾‘æ•°æ®", width='stretch'):
                edited = st.data_editor(df, num_rows="dynamic", width='stretch')
                df = edited.copy()
                st.success("å·²åº”ç”¨ç¼–è¾‘")
    except Exception as e:
        st.error(f"è§£æå¤±è´¥ï¼š{e}")
        st.info("TXTæ–‡ä»¶æ ¼å¼è¦æ±‚ï¼šæ¯è¡Œæ ¼å¼ä¸º 'è‹±è¯­å¥å­ - éŸ³æ ‡ - ä¸­æ–‡è§£é‡Š'")
else:
    st.info("æœªä¸Šä¼ æ•°æ®ï¼Œç¤ºä¾‹ï¼šè¯·ä¸Šä¼ åŒ…å«åˆ— è‹±è¯­ / ä¸­æ–‡ï¼ˆå¯é€‰ éŸ³æ ‡ï¼‰çš„æ–‡ä»¶ã€‚")

# ---------- éŸ³é¢‘è®¾ç½®éƒ¨åˆ† ----------
st.markdown('<div class="card-header">ğŸ”Š éŸ³é¢‘è®¾ç½®</div>', unsafe_allow_html=True)

# ä½¿ç”¨é€‰é¡¹å¡ç»„ç»‡éŸ³é¢‘è®¾ç½®
tab_audio_config, tab_voice_library, tab_voice_settings = st.tabs(["ğŸµ éŸ³é¢‘ç¼–æ’", "ğŸ™ï¸ éŸ³è‰²æ ·æœ¬åº“", "âš™ï¸ éŸ³è‰²è®¾ç½®"])

with tab_audio_config:
    st.markdown('<div class="scrollable-content">', unsafe_allow_html=True)
    
    engine_pref = st.selectbox("å¼•æ“åå¥½", ["åœ¨çº¿ä¼˜å…ˆ"], key="ui_engine_pref")
    st.caption(f"ç³»ç»Ÿç¦»çº¿å¯ç”¨: {PYTTSX3_AVAILABLE}ï¼›åœ¨çº¿ edge-tts å¯ç”¨: {EDGE_TTS_AVAILABLE}")

    # æ™ºèƒ½æ¨è + é¢„è®¾é€‰æ‹©
    learning_goal = st.text_input("å­¦ä¹ ç›®æ ‡ï¼ˆç”¨äºæ™ºèƒ½æ¨èï¼‰", value="", key="ui_learning_goal")
    recommended = recommend_preset(learning_goal)
    preset_choice = st.selectbox("é¢„è®¾æ’­æ”¾æ¨¡å¼", ["(è‡ªå®šä¹‰)"] + list(PRESET_MODES.keys()), index=1 if recommended in PRESET_MODES else 0, key="ui_preset_choice")

    # åˆå§‹åŒ–éŸ³é¢‘æ®µ
    if 'audio_segments' not in st.session_state:
        st.session_state.audio_segments = [
            {"content": "è‹±è¯­", "voice_category": "è‹±æ–‡å¥³å£°", "voice_choice": None, "speed": 1.0, "pause": 0.3},
            {"content": "éŸ³æ ‡", "voice_category": "è‹±æ–‡å¥³å£°", "voice_choice": None, "speed": 1.0, "pause": 0.2},
            {"content": "ä¸­æ–‡", "voice_category": "ä¸­æ–‡éŸ³è‰²", "voice_choice": None, "speed": 1.0, "pause": 0.5},
            {"content": "è‹±è¯­", "voice_category": "è‹±æ–‡å¥³å£°", "voice_choice": None, "speed": 1.0, "pause": 0.3}
        ]

    # åº”ç”¨é¢„è®¾
    if preset_choice != "(è‡ªå®šä¹‰)" and preset_choice in PRESET_MODES:
        if st.button("åº”ç”¨é¢„è®¾"):
            st.session_state.audio_segments = PRESET_MODES[preset_choice].copy()
            st.success(f"å·²åº”ç”¨ {preset_choice} é¢„è®¾")
            st.rerun()

    # æ„å»ºæ®µé…ç½®è¡¨
    audio_segments = st.session_state.audio_segments
    
    # æ·»åŠ æ–°æ®µçš„æŒ‰é’®
    if st.button("â• æ·»åŠ éŸ³é¢‘æ®µ", key="add_audio_segment"):
        st.session_state.audio_segments.append({
            "content": "è‹±è¯­", 
            "voice_category": "è‹±æ–‡å¥³å£°", 
            "voice_choice": None, 
            "speed": 1.0, 
            "pause": 0.3
        })
        st.rerun()

    for si, seg in enumerate(audio_segments):
        st.markdown(f"**æ®µ {si+1}**", unsafe_allow_html=True)
        c1, c2, c3, c4, c5 = st.columns([1.5, 1.2, 1, 1, 0.8])
        
        with c1:
            content = st.selectbox(
                f"æ®µ{si+1} å†…å®¹", 
                ["è‹±è¯­", "éŸ³æ ‡", "ä¸­æ–‡"], 
                index=["è‹±è¯­", "éŸ³æ ‡", "ä¸­æ–‡"].index(seg["content"]),
                key=f"ui_seg_content_{si}"
            )
            st.session_state.audio_segments[si]["content"] = content
            
        with c2:
            category = st.selectbox(
                f"æ®µ{si+1} éŸ³è‰²åº“", 
                ["è‹±æ–‡å¥³å£°", "è‹±æ–‡ç”·å£°", "ä¸­æ–‡éŸ³è‰²"], 
                index=["è‹±æ–‡å¥³å£°", "è‹±æ–‡ç”·å£°", "ä¸­æ–‡éŸ³è‰²"].index(seg["voice_category"]),
                key=f"ui_seg_cat_{si}"
            )
            st.session_state.audio_segments[si]["voice_category"] = category
            
        with c3:
            # ä»éŸ³è‰²è®¾ç½®ä¸­è·å–é»˜è®¤éŸ³è‰²
            voice_settings_key = f"default_voice_{category}"
            default_voice = st.session_state.get(voice_settings_key, VOICE_LIBRARY.get(category, [""])[0])
            
            presets = VOICE_LIBRARY.get(category, [])
            ls = ["(é»˜è®¤)"] + presets
            current_choice = seg["voice_choice"] or "(é»˜è®¤)"
            
            vc = st.selectbox(
                f"æ®µ{si+1} å…·ä½“éŸ³è‰²", 
                ls, 
                index=ls.index(current_choice) if current_choice in ls else 0,
                key=f"ui_seg_preset_{si}"
            )
            st.session_state.audio_segments[si]["voice_choice"] = None if vc == "(é»˜è®¤)" else vc
            
        with c4:
            speed = st.slider(
                f"æ®µ{si+1} è¯­é€Ÿ", 
                0.5, 2.0, seg["speed"], 0.1, 
                key=f"ui_seg_speed_{si}"
            )
            st.session_state.audio_segments[si]["speed"] = speed
            
            pause = st.number_input(
                f"æ®µ{si+1} åœé¡¿ (ç§’)", 
                min_value=0.0, max_value=5.0, value=seg["pause"], step=0.1, 
                key=f"ui_seg_pause_{si}"
            )
            st.session_state.audio_segments[si]["pause"] = pause
            
        with c5:
            # åˆ é™¤æŒ‰é’®
            if len(audio_segments) > 1:  # è‡³å°‘ä¿ç•™ä¸€ä¸ªæ®µ
                if st.button("ğŸ—‘ï¸", key=f"delete_seg_{si}", help="åˆ é™¤æ­¤éŸ³é¢‘æ®µ"):
                    st.session_state.audio_segments.pop(si)
                    st.rerun()
            else:
                st.write("")  # å ä½

with tab_voice_library:
    st.markdown('<div class="scrollable-content">', unsafe_allow_html=True)
    
    # ä½¿ç”¨é€‰é¡¹å¡ç»„ç»‡ä¸åŒéŸ³è‰²åˆ†ç±»
    tab1, tab2, tab3 = st.tabs(["ğŸ™ï¸ è‹±æ–‡å¥³å£°", "ğŸ™ï¸ è‹±æ–‡ç”·å£°", "ğŸ™ï¸ ä¸­æ–‡éŸ³è‰²"])
    
    with tab1:
        st.markdown('<div class="voice-library">', unsafe_allow_html=True)
        for voice in EN_FEMALE:
            sample_path = ensure_sample_voice(voice, "This is a sample of female English voice.")
            col1, col2 = st.columns([3, 1])
            with col1:
                st.markdown(f'<div class="voice-name">{get_voice_display_name(voice)}</div>', unsafe_allow_html=True)
                st.markdown(f'<div class="voice-category">è‹±æ–‡å¥³å£°</div>', unsafe_allow_html=True)
            with col2:
                if sample_path and os.path.exists(sample_path):
                    st.audio(sample_path, format="audio/mp3")
                else:
                    st.warning("æ ·æœ¬ç”Ÿæˆä¸­...")
        
    
    with tab2:
        st.markdown('<div class="voice-library">', unsafe_allow_html=True)
        for voice in EN_MALE:
            sample_path = ensure_sample_voice(voice, "This is a sample of male English voice.")
            col1, col2 = st.columns([3, 1])
            with col1:
                st.markdown(f'<div class="voice-name">{get_voice_display_name(voice)}</div>', unsafe_allow_html=True)
                st.markdown(f'<div class="voice-category">è‹±æ–‡ç”·å£°</div>', unsafe_allow_html=True)
            with col2:
                if sample_path and os.path.exists(sample_path):
                    st.audio(sample_path, format="audio/mp3")
                else:
                    st.warning("æ ·æœ¬ç”Ÿæˆä¸­...")
        
    
    with tab3:
        st.markdown('<div class="voice-library">', unsafe_allow_html=True)
        for voice in ZH_VOICES:
            sample_path = ensure_sample_voice(voice, "è¿™æ˜¯ä¸€ä¸ªä¸­æ–‡éŸ³è‰²æ ·æœ¬ã€‚")
            col1, col2 = st.columns([3, 1])
            with col1:
                st.markdown(f'<div class="voice-name">{get_voice_display_name(voice)}</div>', unsafe_allow_html=True)
                st.markdown(f'<div class="voice-category">ä¸­æ–‡éŸ³è‰²</div>', unsafe_allow_html=True)
            with col2:
                if sample_path and os.path.exists(sample_path):
                    st.audio(sample_path, format="audio/mp3")
                else:
                    st.warning("æ ·æœ¬ç”Ÿæˆä¸­...")

with tab_voice_settings:
    st.markdown('<div class="scrollable-content">', unsafe_allow_html=True)
    st.markdown("### é»˜è®¤éŸ³è‰²è®¾ç½®")
    st.info("åœ¨è¿™é‡Œè®¾ç½®å„ç±»éŸ³è‰²çš„é»˜è®¤é€‰æ‹©ï¼ŒéŸ³é¢‘ç¼–æ’ä¸­çš„éŸ³è‰²é€‰æ‹©ä¼šé»˜è®¤ä½¿ç”¨è¿™é‡Œçš„è®¾ç½®")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### è‹±æ–‡å¥³å£°")
        default_female = st.selectbox(
            "é»˜è®¤è‹±æ–‡å¥³å£°éŸ³è‰²",
            options=EN_FEMALE,
            index=EN_FEMALE.index("en-GB-SoniaNeural") if "en-GB-SoniaNeural" in EN_FEMALE else 0,
            format_func=get_voice_display_name,
            key="default_voice_è‹±æ–‡å¥³å£°"
        )
    
    with col2:
        st.markdown("#### è‹±æ–‡ç”·å£°")
        default_male = st.selectbox(
            "é»˜è®¤è‹±æ–‡ç”·å£°éŸ³è‰²",
            options=EN_MALE,
            index=EN_MALE.index("en-GB-RyanNeural") if "en-GB-RyanNeural" in EN_MALE else 0,
            format_func=get_voice_display_name,
            key="default_voice_è‹±æ–‡ç”·å£°"
        )
    
    with col3:
        st.markdown("#### ä¸­æ–‡éŸ³è‰²")
        default_chinese = st.selectbox(
            "é»˜è®¤ä¸­æ–‡éŸ³è‰²",
            options=ZH_VOICES,
            index=ZH_VOICES.index("zh-CN-XiaoxiaoNeural") if "zh-CN-XiaoxiaoNeural" in ZH_VOICES else 0,
            format_func=get_voice_display_name,
            key="default_voice_ä¸­æ–‡éŸ³è‰²"
        )

# ---------- Frame rendering ----------
def render_frame(en, ph, cn, conf, size=(1280,720)):
    """æ¸²æŸ“å•å¸§å›¾åƒ - ä¸“é—¨é’ˆå¯¹éŸ³æ ‡å’Œå­—ä½“åŠ ç²—é—®é¢˜ä¿®å¤"""
    W,H = size
    
    try:
        # åº”ç”¨æ–‡å­—åŒºåŸŸå®½åº¦æ¯”ä¾‹
        text_area_width = int(W * conf.get("text_area_width_ratio", 0.88))
        text_start_x = (W - text_area_width) // 2
        
        # åˆ›å»ºèƒŒæ™¯
        if conf.get("bg_mode") == "image" and conf.get("bg_image"):
            # ä½¿ç”¨èƒŒæ™¯å›¾ç‰‡
            bg_img = conf["bg_image"]
            # è°ƒæ•´èƒŒæ™¯å›¾ç‰‡å¤§å°ä»¥é€‚åº”å¸§å°ºå¯¸
            bg_img = bg_img.resize((W, H), Image.Resampling.LANCZOS)
            
            # åº”ç”¨èƒŒæ™¯é€æ˜åº¦
            bg_alpha = conf.get("bg_image_alpha", 1.0)
            if bg_alpha < 1.0:
                # åˆ›å»ºé€æ˜èƒŒæ™¯
                base = Image.new("RGBA", (W, H), (255, 255, 255, 0))
                # å°†èƒŒæ™¯å›¾ç‰‡è½¬æ¢ä¸ºRGBA
                bg_img = bg_img.convert("RGBA")
                # è°ƒæ•´é€æ˜åº¦
                if bg_img.mode == 'RGBA':
                    # åˆ†ç¦»alphaé€šé“
                    r, g, b, a = bg_img.split()
                    # è°ƒæ•´alphaé€šé“
                    a = a.point(lambda i: i * bg_alpha)
                    bg_img = Image.merge('RGBA', (r, g, b, a))
                base.paste(bg_img, (0, 0), bg_img)
            else:
                base = bg_img.convert("RGB")
        else:
            # ä½¿ç”¨çº¯è‰²èƒŒæ™¯
            bg_color = conf.get("bg_color", "#D1E1EF")  # é»˜è®¤èƒŒæ™¯é¢œè‰²
            base = Image.new("RGB", (W,H), bg_color)
        
        draw = ImageDraw.Draw(base)

        # åŠ è½½å­—ä½“ - ä¸“é—¨é’ˆå¯¹éŸ³æ ‡ä¼˜åŒ–
        font_en = load_font(DEFAULT_FONT, conf.get("english_size", 46))
        font_ph = load_font(DEFAULT_FONT, conf.get("phonetic_size", 30))
        font_cn = load_font(DEFAULT_FONT, conf.get("chinese_size", 46))

        # è®¡ç®—æ–‡æœ¬ä½ç½®
        english_color = conf.get("english_color", "#000000")  # é»˜è®¤é»‘è‰²
        phonetic_color = conf.get("phonetic_color", "#E6BF20")  # é»˜è®¤éŸ³æ ‡é¢œè‰²
        chinese_color = conf.get("chinese_color", "#000000")  # é»˜è®¤é»‘è‰²
        
        # è·å–åŠ ç²—è®¾ç½®
        english_bold = conf.get("english_bold", False)
        phonetic_bold = conf.get("phonetic_bold", False)
        chinese_bold = conf.get("chinese_bold", False)
        
        # è®¡ç®—æ€»é«˜åº¦
        total_height = (
            conf.get("english_size", 46) + 
            conf.get("phonetic_size", 30) + 
            conf.get("chinese_size", 46) +
            conf.get("english_phonetic_gap", 10) +
            conf.get("phonetic_cn_gap", 10)
        )
        
        start_y = (H - total_height) // 2
        
        # å¦‚æœå¯ç”¨æ–‡å­—èƒŒæ™¯æ¿ï¼Œç»˜åˆ¶èƒŒæ™¯
        if conf.get("text_bg_enable", False):
            # è®¡ç®—èƒŒæ™¯åŒºåŸŸ
            padding = conf.get("text_padding", 20)
            bg_alpha = int(conf.get("text_bg_alpha", 0.35) * 255)
            bg_color = conf.get("text_bg_color", "#FFFFFF")
            bg_radius = conf.get("text_bg_radius", 12)
            
            # åˆ›å»ºåŠé€æ˜èƒŒæ™¯
            bg_rect = Image.new('RGBA', (text_area_width, total_height + padding * 2), (255, 255, 255, 0))
            bg_draw = ImageDraw.Draw(bg_rect)
            
            # ç»˜åˆ¶åœ†è§’çŸ©å½¢ - ä¿®å¤é¢œè‰²è½¬æ¢é—®é¢˜
            try:
                # ä½¿ç”¨ ImageColor.getrgb å°†é¢œè‰²å­—ç¬¦ä¸²è½¬æ¢ä¸º RGB å…ƒç»„
                rgb_color = ImageColor.getrgb(bg_color)
                # æ·»åŠ  alpha é€šé“
                rgba_color = (*rgb_color, bg_alpha)
                bg_draw.rounded_rectangle(
                    [(0, 0), (text_area_width, total_height + padding * 2)],
                    radius=bg_radius,
                    fill=rgba_color
                )
            except Exception as e:
                # å¦‚æœé¢œè‰²è½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨ç™½è‰²ä½œä¸ºå¤‡é€‰
                rgba_color = (255, 255, 255, bg_alpha)
                bg_draw.rounded_rectangle(
                    [(0, 0), (text_area_width, total_height + padding * 2)],
                    radius=bg_radius,
                    fill=rgba_color
                )
            
            # å°†èƒŒæ™¯åˆæˆåˆ°ä¸»å›¾åƒä¸Š
            base.paste(bg_rect, (text_start_x, start_y - padding), bg_rect)
        
        # è‹±è¯­æ–‡æœ¬æ¸²æŸ“
        y = start_y
        try:
            bbox = draw.textbbox((0, 0), en, font=font_en)
            text_width = bbox[2] - bbox[0]
            x = text_start_x + (text_area_width - text_width) // 2
            
            # åº”ç”¨åŠ ç²—æ•ˆæœ
            if english_bold:
                # ç»˜åˆ¶å¤šæ¬¡å®ç°åŠ ç²—æ•ˆæœ
                for dx, dy in [(-1, -1), (1, -1), (-1, 1), (1, 1)]:
                    draw.text((x+dx, y+dy), en, font=font_en, fill=english_color)
            
            draw.text((x, y), en, font=font_en, fill=english_color)
        except Exception as e:
            # å¦‚æœé«˜çº§æ–¹æ³•å¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ–¹æ³•
            try:
                # ä¼°ç®—æ–‡æœ¬å®½åº¦
                approx_width = len(en) * conf.get("english_size", 46) // 2
                x = text_start_x + (text_area_width - approx_width) // 2
                
                # åº”ç”¨åŠ ç²—æ•ˆæœ
                if english_bold:
                    for dx, dy in [(-1, -1), (1, -1), (-1, 1), (1, 1)]:
                        draw.text((x+dx, y+dy), en, font=font_en, fill=english_color)
                
                draw.text((x, y), en, font=font_en, fill=english_color)
            except Exception as e2:
                # å¦‚æœä»ç„¶å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ä½ç½®
                x = text_start_x + 20
                draw.text((x, y), en, font=font_en, fill=english_color)
        
        y += conf.get("english_size", 46) + conf.get("english_phonetic_gap", 10)
        
        # éŸ³æ ‡æ–‡æœ¬æ¸²æŸ“ - ä¸“é—¨ä¿®å¤éŸ³æ ‡æ˜¾ç¤º
        if ph and ph.strip():
            try:
                # å¤„ç†éŸ³æ ‡ç¬¦å· - ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å­—ä½“
                bbox = draw.textbbox((0, 0), ph, font=font_ph)
                text_width = bbox[2] - bbox[0]
                x = text_start_x + (text_area_width - text_width) // 2
                
                # åº”ç”¨åŠ ç²—æ•ˆæœ
                if phonetic_bold:
                    for dx, dy in [(-1, -1), (1, -1), (-1, 1), (1, 1)]:
                        draw.text((x+dx, y+dy), ph, font=font_ph, fill=phonetic_color)
                
                draw.text((x, y), ph, font=font_ph, fill=phonetic_color)
            except Exception as e:
                try:
                    # ä¼°ç®—æ–‡æœ¬å®½åº¦
                    approx_width = len(ph) * conf.get("phonetic_size", 30) // 2
                    x = text_start_x + (text_area_width - approx_width) // 2
                    
                    # åº”ç”¨åŠ ç²—æ•ˆæœ
                    if phonetic_bold:
                        for dx, dy in [(-1, -1), (1, -1), (-1, 1), (1, 1)]:
                            draw.text((x+dx, y+dy), ph, font=font_ph, fill=phonetic_color)
                    
                    draw.text((x, y), ph, font=font_ph, fill=phonetic_color)
                except Exception as e2:
                    x = text_start_x + 20
                    draw.text((x, y), ph, font=font_ph, fill=phonetic_color)
            
            y += conf.get("phonetic_size", 30) + conf.get("phonetic_cn_gap", 10)
        
        # ä¸­æ–‡æ–‡æœ¬æ¸²æŸ“
        try:
            bbox = draw.textbbox((0, 0), cn, font=font_cn)
            text_width = bbox[2] - bbox[0]
            x = text_start_x + (text_area_width - text_width) // 2
            
            # åº”ç”¨åŠ ç²—æ•ˆæœ
            if chinese_bold:
                for dx, dy in [(-1, -1), (1, -1), (-1, 1), (1, 1)]:
                    draw.text((x+dx, y+dy), cn, font=font_cn, fill=chinese_color)
            
            draw.text((x, y), cn, font=font_cn, fill=chinese_color)
        except Exception as e:
            try:
                approx_width = len(cn) * conf.get("chinese_size", 46) // 2
                x = text_start_x + (text_area_width - approx_width) // 2
                
                # åº”ç”¨åŠ ç²—æ•ˆæœ
                if chinese_bold:
                    for dx, dy in [(-1, -1), (1, -1), (-1, 1), (1, 1)]:
                        draw.text((x+dx, y+dy), cn, font=font_cn, fill=chinese_color)
                
                draw.text((x, y), cn, font=font_cn, fill=chinese_color)
            except Exception as e2:
                x = text_start_x + 20
                draw.text((x, y), cn, font=font_cn, fill=chinese_color)

        return base
    except Exception as e:
        st.error(f"å¸§æ¸²æŸ“å¤±è´¥: {e}")
        # åˆ›å»ºé”™è¯¯å›¾åƒ
        error_img = Image.new("RGB", (W, H), conf.get("bg_color", "#D1E1EF"))
        draw = ImageDraw.Draw(error_img)
        # ä½¿ç”¨é»˜è®¤å­—ä½“æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        try:
            draw.text((50, H//2), f"æ¸²æŸ“é”™è¯¯: {str(e)}", fill="red")
        except:
            pass
        return error_img

# ---------- æ•ˆæœé¢„è§ˆéƒ¨åˆ† ----------
st.markdown('<div class="card-header">ğŸ‘€ æ•ˆæœé¢„è§ˆ</div>', unsafe_allow_html=True)

# æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„å­—ä½“ä¿¡æ¯
if DEFAULT_FONT:
    st.sidebar.success(f"å½“å‰å­—ä½“: {os.path.basename(DEFAULT_FONT)}")
else:
    st.sidebar.warning("æœªæ‰¾åˆ°ç³»ç»Ÿå­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")

if uploaded is not None and df is not None:
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼šå·¦ä¾§æ ·å¼è®¾è®¡ï¼Œå³ä¾§å®æ—¶é¢„è§ˆ
    preview_col1, preview_col2 = st.columns([1, 1])
    
    with preview_col1:
        st.markdown('<div class="card-header">ğŸ¨ æ ·å¼è®¾è®¡</div>', unsafe_allow_html=True)
        
        # ä½¿ç”¨é€‰é¡¹å¡ç»„ç»‡æ ·å¼è®¾ç½®
        tab_bg, tab_text, tab_layout, tab_advanced = st.tabs(["ğŸ¨ èƒŒæ™¯è®¾ç½®", "ğŸ”¤ æ–‡å­—æ ·å¼", "ğŸ“ å¸ƒå±€è°ƒæ•´", "âš™ï¸ é«˜çº§è®¾ç½®"])
        
        with tab_bg:
            st.markdown('<div class="scrollable-content">', unsafe_allow_html=True)
            # --- èƒŒæ™¯è®¾ç½® ---
            bg_col1, bg_col2 = st.columns([1,1])
            with bg_col1:
                bg_mode = st.selectbox("èƒŒæ™¯ç±»å‹", ["çº¯è‰²èƒŒæ™¯", "å›¾ç‰‡èƒŒæ™¯"], key="ui_bg_mode")
            with bg_col2:
                ui_bg_color = st.color_picker("èƒŒæ™¯é¢œè‰²", "#D1E1EF", key="ui_bg_color")  # é»˜è®¤èƒŒæ™¯é¢œè‰²
            
            ui_bg_image = None
            if bg_mode == "å›¾ç‰‡èƒŒæ™¯":
                bg_file = st.file_uploader("ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡ (JPG/PNG)", type=["jpg","jpeg","png"], key="ui_bgimg")
                if bg_file:
                    try:
                        ui_bg_image = Image.open(bg_file).convert("RGBA")
                        st.image(ui_bg_image, caption="èƒŒæ™¯é¢„è§ˆ", use_container_width=True)
                    except Exception:
                        st.error("æ— æ³•è¯»å–èƒŒæ™¯å›¾ç‰‡")
                
                # èƒŒæ™¯å›¾ç‰‡é€æ˜åº¦è®¾ç½®
                bg_image_alpha = st.slider("èƒŒæ™¯å›¾ç‰‡é€æ˜åº¦", 0.0, 1.0, 1.0, 0.05, key="ui_bg_image_alpha")
                st.caption("1.0ä¸ºå®Œå…¨ä¸é€æ˜ï¼Œ0.0ä¸ºå®Œå…¨é€æ˜")
        
        with tab_text:
            st.markdown('<div class="scrollable-content">', unsafe_allow_html=True)
            
            # --- æ–‡å­—æ ·å¼ ---
            st.markdown("**æ–‡å­—æ ·å¼**")
            col_en, col_ph, col_cn = st.columns(3)
            with col_en:
                en_size = st.slider("è‹±è¯­å­—å·", 0, 160, 46, key="ui_en_size")
                en_color = st.color_picker("è‹±è¯­é¢œè‰²", "#000000", key="ui_en_color")  # é»˜è®¤é»‘è‰²
                english_bold = st.checkbox("è‹±è¯­åŠ ç²—", value=False, key="ui_english_bold")
            with col_ph:
                ph_size = st.slider("éŸ³æ ‡å­—å·", 0, 120, 30, key="ui_ph_size")
                ph_color = st.color_picker("éŸ³æ ‡é¢œè‰²", "#E6BF20", key="ui_ph_color")  # é»˜è®¤éŸ³æ ‡é¢œè‰²
                phonetic_bold = st.checkbox("éŸ³æ ‡åŠ ç²—", value=False, key="ui_phonetic_bold")
            with col_cn:
                cn_size = st.slider("ä¸­æ–‡å­—å·", 0, 120, 46, key="ui_cn_size")
                cn_color = st.color_picker("ä¸­æ–‡é¢œè‰²", "#000000", key="ui_cn_color")  # é»˜è®¤é»‘è‰²
                chinese_bold = st.checkbox("ä¸­æ–‡åŠ ç²—", value=False, key="ui_chinese_bold")
            
            
        
        with tab_layout:
            st.markdown('<div class="scrollable-content">', unsafe_allow_html=True)
            
            # --- èƒŒæ™¯æ¿ä¸é—´è· ---
            st.markdown("**èƒŒæ™¯æ¿ä¸é—´è·**")
            b1, b2, b3, b4 = st.columns(4)
            with b1:
                text_bg_enable = st.checkbox("å¯ç”¨æ–‡å­—èƒŒæ™¯æ¿", value=True, key="ui_text_bg_enable")  # é»˜è®¤å¯ç”¨
            with b2:
                text_bg_color = st.color_picker("æ–‡å­—èƒŒæ™¯é¢œè‰²", "#FFFFFF", key="ui_text_bg_color")
            with b3:
                text_bg_alpha = st.slider("èƒŒæ™¯é€æ˜åº¦", 0.0, 1.0, 0.35, 0.05, key="ui_text_bg_alpha")
            with b4:
                text_bg_radius = st.slider("èƒŒæ™¯åœ†è§’", 0, 60, 12, key="ui_text_bg_radius")

            g1, g2, g3, g4 = st.columns(4)
            with g1:
                english_ph_gap = st.slider("è‹±è¯­â†’éŸ³æ ‡é—´è·", 0, 200, 10, key="ui_gap_en_ph")
            with g2:
                ph_cn_gap = st.slider("éŸ³æ ‡â†’ä¸­æ–‡é—´è·", 0, 200, 10, key="ui_gap_ph_cn")
            with g3:
                line_spacing = st.slider("è¡Œé—´è·", 0, 50, 6, key="ui_line_spacing")
            with g4:
                text_padding = st.slider("æ–‡å­—å†…è¾¹è·", 0, 120, 20, key="ui_text_padding")
            
            
        
        with tab_advanced:
            st.markdown('<div class="scrollable-content">', unsafe_allow_html=True)
            
            # --- åŒºåŸŸè®¾ç½® ---
            t1, t2 = st.columns(2)
            with t1:
                text_area_ratio = st.slider("æ–‡å­—åŒºåŸŸå®½åº¦æ¯”ä¾‹", 0.3, 1.0, 0.88, key="ui_text_area_ratio")
            
            # å­—ä½“é¢„è§ˆ
            if DEFAULT_FONT:
                st.success(f"å½“å‰ä½¿ç”¨å­—ä½“: {os.path.basename(DEFAULT_FONT)}")
                st.info(f"å­—ä½“è·¯å¾„: {DEFAULT_FONT}")
            else:
                st.warning("æœªæ£€æµ‹åˆ°ç³»ç»Ÿå­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
            
            
    
    with preview_col2:
        st.markdown('<div class="card-header">ğŸ‘ï¸ å®æ—¶é¢„è§ˆ</div>', unsafe_allow_html=True)
        
        # é€‰æ‹©é¢„è§ˆçš„è¡Œ
        preview_row = st.selectbox(
            "é€‰æ‹©é¢„è§ˆçš„è¡Œ",
            options=list(range(len(df))),
            format_func=lambda i: f"{i+1} - {df.iloc[i]['è‹±è¯­'][:30]}...",
            key="preview_row"
        )
        
        # å®æ—¶ç”Ÿæˆé¢„è§ˆ
        if st.button("ğŸ”„ æ›´æ–°é¢„è§ˆ", width='stretch'):
            st.session_state.force_preview_update = True
        
        # æ±‡æ€» style_conf
        style_conf = {
            "bg_mode": "image" if ui_bg_image else "color",
            "bg_color": ui_bg_color,
            "bg_image": ui_bg_image,
            "bg_image_alpha": bg_image_alpha if bg_mode == "å›¾ç‰‡èƒŒæ™¯" else 1.0,
            "english_size": en_size,
            "english_color": en_color,
            "english_bold": english_bold,
            "phonetic_size": ph_size,
            "phonetic_color": ph_color,
            "phonetic_bold": phonetic_bold,
            "chinese_size": cn_size,
            "chinese_color": cn_color,
            "chinese_bold": chinese_bold,
            "text_bg_enable": text_bg_enable,
            "text_bg_color": text_bg_color,
            "text_bg_alpha": text_bg_alpha,
            "text_bg_radius": text_bg_radius,
            "text_padding": text_padding,
            "text_area_width_ratio": text_area_ratio,
            "english_phonetic_gap": english_ph_gap,
            "phonetic_cn_gap": ph_cn_gap,
            "line_spacing": line_spacing,
        }
        
        # å®æ—¶æ¸²æŸ“é¢„è§ˆ
        row = df.iloc[preview_row]
        en = str(row.get("è‹±è¯­",""))
        ph = str(row.get("éŸ³æ ‡",""))
        cn = str(row.get("ä¸­æ–‡",""))
        
        # ç”Ÿæˆé¢„è§ˆå›¾åƒ
        preview_image = render_frame(en, ph, cn, style_conf, (640, 360))
        
        # æ˜¾ç¤ºå®æ—¶é¢„è§ˆ
        st.markdown('<div class="live-preview-container">', unsafe_allow_html=True)
        st.markdown('<div class="live-preview-title">å®æ—¶é¢„è§ˆæ•ˆæœ</div>', unsafe_allow_html=True)
        st.image(preview_image, caption="æ ·å¼é¢„è§ˆ", use_container_width=True)
        
        # æ˜¾ç¤ºé¢„è§ˆæ–‡æœ¬
        st.markdown(f'<div class="live-preview-text live-preview-english">{en}</div>', unsafe_allow_html=True)
        if ph and ph.strip():
            st.markdown(f'<div class="live-preview-text live-preview-phonetic">/{ph}/</div>', unsafe_allow_html=True)
        st.markdown(f'<div class="live-preview-text live-preview-chinese">{cn}</div>', unsafe_allow_html=True)
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # éŸ³é¢‘é¢„è§ˆéƒ¨åˆ†
        st.markdown("### ğŸ”Š éŸ³é¢‘é¢„è§ˆ")
        if st.button("ç”ŸæˆéŸ³é¢‘é¢„è§ˆ", width='stretch'):
            with st.spinner("æ­£åœ¨ç”ŸæˆéŸ³é¢‘é¢„è§ˆ..."):
                # ç”Ÿæˆé¢„è§ˆéŸ³é¢‘ - ç°åœ¨å‡½æ•°å·²ç»å®šä¹‰
                preview_audio = generate_preview_audio(df, preview_row, st.session_state.audio_segments)
                
                if preview_audio and os.path.exists(preview_audio):
                    st.audio(preview_audio, format="audio/mp3")
                    st.success("éŸ³é¢‘é¢„è§ˆç”Ÿæˆå®Œæˆï¼")
                else:
                    st.error("éŸ³é¢‘é¢„è§ˆç”Ÿæˆå¤±è´¥")
        
else:
    st.warning("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶ä»¥å¯ç”¨é¢„è§ˆåŠŸèƒ½")

# ---------- è·å–éŸ³é¢‘æ—¶é•¿ ----------
def get_audio_duration(audio_path: str) -> float:
    """è·å–éŸ³é¢‘æ–‡ä»¶çš„æ—¶é•¿ï¼ˆç§’ï¼‰"""
    try:
        if PYDUB_AVAILABLE:
            audio = AudioSegment.from_file(audio_path)
            return len(audio) / 1000.0  # è½¬æ¢ä¸ºç§’
        else:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ ffprobe
            ffprobe_path = find_ffmpeg_path().replace("ffmpeg", "ffprobe")
            cmd = [
                ffprobe_path, "-v", "error", "-show_entries", "format=duration",
                "-of", "default=noprint_wrappers=1:nokey=1", audio_path
            ]
            result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
            return float(result.stdout.strip())
    except Exception as e:
        # å¦‚æœæ— æ³•è·å–æ—¶é•¿ï¼Œè¿”å›é»˜è®¤å€¼
        return 3.0

# ---------- æ‰¹é‡TTSç”Ÿæˆå‡½æ•° ----------
def batch_generate_tts(tasks):
    """æ‰¹é‡ç”ŸæˆTTSéŸ³é¢‘ - ä½¿ç”¨çº¿ç¨‹æ± æé«˜æ•ˆç‡"""
    results = {}
    
    def worker(task):
        idx, text, voice_category, voice_choice, speed = task
        try:
            # ä¸´æ—¶æ–‡ä»¶è·¯å¾„
            fd, tmpmp3 = tempfile.mkstemp(suffix=".mp3")
            os.close(fd)
            
            # ç”ŸæˆTTS
            success = generate_tts_cached(text, voice_category, voice_choice, speed, "åœ¨çº¿ä¼˜å…ˆ", tmpmp3)
            
            if success and os.path.exists(tmpmp3):
                return idx, tmpmp3, True
            else:
                safe_remove(tmpmp3)
                return idx, None, False
        except Exception as e:
            return idx, None, False
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        future_to_task = {executor.submit(worker, task): task for task in tasks}
        
        for future in concurrent.futures.as_completed(future_to_task):
            task = future_to_task[future]
            try:
                idx, audio_path, success = future.result()
                results[idx] = (audio_path, success)
            except Exception as e:
                results[task[0]] = (None, False)
    
    return results

# ---------- ä¼˜åŒ–åçš„è§†é¢‘ç”Ÿæˆå‡½æ•° ----------
def generate_video_pipeline_optimized(df, rows, style_conf, audio_segments, video_params, progress_cb=None):
    """ä¼˜åŒ–åçš„è§†é¢‘ç”Ÿæˆæµç¨‹ - ä½¿ç”¨æ‰¹é‡å¤„ç†å’Œå¹¶è¡ŒåŒ–"""
    tmpdir = tempfile.mkdtemp(prefix="gen_")
    try:
        W,H = video_params.get("resolution",(1280,720))
        fps = video_params.get("fps",12)
        
        frame_files = []
        audios = []
        
        # ç¬¬ä¸€æ­¥ï¼šæ‰¹é‡ç”Ÿæˆæ‰€æœ‰éŸ³é¢‘
        st.info("ğŸµ æ­£åœ¨æ‰¹é‡ç”ŸæˆéŸ³é¢‘...")
        tts_tasks = []
        audio_task_map = {}  # æ˜ å°„: (row_id, seg_idx) -> task_index
        
        task_idx = 0
        for rid in rows:
            row = df.iloc[rid]
            en = str(row.get("è‹±è¯­",""))
            ph = str(row.get("éŸ³æ ‡",""))
            cn = str(row.get("ä¸­æ–‡",""))
            
            for seg_idx, seg in enumerate(audio_segments):
                text = en if seg["content"]=="è‹±è¯­" else (ph if seg["content"]=="éŸ³æ ‡" else cn)
                tts_tasks.append((task_idx, text, seg["voice_category"], seg["voice_choice"], seg["speed"]))
                audio_task_map[(rid, seg_idx)] = task_idx
                task_idx += 1
        
        # æ‰¹é‡ç”ŸæˆTTS
        tts_results = batch_generate_tts(tts_tasks)
        
        if progress_cb:
            progress_cb(0.3)
        
        # ç¬¬äºŒæ­¥ï¼šå¤„ç†æ¯ä¸€è¡Œæ•°æ®
        st.info("ğŸ–¼ï¸ æ­£åœ¨ç”Ÿæˆè§†é¢‘å¸§å’ŒéŸ³é¢‘...")
        total_rows = len(rows)
        
        for row_idx, rid in enumerate(rows):
            row = df.iloc[rid]
            en = str(row.get("è‹±è¯­",""))
            ph = str(row.get("éŸ³æ ‡",""))
            cn = str(row.get("ä¸­æ–‡",""))
            
            # æ¸²æŸ“å½“å‰å•è¯çš„ç”»é¢
            img = render_frame(en, ph, cn, style_conf, (W,H))
            
            # éŸ³é¢‘ç”Ÿæˆ - ä½¿ç”¨é¢„ç”Ÿæˆçš„TTSç»“æœ
            seg_paths = []
            total_audio_duration = 0
            
            for seg_idx, seg in enumerate(audio_segments):
                task_idx = audio_task_map[(rid, seg_idx)]
                audio_path, success = tts_results[task_idx]
                
                if success and audio_path and os.path.exists(audio_path):
                    # è·å–å®é™…éŸ³é¢‘æ—¶é•¿
                    audio_duration = get_audio_duration(audio_path)
                    total_audio_duration += audio_duration
                    seg_paths.append(audio_path)
                else:
                    # å¦‚æœTTSå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ—¶é•¿
                    default_duration = 3.0
                    total_audio_duration += default_duration
                    silent_path = os.path.join(tmpdir, f"silent_{rid}_{seg_idx}.mp3")
                    create_silent_mp3(silent_path, default_duration)
                    seg_paths.append(silent_path)
                
                # æ·»åŠ åœé¡¿
                if seg.get("pause",0) > 0:
                    pause_path = os.path.join(tmpdir, f"pause_{rid}_{seg_idx}.mp3")
                    create_silent_mp3(pause_path, seg["pause"])
                    total_audio_duration += seg["pause"]
                    seg_paths.append(pause_path)
            
            # åˆå¹¶å½“å‰è¡Œçš„éŸ³é¢‘
            if seg_paths:
                merged_audio = os.path.join(tmpdir, f"{rid}_merged.mp3")
                try:
                    concat_audios_ffmpeg(seg_paths, merged_audio)
                    audios.append(merged_audio)
                    
                    # æ ¹æ®éŸ³é¢‘æ—¶é•¿ç”Ÿæˆå¯¹åº”æ•°é‡çš„å¸§
                    frames_this_word = int(total_audio_duration * fps)
                    for i in range(frames_this_word):
                        fname = os.path.join(tmpdir, f"{rid}_{i:04d}.png")
                        img.save(fname)
                        frame_files.append(fname)
                        
                except Exception as e:
                    st.error(f"éŸ³é¢‘åˆå¹¶å¤±è´¥: {e}")
                    # ä½¿ç”¨é»˜è®¤å¸§æ•°ä½œä¸ºå¤‡é€‰
                    frames_this_word = int(3.0 * fps)  # é»˜è®¤3ç§’
                    for i in range(frames_this_word):
                        fname = os.path.join(tmpdir, f"{rid}_{i:04d}.png")
                        img.save(fname)
                        frame_files.append(fname)
            
            # æ›´æ–°è¿›åº¦
            if progress_cb:
                progress = 0.3 + (row_idx / total_rows) * 0.4
                progress_cb(progress)

        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„å¸§
        if not frame_files:
            st.error("æ²¡æœ‰ç”Ÿæˆä»»ä½•å¸§ï¼Œæ— æ³•åˆæˆè§†é¢‘")
            return None
            
        # ç¬¬ä¸‰æ­¥ï¼šåˆæˆè§†é¢‘
        st.info("ğŸ¬ æ­£åœ¨åˆæˆè§†é¢‘...")
        list_txt = os.path.join(tmpdir, "imgs.txt")
        with open(list_txt, "w", encoding="utf-8") as f:
            for p in frame_files:
                f.write(f"file '{p}'\n")
                f.write(f"duration {1.0/fps}\n")  # æ¯å¸§çš„æŒç»­æ—¶é—´
        
        video_no_audio = os.path.join(tmpdir, "video.mp4")
        
        cmd = [
            "ffmpeg", "-y", "-f", "concat", "-safe", "0", 
            "-i", list_txt, "-r", str(fps), "-pix_fmt", "yuv420p", 
            video_no_audio
        ]
        
        try:
            run_ffmpeg_command(cmd)
        except Exception as e:
            st.error(f"è§†é¢‘åˆæˆå¤±è´¥: {e}")
            return None
        
        if progress_cb:
            progress_cb(0.8)
        
        # ç¬¬å››æ­¥ï¼šåˆå¹¶éŸ³é¢‘
        st.info("ğŸ”Š æ­£åœ¨åˆå¹¶éŸ³é¢‘...")
        if audios:
            final_audio = os.path.join(tmpdir, "final_audio.mp3")
            try:
                concat_audios_ffmpeg(audios, final_audio)
            except Exception as e:
                st.error(f"æœ€ç»ˆéŸ³é¢‘åˆå¹¶å¤±è´¥: {e}")
                return None
            
            # åˆå¹¶éŸ³è§†é¢‘
            out_video = os.path.join(tmpdir, "final_out.mp4")
            cmd = [
                "ffmpeg", "-y", "-i", video_no_audio, "-i", final_audio,
                "-c:v", "copy", "-c:a", "aac", "-shortest", out_video
            ]
            try:
                run_ffmpeg_command(cmd)
            except Exception as e:
                st.error(f"éŸ³è§†é¢‘åˆå¹¶å¤±è´¥: {e}")
                return None
        else:
            out_video = video_no_audio
        
        if progress_cb:
            progress_cb(1.0)
        
        if os.path.exists(out_video):
            # å°†è§†é¢‘æ–‡ä»¶å¤åˆ¶åˆ°æ°¸ä¹…ä½ç½®
            permanent_video_path = os.path.join(CACHE_DIR, f"generated_video_{int(time.time())}.mp4")
            try:
                shutil.copy2(out_video, permanent_video_path)
                return permanent_video_path
            except Exception as e:
                # å¦‚æœå¤åˆ¶å¤±è´¥ï¼Œä»ç„¶è¿”å›åŸå§‹è·¯å¾„
                return out_video
        else:
            st.error("è¾“å‡ºè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
            return None
            
    except Exception as e:
        st.error(f"ç”Ÿæˆæµç¨‹å¼‚å¸¸: {e}")
        import traceback
        st.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return None
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            shutil.rmtree(tmpdir)
        except:
            pass

# ---------- ç”Ÿæˆä¸ä¸‹è½½éƒ¨åˆ† ----------
st.markdown('<div class="card-header">ğŸ“¤ ç”Ÿæˆä¸ä¸‹è½½</div>', unsafe_allow_html=True)

# FFmpeg æ£€æµ‹å’Œå®‰è£…æŒ‡å¼•
ffmpeg_path = find_ffmpeg_path()
if not ffmpeg_available():
    st.error("âš ï¸ FFmpeg æœªæ‰¾åˆ°ï¼Œè§†é¢‘ç”ŸæˆåŠŸèƒ½ä¸å¯ç”¨")
    
    if 'STREAMLIT_SHARING_MODE' in os.environ:
        st.info("""
        **Streamlit Cloud ç¯å¢ƒæ£€æµ‹**
        
        åœ¨ Streamlit Cloud ä¸Šï¼Œè¯·ç¡®ä¿ requirements.txt åŒ…å«ï¼š
        ```
        imageio[ffmpeg]>=2.33.0
        ```
        """)
    elif sys.platform.startswith("darwin"):
        st.info("""
        **macOS FFmpeg å®‰è£…ï¼š**
        ```bash
        brew install ffmpeg
        ```
        """)
    else:
        st.info("""
        **FFmpeg å®‰è£…æŒ‡å—ï¼š**
        
        **Windows:**
        1. ä¸‹è½½: https://ffmpeg.org/download.html
        2. è§£å‹åˆ° C:\\ffmpeg
        3. æ·»åŠ  C:\\ffmpeg\\bin åˆ°ç³»ç»Ÿ PATH
        
        **Linux:**
        ```bash
        sudo apt-get install ffmpeg
        ```
        """)

# è§†é¢‘è´¨é‡è®¾ç½®
st.markdown("### ğŸ¯ è§†é¢‘è´¨é‡è®¾ç½®")
quality_col1, quality_col2, quality_col3 = st.columns(3)

with quality_col1:
    resolution = st.selectbox(
        "è§†é¢‘åˆ†è¾¨ç‡",
        ["640x360", "854x480", "1280x720", "1920x1080"],
        index=2,
        help="è¾ƒä½åˆ†è¾¨ç‡ç”Ÿæˆæ›´å¿«ï¼Œä½†ç”»è´¨è¾ƒå·®"
    )

with quality_col2:
    fps = st.selectbox(
        "å¸§ç‡ (FPS)",
        [8, 12, 24, 30],
        index=1,
        help="è¾ƒä½å¸§ç‡ç”Ÿæˆæ›´å¿«ï¼Œä½†æµç•…åº¦è¾ƒå·®"
    )

with quality_col3:
    quality_preset = st.selectbox(
        "ç”Ÿæˆé€Ÿåº¦ä¼˜åŒ–",
        ["æ ‡å‡†æ¨¡å¼", "å¿«é€Ÿæ¨¡å¼", "æé€Ÿæ¨¡å¼"],
        index=1,
        help="å¿«é€Ÿæ¨¡å¼ä¼šç‰ºç‰²ä¸€äº›è´¨é‡æ¥æå‡ç”Ÿæˆé€Ÿåº¦"
    )

# è§£æåˆ†è¾¨ç‡
res_map = {
    "640x360": (640, 360),
    "854x480": (854, 480), 
    "1280x720": (1280, 720),
    "1920x1080": (1920, 1080)
}

# æ ¹æ®è´¨é‡é¢„è®¾è°ƒæ•´å‚æ•°
if quality_preset == "å¿«é€Ÿæ¨¡å¼":
    fps = min(fps, 12)  # é™åˆ¶å¸§ç‡
    if resolution == "1920x1080":
        resolution = "1280x720"  # é™ä½åˆ†è¾¨ç‡
elif quality_preset == "æé€Ÿæ¨¡å¼":
    fps = 8
    resolution = "854x480"

video_params = {
    "resolution": res_map[resolution],
    "fps": fps
}

# åœ¨ç”Ÿæˆè§†é¢‘éƒ¨åˆ†ä½¿ç”¨ audio_segments
if uploaded is not None and df is not None:
    total = len(df)
    
    # é»˜è®¤é€‰æ‹©æ‰€æœ‰è¡Œï¼ˆæŒ‰é¡ºåºï¼‰
    default_rows = list(range(min(total, 10)))  # é»˜è®¤é€‰æ‹©å‰10è¡Œæˆ–å…¨éƒ¨ï¼ˆå¦‚æœå°‘äº10è¡Œï¼‰
    
    rows = st.multiselect(
        "é€‰æ‹©ç”Ÿæˆçš„è¡Œ", 
        options=list(range(total)), 
        format_func=lambda i: f"{i+1} - {df.iloc[i]['è‹±è¯­'][:30]}...", 
        default=default_rows
    )
    
    # æ˜¾ç¤ºé¢„ä¼°æ—¶é—´
    if rows:
        estimated_time = len(rows) * len(st.session_state.audio_segments) * 2  # æ¯æ®µéŸ³é¢‘çº¦2ç§’
        if quality_preset == "å¿«é€Ÿæ¨¡å¼":
            estimated_time = estimated_time * 0.7
        elif quality_preset == "æé€Ÿæ¨¡å¼":
            estimated_time = estimated_time * 0.5
            
        st.info(f"â±ï¸ é¢„ä¼°ç”Ÿæˆæ—¶é—´: {estimated_time:.0f}ç§’ (ä½¿ç”¨{quality_preset})")
    
    if rows:
        if st.button("â–¶ï¸ å¼€å§‹ç”Ÿæˆè§†é¢‘", width='stretch', disabled=not ffmpeg_available()):
            # é¢„æ£€æŸ¥
            if not ffmpeg_available():
                st.error("FFmpeg ä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆè§†é¢‘")
                st.stop()
                
            if df is None:
                st.error("æ²¡æœ‰æ•°æ®å¯å¤„ç†")
                st.stop()
                
            if not rows:
                st.error("è¯·é€‰æ‹©è¦ç”Ÿæˆçš„è¡Œ")
                st.stop()
            
            progress = st.progress(0.0)
            status = st.empty()
            
            def cb(p):
                progress.progress(p)
                status.text(f"è¿›åº¦: {int(p*100)}%")
            
            status.text("ç”Ÿæˆä¸­...")
            
            try:
                # ä½¿ç”¨ä¼˜åŒ–åçš„ç”Ÿæˆå‡½æ•°
                outp = generate_video_pipeline_optimized(df, rows, style_conf, st.session_state.audio_segments, video_params, progress_cb=cb)
                
                if outp and os.path.exists(outp):
                    st.success("âœ… è§†é¢‘ç”Ÿæˆå®Œæˆ")
                    
                    # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
                    video_size = os.path.getsize(outp) / (1024 * 1024)  # MB
                    st.info(f"è§†é¢‘ä¿¡æ¯: {resolution} @ {fps}fps, å¤§å°: {video_size:.1f}MB")
                    
                    with open(outp,"rb") as f:
                        st.video(f.read())
                    with open(outp,"rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è½½è§†é¢‘", f, file_name="travel_english.mp4", width='stretch')
                else:
                    st.error("âŒ ç”Ÿæˆå¤±è´¥ï¼Œè¯·æŸ¥çœ‹é”™è¯¯ä¿¡æ¯")
            except Exception as e:
                st.error(f"âŒ ç”Ÿæˆé”™è¯¯: {str(e)}")
                with st.expander("æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                    st.code(traceback.format_exc())
    else:
        st.info("è¯·é€‰æ‹©è‡³å°‘ä¸€è¡Œè¿›è¡Œç”Ÿæˆã€‚")
else:
    st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶ä»¥å¯ç”¨è§†é¢‘ç”ŸæˆåŠŸèƒ½")

# ---------- ä¾§è¾¹æ ï¼šæ¨¡æ¿ä¸è¿›åº¦ ----------
st.sidebar.header("ğŸ“¦ æ¨¡æ¿ä¸ä»»åŠ¡")
templates = load_templates()
if st.sidebar.button("ä¿å­˜å½“å‰é…ç½®ä¸ºæ¨¡æ¿", width='stretch'):
    name = f"æ¨¡æ¿_{time.strftime('%H%M%S')}"
    save_template(name, style_conf, st.session_state.audio_segments, {"resolution":(1280,720),"fps":12})
    st.sidebar.success(f"å·²ä¿å­˜æ¨¡æ¿ {name}")
if templates:
    st.sidebar.subheader("å·²ä¿å­˜çš„æ¨¡æ¿")
    for tname, tdata in templates:
        if st.sidebar.button(f"åº”ç”¨æ¨¡æ¿ {tname}", width='stretch'):
            style_conf.update(tdata["style"])
            st.session_state.audio_segments = tdata["audio"].copy()
            st.sidebar.info(f"å·²åº”ç”¨æ¨¡æ¿ {tname}")

# å­¦ä¹ è¿›åº¦
st.sidebar.header("ğŸ“š å­¦ä¹ è¿›åº¦")
prog = load_progress()
st.sidebar.write(f"å·²å­¦ä¹ è®°å½•æ¡ç›®ï¼š{len(prog)}")
if st.sidebar.button("æ¸…é™¤å­¦ä¹ è®°å½•", width='stretch'):
    save_progress({})
    st.sidebar.success("å­¦ä¹ è®°å½•å·²æ¸…é™¤")

# ---------- ç¯å¢ƒæç¤º ----------
st.sidebar.header("ğŸ”§ ç³»ç»Ÿç¯å¢ƒ")
st.sidebar.write(f"âœ… æ“ä½œç³»ç»Ÿ: {sys.platform}")
st.sidebar.write(f"âœ… ffmpeg: {'å¯ç”¨' if ffmpeg_available() else 'ç¼ºå¤±'}")
if ffmpeg_path:
    st.sidebar.write(f"ğŸ“ è·¯å¾„: {ffmpeg_path}")
st.sidebar.write(f"âœ… pyttsx3: {'å¯ç”¨' if PYTTSX3_AVAILABLE else 'ç¼ºå¤±'}")
st.sidebar.write(f"âœ… edge-tts: {'å¯ç”¨' if EDGE_TTS_AVAILABLE else 'ç¼ºå¤±'}")
st.sidebar.write(f"âœ… pydub: {'å¯ç”¨' if PYDUB_AVAILABLE else 'ç¼ºå¤±'}")

# æ£€æµ‹è¿è¡Œç¯å¢ƒ
if 'STREAMLIT_SHARING_MODE' in os.environ:
    st.sidebar.info("ğŸŒ Streamlit Cloud ç¯å¢ƒ")
else:
    st.sidebar.info("ğŸ’» æœ¬åœ°è¿è¡Œç¯å¢ƒ")

# ---------- é¡µè„š ----------
st.markdown(
    f"""
    <div class='footer'>
    Â© 2025 è‹±è¯­è§†é¢‘ç”Ÿæˆå™¨ â€¢ æŠ€æœ¯æ”¯æŒï¼šAI å¤šåª’ä½“å®éªŒå®¤  
    ç¯å¢ƒï¼šFFmpeg {"âœ… å·²æ£€æµ‹" if ffmpeg_available() else "âš ï¸ æœªæ£€æµ‹"} | å¹³å°: {sys.platform}
    </div>
    """,
    unsafe_allow_html=True
)
